{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.9479593634605408,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 2.3789,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.5464972257614136,
      "learning_rate": 4.9e-05,
      "loss": 2.3549,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.3337299823760986,
      "learning_rate": 4.85e-05,
      "loss": 2.1671,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.6896445751190186,
      "learning_rate": 4.8e-05,
      "loss": 2.1884,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3402836322784424,
      "learning_rate": 4.75e-05,
      "loss": 2.2034,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.5278422832489014,
      "learning_rate": 4.7e-05,
      "loss": 1.9327,
      "step": 60
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3716206550598145,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 1.9221,
      "step": 70
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.409725666046143,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.0053,
      "step": 80
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6158283948898315,
      "learning_rate": 4.55e-05,
      "loss": 2.0212,
      "step": 90
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.48403000831604,
      "learning_rate": 4.5e-05,
      "loss": 1.8959,
      "step": 100
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.4590351581573486,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 1.7994,
      "step": 110
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.807621002197266,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.9688,
      "step": 120
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.782036304473877,
      "learning_rate": 4.35e-05,
      "loss": 1.8454,
      "step": 130
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6472448110580444,
      "learning_rate": 4.3e-05,
      "loss": 1.8773,
      "step": 140
    },
    {
      "epoch": 0.15,
      "grad_norm": 13.436528205871582,
      "learning_rate": 4.25e-05,
      "loss": 1.8684,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7069646120071411,
      "learning_rate": 4.2e-05,
      "loss": 1.9199,
      "step": 160
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1392927169799805,
      "learning_rate": 4.15e-05,
      "loss": 1.872,
      "step": 170
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.2833409309387207,
      "learning_rate": 4.1e-05,
      "loss": 1.8646,
      "step": 180
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.951127529144287,
      "learning_rate": 4.05e-05,
      "loss": 1.9761,
      "step": 190
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.927355170249939,
      "learning_rate": 4e-05,
      "loss": 1.9869,
      "step": 200
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.5045218467712402,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 1.8841,
      "step": 210
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.4008122682571411,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.8116,
      "step": 220
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.7159337997436523,
      "learning_rate": 3.85e-05,
      "loss": 1.8972,
      "step": 230
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0310620069503784,
      "learning_rate": 3.8e-05,
      "loss": 1.8893,
      "step": 240
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.8333520889282227,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.8964,
      "step": 250
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.6094211339950562,
      "learning_rate": 3.7e-05,
      "loss": 1.8713,
      "step": 260
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3568891286849976,
      "learning_rate": 3.65e-05,
      "loss": 1.8017,
      "step": 270
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.475947856903076,
      "learning_rate": 3.6e-05,
      "loss": 1.9438,
      "step": 280
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.6581863164901733,
      "learning_rate": 3.55e-05,
      "loss": 1.8186,
      "step": 290
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.2852535247802734,
      "learning_rate": 3.5e-05,
      "loss": 1.8365,
      "step": 300
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.715097427368164,
      "learning_rate": 3.45e-05,
      "loss": 1.8292,
      "step": 310
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.043025016784668,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.8128,
      "step": 320
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5570554733276367,
      "learning_rate": 3.35e-05,
      "loss": 1.9504,
      "step": 330
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7877521514892578,
      "learning_rate": 3.3e-05,
      "loss": 1.9937,
      "step": 340
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.7406948804855347,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.9222,
      "step": 350
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.781418800354004,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.7718,
      "step": 360
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9669230580329895,
      "learning_rate": 3.15e-05,
      "loss": 1.8339,
      "step": 370
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.663727283477783,
      "learning_rate": 3.1e-05,
      "loss": 1.9475,
      "step": 380
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3957645893096924,
      "learning_rate": 3.05e-05,
      "loss": 1.8141,
      "step": 390
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1903808116912842,
      "learning_rate": 3e-05,
      "loss": 2.1153,
      "step": 400
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5157729387283325,
      "learning_rate": 2.95e-05,
      "loss": 1.9589,
      "step": 410
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.487905740737915,
      "learning_rate": 2.9e-05,
      "loss": 1.7591,
      "step": 420
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1528892517089844,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 1.8682,
      "step": 430
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.253916025161743,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.7862,
      "step": 440
    },
    {
      "epoch": 0.45,
      "grad_norm": 9.462148666381836,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 1.8934,
      "step": 450
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.682309865951538,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.9483,
      "step": 460
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.697963833808899,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 1.8275,
      "step": 470
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.877429187297821,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.6758,
      "step": 480
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.508242607116699,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 1.8869,
      "step": 490
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8541114330291748,
      "learning_rate": 2.5e-05,
      "loss": 1.8732,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 20,
  "total_flos": 2213164107399168.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
