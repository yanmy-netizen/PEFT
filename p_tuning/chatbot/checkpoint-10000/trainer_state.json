{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9319938176197837,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.512276530265808,
      "learning_rate": 4.99517001545595e-05,
      "loss": 2.2979,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.5537364482879639,
      "learning_rate": 4.9903400309119017e-05,
      "loss": 2.058,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4186077117919922,
      "learning_rate": 4.985510046367852e-05,
      "loss": 2.0979,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8649060726165771,
      "learning_rate": 4.9806800618238024e-05,
      "loss": 1.9974,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.789161205291748,
      "learning_rate": 4.975850077279753e-05,
      "loss": 1.8942,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.22195291519165,
      "learning_rate": 4.971020092735704e-05,
      "loss": 1.9617,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.871561884880066,
      "learning_rate": 4.966190108191654e-05,
      "loss": 1.9494,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9821010828018188,
      "learning_rate": 4.9613601236476046e-05,
      "loss": 1.9051,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9740235209465027,
      "learning_rate": 4.956530139103555e-05,
      "loss": 1.8326,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.4539144039154053,
      "learning_rate": 4.951700154559505e-05,
      "loss": 1.8645,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 4.128133773803711,
      "learning_rate": 4.946870170015456e-05,
      "loss": 1.9122,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2362775802612305,
      "learning_rate": 4.942040185471407e-05,
      "loss": 1.8465,
      "step": 120
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3259879350662231,
      "learning_rate": 4.9372102009273574e-05,
      "loss": 1.9632,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4482978582382202,
      "learning_rate": 4.9323802163833074e-05,
      "loss": 1.7859,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.023425817489624,
      "learning_rate": 4.927550231839259e-05,
      "loss": 1.9107,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3293758630752563,
      "learning_rate": 4.922720247295209e-05,
      "loss": 1.9042,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.7725319862365723,
      "learning_rate": 4.917890262751159e-05,
      "loss": 1.9426,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.298893690109253,
      "learning_rate": 4.91306027820711e-05,
      "loss": 1.7779,
      "step": 180
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.4886245727539062,
      "learning_rate": 4.90823029366306e-05,
      "loss": 1.9131,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.5831756591796875,
      "learning_rate": 4.903400309119011e-05,
      "loss": 1.9413,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.3882287740707397,
      "learning_rate": 4.898570324574962e-05,
      "loss": 1.8305,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.3007094860076904,
      "learning_rate": 4.8937403400309124e-05,
      "loss": 1.9328,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.189422607421875,
      "learning_rate": 4.8889103554868625e-05,
      "loss": 1.8124,
      "step": 230
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.4196733236312866,
      "learning_rate": 4.884080370942813e-05,
      "loss": 1.9176,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8174216151237488,
      "learning_rate": 4.879250386398764e-05,
      "loss": 1.9243,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.9444830417633057,
      "learning_rate": 4.874420401854714e-05,
      "loss": 1.8786,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.4274126291275024,
      "learning_rate": 4.8695904173106646e-05,
      "loss": 1.8048,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.400054931640625,
      "learning_rate": 4.864760432766615e-05,
      "loss": 1.99,
      "step": 280
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7923294901847839,
      "learning_rate": 4.859930448222566e-05,
      "loss": 1.9963,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.3093634843826294,
      "learning_rate": 4.855100463678516e-05,
      "loss": 1.8503,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1989244222640991,
      "learning_rate": 4.8502704791344675e-05,
      "loss": 1.9939,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0896685123443604,
      "learning_rate": 4.8454404945904175e-05,
      "loss": 1.872,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.446650505065918,
      "learning_rate": 4.840610510046368e-05,
      "loss": 2.1034,
      "step": 330
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1043789386749268,
      "learning_rate": 4.835780525502319e-05,
      "loss": 1.8615,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.2948262691497803,
      "learning_rate": 4.830950540958269e-05,
      "loss": 1.9182,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.2375115156173706,
      "learning_rate": 4.8261205564142196e-05,
      "loss": 1.9943,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8587477803230286,
      "learning_rate": 4.8212905718701704e-05,
      "loss": 1.7864,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.5831174850463867,
      "learning_rate": 4.816460587326121e-05,
      "loss": 1.9547,
      "step": 380
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5537477731704712,
      "learning_rate": 4.811630602782071e-05,
      "loss": 1.8623,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.6346931457519531,
      "learning_rate": 4.806800618238022e-05,
      "loss": 1.853,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.711123466491699,
      "learning_rate": 4.8019706336939725e-05,
      "loss": 1.8546,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9784862995147705,
      "learning_rate": 4.797140649149923e-05,
      "loss": 1.8125,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6326505541801453,
      "learning_rate": 4.792310664605873e-05,
      "loss": 1.827,
      "step": 430
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.099151134490967,
      "learning_rate": 4.787480680061824e-05,
      "loss": 1.9751,
      "step": 440
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6215066313743591,
      "learning_rate": 4.782650695517775e-05,
      "loss": 1.7989,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9491435289382935,
      "learning_rate": 4.777820710973725e-05,
      "loss": 2.0475,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9534379243850708,
      "learning_rate": 4.772990726429676e-05,
      "loss": 1.7003,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9982730150222778,
      "learning_rate": 4.768160741885626e-05,
      "loss": 1.8023,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0261658430099487,
      "learning_rate": 4.763330757341577e-05,
      "loss": 1.8769,
      "step": 490
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9873858094215393,
      "learning_rate": 4.7585007727975275e-05,
      "loss": 1.7999,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1183280944824219,
      "learning_rate": 4.7536707882534776e-05,
      "loss": 2.173,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.270329475402832,
      "learning_rate": 4.748840803709428e-05,
      "loss": 1.8835,
      "step": 520
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2495784759521484,
      "learning_rate": 4.744010819165379e-05,
      "loss": 1.8691,
      "step": 530
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2955824136734009,
      "learning_rate": 4.73918083462133e-05,
      "loss": 1.7695,
      "step": 540
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.50275456905365,
      "learning_rate": 4.73435085007728e-05,
      "loss": 1.7828,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 4.992642879486084,
      "learning_rate": 4.7295208655332304e-05,
      "loss": 1.7758,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7197144627571106,
      "learning_rate": 4.724690880989181e-05,
      "loss": 1.7896,
      "step": 570
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9814595580101013,
      "learning_rate": 4.719860896445132e-05,
      "loss": 1.9715,
      "step": 580
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8010063171386719,
      "learning_rate": 4.715030911901082e-05,
      "loss": 1.8223,
      "step": 590
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5096444487571716,
      "learning_rate": 4.7102009273570326e-05,
      "loss": 1.9206,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.182224273681641,
      "learning_rate": 4.705370942812983e-05,
      "loss": 1.824,
      "step": 610
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7621951699256897,
      "learning_rate": 4.700540958268933e-05,
      "loss": 1.8885,
      "step": 620
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.5553687810897827,
      "learning_rate": 4.695710973724885e-05,
      "loss": 1.7265,
      "step": 630
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.376128911972046,
      "learning_rate": 4.690880989180835e-05,
      "loss": 1.8071,
      "step": 640
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.4635179042816162,
      "learning_rate": 4.6860510046367854e-05,
      "loss": 1.8754,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8926180005073547,
      "learning_rate": 4.681221020092736e-05,
      "loss": 1.7935,
      "step": 660
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1338555812835693,
      "learning_rate": 4.676391035548687e-05,
      "loss": 1.8387,
      "step": 670
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3646782636642456,
      "learning_rate": 4.671561051004637e-05,
      "loss": 1.991,
      "step": 680
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7142999172210693,
      "learning_rate": 4.6667310664605876e-05,
      "loss": 1.8811,
      "step": 690
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.879024624824524,
      "learning_rate": 4.661901081916538e-05,
      "loss": 1.8481,
      "step": 700
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3532814979553223,
      "learning_rate": 4.6570710973724883e-05,
      "loss": 1.8649,
      "step": 710
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0253468751907349,
      "learning_rate": 4.652241112828439e-05,
      "loss": 1.9204,
      "step": 720
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.155950665473938,
      "learning_rate": 4.64741112828439e-05,
      "loss": 1.8308,
      "step": 730
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0912095308303833,
      "learning_rate": 4.6425811437403405e-05,
      "loss": 1.8001,
      "step": 740
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9994227290153503,
      "learning_rate": 4.6377511591962905e-05,
      "loss": 1.9835,
      "step": 750
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.474937915802002,
      "learning_rate": 4.632921174652241e-05,
      "loss": 1.9668,
      "step": 760
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6076232194900513,
      "learning_rate": 4.628091190108192e-05,
      "loss": 1.6741,
      "step": 770
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9723702669143677,
      "learning_rate": 4.623261205564142e-05,
      "loss": 1.8352,
      "step": 780
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.043243169784546,
      "learning_rate": 4.618431221020093e-05,
      "loss": 1.9326,
      "step": 790
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9893133044242859,
      "learning_rate": 4.6136012364760434e-05,
      "loss": 1.841,
      "step": 800
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.8705155849456787,
      "learning_rate": 4.608771251931994e-05,
      "loss": 1.975,
      "step": 810
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7871485948562622,
      "learning_rate": 4.603941267387945e-05,
      "loss": 1.8479,
      "step": 820
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9031606912612915,
      "learning_rate": 4.5991112828438955e-05,
      "loss": 1.6957,
      "step": 830
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.63371467590332,
      "learning_rate": 4.5942812982998455e-05,
      "loss": 1.8144,
      "step": 840
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5965730547904968,
      "learning_rate": 4.589451313755796e-05,
      "loss": 1.675,
      "step": 850
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0393162965774536,
      "learning_rate": 4.584621329211747e-05,
      "loss": 1.7947,
      "step": 860
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.3515117168426514,
      "learning_rate": 4.579791344667697e-05,
      "loss": 2.0096,
      "step": 870
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.37807974219322205,
      "learning_rate": 4.574961360123648e-05,
      "loss": 1.7741,
      "step": 880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.873267650604248,
      "learning_rate": 4.5701313755795984e-05,
      "loss": 1.7496,
      "step": 890
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5980045795440674,
      "learning_rate": 4.565301391035549e-05,
      "loss": 1.7457,
      "step": 900
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5626999139785767,
      "learning_rate": 4.560471406491499e-05,
      "loss": 1.8995,
      "step": 910
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0855103731155396,
      "learning_rate": 4.5556414219474505e-05,
      "loss": 1.8395,
      "step": 920
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.4773776531219482,
      "learning_rate": 4.5508114374034005e-05,
      "loss": 1.7497,
      "step": 930
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.45380285382270813,
      "learning_rate": 4.5459814528593506e-05,
      "loss": 1.7898,
      "step": 940
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7747995257377625,
      "learning_rate": 4.541151468315302e-05,
      "loss": 1.992,
      "step": 950
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7440056800842285,
      "learning_rate": 4.536321483771252e-05,
      "loss": 1.7165,
      "step": 960
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9495611786842346,
      "learning_rate": 4.531491499227203e-05,
      "loss": 1.8197,
      "step": 970
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7492652535438538,
      "learning_rate": 4.5266615146831534e-05,
      "loss": 1.8076,
      "step": 980
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6033920049667358,
      "learning_rate": 4.521831530139104e-05,
      "loss": 1.7836,
      "step": 990
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.3589630126953125,
      "learning_rate": 4.517001545595054e-05,
      "loss": 1.7279,
      "step": 1000
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.358678102493286,
      "learning_rate": 4.512171561051005e-05,
      "loss": 1.7875,
      "step": 1010
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.4119524955749512,
      "learning_rate": 4.5073415765069556e-05,
      "loss": 1.7986,
      "step": 1020
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7276859283447266,
      "learning_rate": 4.5025115919629056e-05,
      "loss": 1.8504,
      "step": 1030
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2682219743728638,
      "learning_rate": 4.497681607418856e-05,
      "loss": 1.8137,
      "step": 1040
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.443548560142517,
      "learning_rate": 4.492851622874807e-05,
      "loss": 1.9619,
      "step": 1050
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8112573623657227,
      "learning_rate": 4.488021638330758e-05,
      "loss": 1.8393,
      "step": 1060
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.166896343231201,
      "learning_rate": 4.483191653786708e-05,
      "loss": 1.7655,
      "step": 1070
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3739774823188782,
      "learning_rate": 4.478361669242659e-05,
      "loss": 1.8561,
      "step": 1080
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0667879581451416,
      "learning_rate": 4.473531684698609e-05,
      "loss": 1.7304,
      "step": 1090
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7878924012184143,
      "learning_rate": 4.468701700154559e-05,
      "loss": 1.7866,
      "step": 1100
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.3421142101287842,
      "learning_rate": 4.4638717156105106e-05,
      "loss": 1.7897,
      "step": 1110
    },
    {
      "epoch": 0.22,
      "grad_norm": 6.5324835777282715,
      "learning_rate": 4.4590417310664606e-05,
      "loss": 2.1281,
      "step": 1120
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1432931423187256,
      "learning_rate": 4.454211746522411e-05,
      "loss": 1.802,
      "step": 1130
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.832145094871521,
      "learning_rate": 4.449381761978362e-05,
      "loss": 1.8606,
      "step": 1140
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8021724224090576,
      "learning_rate": 4.444551777434313e-05,
      "loss": 1.9061,
      "step": 1150
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8149114847183228,
      "learning_rate": 4.439721792890263e-05,
      "loss": 1.8476,
      "step": 1160
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.6626126766204834,
      "learning_rate": 4.4348918083462135e-05,
      "loss": 1.9236,
      "step": 1170
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1882445812225342,
      "learning_rate": 4.430061823802164e-05,
      "loss": 1.8451,
      "step": 1180
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5908521413803101,
      "learning_rate": 4.425231839258114e-05,
      "loss": 1.8182,
      "step": 1190
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6137890815734863,
      "learning_rate": 4.420401854714065e-05,
      "loss": 1.7266,
      "step": 1200
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9044125080108643,
      "learning_rate": 4.4155718701700156e-05,
      "loss": 1.851,
      "step": 1210
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1307733058929443,
      "learning_rate": 4.4107418856259663e-05,
      "loss": 2.014,
      "step": 1220
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.0472099781036377,
      "learning_rate": 4.4059119010819164e-05,
      "loss": 1.7692,
      "step": 1230
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9075871109962463,
      "learning_rate": 4.401081916537868e-05,
      "loss": 1.7961,
      "step": 1240
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1410274505615234,
      "learning_rate": 4.396251931993818e-05,
      "loss": 1.839,
      "step": 1250
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8957542777061462,
      "learning_rate": 4.3914219474497685e-05,
      "loss": 1.8662,
      "step": 1260
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0558130741119385,
      "learning_rate": 4.386591962905719e-05,
      "loss": 1.8214,
      "step": 1270
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.150748610496521,
      "learning_rate": 4.381761978361669e-05,
      "loss": 1.8825,
      "step": 1280
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9480321407318115,
      "learning_rate": 4.37693199381762e-05,
      "loss": 1.8803,
      "step": 1290
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6620209217071533,
      "learning_rate": 4.3721020092735707e-05,
      "loss": 1.9995,
      "step": 1300
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.8581347465515137,
      "learning_rate": 4.3672720247295214e-05,
      "loss": 1.881,
      "step": 1310
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.8386088609695435,
      "learning_rate": 4.3624420401854714e-05,
      "loss": 1.9126,
      "step": 1320
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4528829753398895,
      "learning_rate": 4.357612055641422e-05,
      "loss": 1.8414,
      "step": 1330
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4300568699836731,
      "learning_rate": 4.352782071097373e-05,
      "loss": 1.9868,
      "step": 1340
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5541147589683533,
      "learning_rate": 4.347952086553323e-05,
      "loss": 1.9959,
      "step": 1350
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.988089919090271,
      "learning_rate": 4.3431221020092735e-05,
      "loss": 1.8864,
      "step": 1360
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.44844138622283936,
      "learning_rate": 4.338292117465224e-05,
      "loss": 1.8255,
      "step": 1370
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1354286670684814,
      "learning_rate": 4.333462132921175e-05,
      "loss": 1.9286,
      "step": 1380
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4958421289920807,
      "learning_rate": 4.328632148377125e-05,
      "loss": 1.7854,
      "step": 1390
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1844662427902222,
      "learning_rate": 4.3238021638330764e-05,
      "loss": 1.7614,
      "step": 1400
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8516061902046204,
      "learning_rate": 4.3189721792890264e-05,
      "loss": 1.8272,
      "step": 1410
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.6150354146957397,
      "learning_rate": 4.314142194744977e-05,
      "loss": 1.8185,
      "step": 1420
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.006583333015442,
      "learning_rate": 4.309312210200928e-05,
      "loss": 1.73,
      "step": 1430
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.7553976774215698,
      "learning_rate": 4.304482225656878e-05,
      "loss": 1.6802,
      "step": 1440
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3219590187072754,
      "learning_rate": 4.2996522411128286e-05,
      "loss": 1.7123,
      "step": 1450
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6660901308059692,
      "learning_rate": 4.294822256568779e-05,
      "loss": 1.8724,
      "step": 1460
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4473734498023987,
      "learning_rate": 4.28999227202473e-05,
      "loss": 1.8663,
      "step": 1470
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9502598643302917,
      "learning_rate": 4.28516228748068e-05,
      "loss": 1.8305,
      "step": 1480
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2205435037612915,
      "learning_rate": 4.280332302936631e-05,
      "loss": 1.8776,
      "step": 1490
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7307064533233643,
      "learning_rate": 4.2755023183925814e-05,
      "loss": 1.8637,
      "step": 1500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8050814867019653,
      "learning_rate": 4.270672333848532e-05,
      "loss": 1.9022,
      "step": 1510
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9130234718322754,
      "learning_rate": 4.265842349304482e-05,
      "loss": 1.6843,
      "step": 1520
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7025760412216187,
      "learning_rate": 4.261012364760433e-05,
      "loss": 1.7067,
      "step": 1530
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.6252217292785645,
      "learning_rate": 4.2561823802163836e-05,
      "loss": 1.8797,
      "step": 1540
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.0501272678375244,
      "learning_rate": 4.2513523956723336e-05,
      "loss": 1.8252,
      "step": 1550
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1289424896240234,
      "learning_rate": 4.246522411128285e-05,
      "loss": 1.8476,
      "step": 1560
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.428490161895752,
      "learning_rate": 4.241692426584235e-05,
      "loss": 1.7805,
      "step": 1570
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1264950037002563,
      "learning_rate": 4.236862442040186e-05,
      "loss": 1.8558,
      "step": 1580
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4132430851459503,
      "learning_rate": 4.2320324574961365e-05,
      "loss": 1.8192,
      "step": 1590
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0534638166427612,
      "learning_rate": 4.2272024729520865e-05,
      "loss": 1.8768,
      "step": 1600
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0679142475128174,
      "learning_rate": 4.222372488408037e-05,
      "loss": 1.7732,
      "step": 1610
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6133691668510437,
      "learning_rate": 4.217542503863988e-05,
      "loss": 2.0537,
      "step": 1620
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0526880025863647,
      "learning_rate": 4.2127125193199386e-05,
      "loss": 1.8988,
      "step": 1630
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.3005210161209106,
      "learning_rate": 4.2078825347758886e-05,
      "loss": 2.0216,
      "step": 1640
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.15906023979187,
      "learning_rate": 4.2030525502318393e-05,
      "loss": 1.8645,
      "step": 1650
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.106969118118286,
      "learning_rate": 4.19822256568779e-05,
      "loss": 1.8579,
      "step": 1660
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.241502046585083,
      "learning_rate": 4.193392581143741e-05,
      "loss": 1.8835,
      "step": 1670
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.5444122552871704,
      "learning_rate": 4.188562596599691e-05,
      "loss": 1.8114,
      "step": 1680
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6966911554336548,
      "learning_rate": 4.1837326120556415e-05,
      "loss": 1.7835,
      "step": 1690
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6813676953315735,
      "learning_rate": 4.178902627511592e-05,
      "loss": 1.6924,
      "step": 1700
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5313875675201416,
      "learning_rate": 4.174072642967542e-05,
      "loss": 1.8381,
      "step": 1710
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.47681736946105957,
      "learning_rate": 4.1692426584234936e-05,
      "loss": 1.8464,
      "step": 1720
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6337480545043945,
      "learning_rate": 4.1644126738794437e-05,
      "loss": 2.0357,
      "step": 1730
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.663503885269165,
      "learning_rate": 4.1595826893353944e-05,
      "loss": 1.7534,
      "step": 1740
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7457711696624756,
      "learning_rate": 4.154752704791345e-05,
      "loss": 1.8023,
      "step": 1750
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4849100112915039,
      "learning_rate": 4.149922720247296e-05,
      "loss": 1.7419,
      "step": 1760
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6464724540710449,
      "learning_rate": 4.145092735703246e-05,
      "loss": 1.7903,
      "step": 1770
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7908340692520142,
      "learning_rate": 4.1402627511591965e-05,
      "loss": 1.9191,
      "step": 1780
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.015866756439209,
      "learning_rate": 4.135432766615147e-05,
      "loss": 1.7994,
      "step": 1790
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.152036428451538,
      "learning_rate": 4.130602782071097e-05,
      "loss": 1.8829,
      "step": 1800
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.43474769592285156,
      "learning_rate": 4.125772797527048e-05,
      "loss": 1.8151,
      "step": 1810
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9778577089309692,
      "learning_rate": 4.120942812982999e-05,
      "loss": 1.7844,
      "step": 1820
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5672020316123962,
      "learning_rate": 4.1161128284389494e-05,
      "loss": 1.8273,
      "step": 1830
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.109671711921692,
      "learning_rate": 4.1112828438948994e-05,
      "loss": 1.6775,
      "step": 1840
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.252925395965576,
      "learning_rate": 4.10645285935085e-05,
      "loss": 1.8812,
      "step": 1850
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5878448486328125,
      "learning_rate": 4.101622874806801e-05,
      "loss": 1.9716,
      "step": 1860
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9286821484565735,
      "learning_rate": 4.096792890262751e-05,
      "loss": 1.7045,
      "step": 1870
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8229918479919434,
      "learning_rate": 4.091962905718702e-05,
      "loss": 1.799,
      "step": 1880
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.9274275302886963,
      "learning_rate": 4.087132921174652e-05,
      "loss": 1.7598,
      "step": 1890
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0780739784240723,
      "learning_rate": 4.082302936630603e-05,
      "loss": 1.7376,
      "step": 1900
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.099790334701538,
      "learning_rate": 4.077472952086554e-05,
      "loss": 1.6825,
      "step": 1910
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1417824029922485,
      "learning_rate": 4.0726429675425044e-05,
      "loss": 2.0257,
      "step": 1920
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1119027137756348,
      "learning_rate": 4.0678129829984544e-05,
      "loss": 1.8098,
      "step": 1930
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.386387348175049,
      "learning_rate": 4.062982998454405e-05,
      "loss": 1.6828,
      "step": 1940
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.453120708465576,
      "learning_rate": 4.058153013910356e-05,
      "loss": 1.8219,
      "step": 1950
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8465881943702698,
      "learning_rate": 4.053323029366306e-05,
      "loss": 1.8619,
      "step": 1960
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1503010988235474,
      "learning_rate": 4.0484930448222566e-05,
      "loss": 1.8192,
      "step": 1970
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8697370290756226,
      "learning_rate": 4.043663060278207e-05,
      "loss": 1.8505,
      "step": 1980
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3689739406108856,
      "learning_rate": 4.038833075734158e-05,
      "loss": 1.866,
      "step": 1990
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8348159790039062,
      "learning_rate": 4.034003091190108e-05,
      "loss": 1.8059,
      "step": 2000
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.4034963846206665,
      "learning_rate": 4.0291731066460594e-05,
      "loss": 1.8151,
      "step": 2010
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5273447036743164,
      "learning_rate": 4.0243431221020095e-05,
      "loss": 1.8187,
      "step": 2020
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.160610675811768,
      "learning_rate": 4.0195131375579595e-05,
      "loss": 1.8112,
      "step": 2030
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8668794631958008,
      "learning_rate": 4.014683153013911e-05,
      "loss": 1.7477,
      "step": 2040
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0176182985305786,
      "learning_rate": 4.009853168469861e-05,
      "loss": 1.6992,
      "step": 2050
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8649264574050903,
      "learning_rate": 4.0050231839258116e-05,
      "loss": 1.6863,
      "step": 2060
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0502829551696777,
      "learning_rate": 4.000193199381762e-05,
      "loss": 1.8828,
      "step": 2070
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6809211373329163,
      "learning_rate": 3.995363214837713e-05,
      "loss": 1.8368,
      "step": 2080
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.41476327180862427,
      "learning_rate": 3.990533230293663e-05,
      "loss": 1.6946,
      "step": 2090
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.02921724319458,
      "learning_rate": 3.985703245749614e-05,
      "loss": 1.7072,
      "step": 2100
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6393416523933411,
      "learning_rate": 3.9808732612055645e-05,
      "loss": 1.9123,
      "step": 2110
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6558786630630493,
      "learning_rate": 3.9760432766615145e-05,
      "loss": 1.783,
      "step": 2120
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7637156844139099,
      "learning_rate": 3.971213292117465e-05,
      "loss": 1.7711,
      "step": 2130
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7332802414894104,
      "learning_rate": 3.966383307573416e-05,
      "loss": 1.8252,
      "step": 2140
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.468736171722412,
      "learning_rate": 3.9615533230293666e-05,
      "loss": 1.9375,
      "step": 2150
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.145315170288086,
      "learning_rate": 3.956723338485317e-05,
      "loss": 1.8586,
      "step": 2160
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7055745124816895,
      "learning_rate": 3.951893353941268e-05,
      "loss": 1.9332,
      "step": 2170
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1058677434921265,
      "learning_rate": 3.947063369397218e-05,
      "loss": 1.9261,
      "step": 2180
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.9627323150634766,
      "learning_rate": 3.942233384853168e-05,
      "loss": 1.9258,
      "step": 2190
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3420052528381348,
      "learning_rate": 3.9374034003091195e-05,
      "loss": 1.7651,
      "step": 2200
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.7038748264312744,
      "learning_rate": 3.9325734157650695e-05,
      "loss": 1.7669,
      "step": 2210
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4321475923061371,
      "learning_rate": 3.92774343122102e-05,
      "loss": 1.8237,
      "step": 2220
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9415912628173828,
      "learning_rate": 3.922913446676971e-05,
      "loss": 1.8146,
      "step": 2230
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.773375928401947,
      "learning_rate": 3.9180834621329217e-05,
      "loss": 1.7983,
      "step": 2240
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8704792261123657,
      "learning_rate": 3.913253477588872e-05,
      "loss": 1.8185,
      "step": 2250
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5485180616378784,
      "learning_rate": 3.9084234930448224e-05,
      "loss": 1.824,
      "step": 2260
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8028042316436768,
      "learning_rate": 3.903593508500773e-05,
      "loss": 1.8752,
      "step": 2270
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.35692086815834045,
      "learning_rate": 3.898763523956723e-05,
      "loss": 1.7966,
      "step": 2280
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7245436906814575,
      "learning_rate": 3.893933539412674e-05,
      "loss": 1.8577,
      "step": 2290
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9818335771560669,
      "learning_rate": 3.8891035548686246e-05,
      "loss": 1.7453,
      "step": 2300
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7878914475440979,
      "learning_rate": 3.884273570324575e-05,
      "loss": 1.7672,
      "step": 2310
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.045269250869751,
      "learning_rate": 3.879443585780525e-05,
      "loss": 1.7471,
      "step": 2320
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6717909574508667,
      "learning_rate": 3.874613601236477e-05,
      "loss": 1.7787,
      "step": 2330
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.37859562039375305,
      "learning_rate": 3.869783616692427e-05,
      "loss": 1.8621,
      "step": 2340
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9239323139190674,
      "learning_rate": 3.8649536321483774e-05,
      "loss": 1.6758,
      "step": 2350
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7892282009124756,
      "learning_rate": 3.860123647604328e-05,
      "loss": 1.8865,
      "step": 2360
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7261013388633728,
      "learning_rate": 3.855293663060278e-05,
      "loss": 1.6659,
      "step": 2370
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.48256292939186096,
      "learning_rate": 3.850463678516229e-05,
      "loss": 1.8761,
      "step": 2380
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6421370506286621,
      "learning_rate": 3.8456336939721796e-05,
      "loss": 1.7855,
      "step": 2390
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1762555837631226,
      "learning_rate": 3.84080370942813e-05,
      "loss": 1.8811,
      "step": 2400
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0394682884216309,
      "learning_rate": 3.83597372488408e-05,
      "loss": 1.8293,
      "step": 2410
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.963985800743103,
      "learning_rate": 3.831143740340031e-05,
      "loss": 1.9028,
      "step": 2420
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.504577398300171,
      "learning_rate": 3.826313755795982e-05,
      "loss": 1.8222,
      "step": 2430
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8404446840286255,
      "learning_rate": 3.821483771251932e-05,
      "loss": 1.8268,
      "step": 2440
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9568771719932556,
      "learning_rate": 3.8166537867078825e-05,
      "loss": 1.7163,
      "step": 2450
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.203711986541748,
      "learning_rate": 3.811823802163833e-05,
      "loss": 1.9592,
      "step": 2460
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3354543149471283,
      "learning_rate": 3.806993817619784e-05,
      "loss": 1.7081,
      "step": 2470
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8402994871139526,
      "learning_rate": 3.802163833075734e-05,
      "loss": 1.81,
      "step": 2480
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6286702156066895,
      "learning_rate": 3.797333848531685e-05,
      "loss": 1.8216,
      "step": 2490
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7844212651252747,
      "learning_rate": 3.792503863987635e-05,
      "loss": 1.7918,
      "step": 2500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8135498762130737,
      "learning_rate": 3.787673879443586e-05,
      "loss": 1.6821,
      "step": 2510
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5981337428092957,
      "learning_rate": 3.782843894899537e-05,
      "loss": 1.6844,
      "step": 2520
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.366692066192627,
      "learning_rate": 3.778013910355487e-05,
      "loss": 1.9301,
      "step": 2530
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7565180063247681,
      "learning_rate": 3.7731839258114375e-05,
      "loss": 1.8272,
      "step": 2540
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9990636706352234,
      "learning_rate": 3.768353941267388e-05,
      "loss": 1.7462,
      "step": 2550
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.1884407997131348,
      "learning_rate": 3.763523956723339e-05,
      "loss": 1.8645,
      "step": 2560
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4558373987674713,
      "learning_rate": 3.758693972179289e-05,
      "loss": 1.7834,
      "step": 2570
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5786819458007812,
      "learning_rate": 3.7538639876352396e-05,
      "loss": 1.6659,
      "step": 2580
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.563191294670105,
      "learning_rate": 3.7490340030911904e-05,
      "loss": 1.7599,
      "step": 2590
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.027634382247925,
      "learning_rate": 3.744204018547141e-05,
      "loss": 1.8595,
      "step": 2600
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2399873733520508,
      "learning_rate": 3.739374034003091e-05,
      "loss": 1.7651,
      "step": 2610
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.32527756690979,
      "learning_rate": 3.734544049459042e-05,
      "loss": 1.8126,
      "step": 2620
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9635913372039795,
      "learning_rate": 3.7297140649149925e-05,
      "loss": 1.7085,
      "step": 2630
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.187320709228516,
      "learning_rate": 3.7248840803709425e-05,
      "loss": 1.9124,
      "step": 2640
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9140391945838928,
      "learning_rate": 3.720054095826894e-05,
      "loss": 1.6224,
      "step": 2650
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.48086467385292053,
      "learning_rate": 3.715224111282844e-05,
      "loss": 1.9388,
      "step": 2660
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8960702419281006,
      "learning_rate": 3.710394126738795e-05,
      "loss": 1.8575,
      "step": 2670
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8659117221832275,
      "learning_rate": 3.7055641421947454e-05,
      "loss": 1.7388,
      "step": 2680
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3962685763835907,
      "learning_rate": 3.7007341576506954e-05,
      "loss": 1.8231,
      "step": 2690
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5198379755020142,
      "learning_rate": 3.695904173106646e-05,
      "loss": 1.87,
      "step": 2700
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.581883668899536,
      "learning_rate": 3.691074188562597e-05,
      "loss": 1.8785,
      "step": 2710
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8840017914772034,
      "learning_rate": 3.6862442040185475e-05,
      "loss": 1.7123,
      "step": 2720
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.104396104812622,
      "learning_rate": 3.6814142194744976e-05,
      "loss": 1.9259,
      "step": 2730
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5784290432929993,
      "learning_rate": 3.676584234930448e-05,
      "loss": 1.934,
      "step": 2740
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1224746704101562,
      "learning_rate": 3.671754250386399e-05,
      "loss": 1.7622,
      "step": 2750
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.382800817489624,
      "learning_rate": 3.66692426584235e-05,
      "loss": 1.8306,
      "step": 2760
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6302035450935364,
      "learning_rate": 3.6620942812983e-05,
      "loss": 1.77,
      "step": 2770
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6275874972343445,
      "learning_rate": 3.6572642967542504e-05,
      "loss": 1.7976,
      "step": 2780
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.785613477230072,
      "learning_rate": 3.652434312210201e-05,
      "loss": 1.7915,
      "step": 2790
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.3767929077148438,
      "learning_rate": 3.647604327666151e-05,
      "loss": 1.8668,
      "step": 2800
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7818799018859863,
      "learning_rate": 3.6427743431221026e-05,
      "loss": 1.7675,
      "step": 2810
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.2796950340270996,
      "learning_rate": 3.6379443585780526e-05,
      "loss": 1.8853,
      "step": 2820
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8900995850563049,
      "learning_rate": 3.633114374034003e-05,
      "loss": 1.9339,
      "step": 2830
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9345669746398926,
      "learning_rate": 3.628284389489954e-05,
      "loss": 1.7314,
      "step": 2840
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.370170921087265,
      "learning_rate": 3.623454404945905e-05,
      "loss": 1.6981,
      "step": 2850
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1430089473724365,
      "learning_rate": 3.618624420401855e-05,
      "loss": 1.8659,
      "step": 2860
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7414578795433044,
      "learning_rate": 3.6137944358578054e-05,
      "loss": 1.852,
      "step": 2870
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.026833415031433,
      "learning_rate": 3.608964451313756e-05,
      "loss": 1.7855,
      "step": 2880
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6122148036956787,
      "learning_rate": 3.604134466769706e-05,
      "loss": 1.9145,
      "step": 2890
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.440323829650879,
      "learning_rate": 3.599304482225657e-05,
      "loss": 1.7095,
      "step": 2900
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4551483690738678,
      "learning_rate": 3.5944744976816076e-05,
      "loss": 1.7227,
      "step": 2910
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8782498836517334,
      "learning_rate": 3.589644513137558e-05,
      "loss": 1.8005,
      "step": 2920
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.0005203485488892,
      "learning_rate": 3.5848145285935083e-05,
      "loss": 1.7986,
      "step": 2930
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.921225368976593,
      "learning_rate": 3.57998454404946e-05,
      "loss": 1.7822,
      "step": 2940
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3968363106250763,
      "learning_rate": 3.57515455950541e-05,
      "loss": 1.7644,
      "step": 2950
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.0696377754211426,
      "learning_rate": 3.57032457496136e-05,
      "loss": 1.7526,
      "step": 2960
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.631361484527588,
      "learning_rate": 3.565494590417311e-05,
      "loss": 1.8365,
      "step": 2970
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5819266438484192,
      "learning_rate": 3.560664605873261e-05,
      "loss": 1.7419,
      "step": 2980
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0323759317398071,
      "learning_rate": 3.555834621329212e-05,
      "loss": 1.9456,
      "step": 2990
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.4471527338027954,
      "learning_rate": 3.5510046367851626e-05,
      "loss": 2.0766,
      "step": 3000
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7657753825187683,
      "learning_rate": 3.546174652241113e-05,
      "loss": 1.7899,
      "step": 3010
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.4254021644592285,
      "learning_rate": 3.5413446676970634e-05,
      "loss": 1.8124,
      "step": 3020
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.46053752303123474,
      "learning_rate": 3.536514683153014e-05,
      "loss": 1.7275,
      "step": 3030
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4550020694732666,
      "learning_rate": 3.531684698608965e-05,
      "loss": 1.7858,
      "step": 3040
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.628485918045044,
      "learning_rate": 3.526854714064915e-05,
      "loss": 1.6682,
      "step": 3050
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8171994090080261,
      "learning_rate": 3.5220247295208655e-05,
      "loss": 1.7631,
      "step": 3060
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8917094469070435,
      "learning_rate": 3.517194744976816e-05,
      "loss": 1.7833,
      "step": 3070
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.454637885093689,
      "learning_rate": 3.512364760432767e-05,
      "loss": 1.7374,
      "step": 3080
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6259910464286804,
      "learning_rate": 3.507534775888717e-05,
      "loss": 1.9705,
      "step": 3090
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7923489809036255,
      "learning_rate": 3.5027047913446684e-05,
      "loss": 1.7234,
      "step": 3100
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6480559706687927,
      "learning_rate": 3.4978748068006184e-05,
      "loss": 1.818,
      "step": 3110
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.2733462154865265,
      "learning_rate": 3.4930448222565684e-05,
      "loss": 1.8936,
      "step": 3120
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9683840274810791,
      "learning_rate": 3.48821483771252e-05,
      "loss": 1.7745,
      "step": 3130
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.018662214279175,
      "learning_rate": 3.48338485316847e-05,
      "loss": 1.7077,
      "step": 3140
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8062774538993835,
      "learning_rate": 3.4785548686244205e-05,
      "loss": 1.7579,
      "step": 3150
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0894224643707275,
      "learning_rate": 3.473724884080371e-05,
      "loss": 1.6957,
      "step": 3160
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.2768714427948,
      "learning_rate": 3.468894899536322e-05,
      "loss": 1.7148,
      "step": 3170
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2916234731674194,
      "learning_rate": 3.464064914992272e-05,
      "loss": 1.9512,
      "step": 3180
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.51400887966156,
      "learning_rate": 3.459234930448223e-05,
      "loss": 1.6899,
      "step": 3190
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5362010598182678,
      "learning_rate": 3.4544049459041734e-05,
      "loss": 1.7582,
      "step": 3200
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7654790282249451,
      "learning_rate": 3.4495749613601234e-05,
      "loss": 1.7575,
      "step": 3210
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5894935131072998,
      "learning_rate": 3.444744976816074e-05,
      "loss": 1.7015,
      "step": 3220
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0262091159820557,
      "learning_rate": 3.439914992272025e-05,
      "loss": 1.7662,
      "step": 3230
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7765905261039734,
      "learning_rate": 3.4350850077279756e-05,
      "loss": 1.7817,
      "step": 3240
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1859407424926758,
      "learning_rate": 3.4302550231839256e-05,
      "loss": 2.156,
      "step": 3250
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6450164914131165,
      "learning_rate": 3.425425038639877e-05,
      "loss": 1.7743,
      "step": 3260
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9749343991279602,
      "learning_rate": 3.420595054095827e-05,
      "loss": 1.782,
      "step": 3270
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1399543285369873,
      "learning_rate": 3.415765069551777e-05,
      "loss": 1.9851,
      "step": 3280
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7739711999893188,
      "learning_rate": 3.4109350850077284e-05,
      "loss": 1.843,
      "step": 3290
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7611562609672546,
      "learning_rate": 3.4061051004636785e-05,
      "loss": 1.7044,
      "step": 3300
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6706411838531494,
      "learning_rate": 3.401275115919629e-05,
      "loss": 1.8348,
      "step": 3310
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2888950109481812,
      "learning_rate": 3.39644513137558e-05,
      "loss": 1.8297,
      "step": 3320
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1088495254516602,
      "learning_rate": 3.3916151468315306e-05,
      "loss": 1.7891,
      "step": 3330
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9296287894248962,
      "learning_rate": 3.3867851622874806e-05,
      "loss": 1.8119,
      "step": 3340
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.8869940042495728,
      "learning_rate": 3.381955177743431e-05,
      "loss": 1.8464,
      "step": 3350
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.42344266176223755,
      "learning_rate": 3.377125193199382e-05,
      "loss": 1.6742,
      "step": 3360
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.608734667301178,
      "learning_rate": 3.372295208655332e-05,
      "loss": 1.7798,
      "step": 3370
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4979178309440613,
      "learning_rate": 3.367465224111283e-05,
      "loss": 1.7357,
      "step": 3380
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5495544672012329,
      "learning_rate": 3.3626352395672335e-05,
      "loss": 1.902,
      "step": 3390
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4297991394996643,
      "learning_rate": 3.357805255023184e-05,
      "loss": 1.7505,
      "step": 3400
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5591256618499756,
      "learning_rate": 3.352975270479134e-05,
      "loss": 1.8224,
      "step": 3410
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.248734951019287,
      "learning_rate": 3.3481452859350856e-05,
      "loss": 1.868,
      "step": 3420
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.4817298650741577,
      "learning_rate": 3.3433153013910356e-05,
      "loss": 1.7097,
      "step": 3430
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.256889820098877,
      "learning_rate": 3.3384853168469863e-05,
      "loss": 1.8237,
      "step": 3440
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0976767539978027,
      "learning_rate": 3.333655332302937e-05,
      "loss": 1.7375,
      "step": 3450
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5341070890426636,
      "learning_rate": 3.328825347758887e-05,
      "loss": 1.715,
      "step": 3460
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6338204145431519,
      "learning_rate": 3.323995363214838e-05,
      "loss": 1.7571,
      "step": 3470
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.941305935382843,
      "learning_rate": 3.3191653786707885e-05,
      "loss": 1.7247,
      "step": 3480
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2138581275939941,
      "learning_rate": 3.314335394126739e-05,
      "loss": 1.788,
      "step": 3490
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.5502521991729736,
      "learning_rate": 3.309505409582689e-05,
      "loss": 1.7545,
      "step": 3500
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0026100873947144,
      "learning_rate": 3.30467542503864e-05,
      "loss": 1.8997,
      "step": 3510
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9027469158172607,
      "learning_rate": 3.2998454404945907e-05,
      "loss": 1.9463,
      "step": 3520
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3259679973125458,
      "learning_rate": 3.295015455950541e-05,
      "loss": 1.902,
      "step": 3530
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8192416429519653,
      "learning_rate": 3.2901854714064914e-05,
      "loss": 1.8766,
      "step": 3540
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8802549242973328,
      "learning_rate": 3.285355486862442e-05,
      "loss": 1.8169,
      "step": 3550
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8120145797729492,
      "learning_rate": 3.280525502318393e-05,
      "loss": 1.8718,
      "step": 3560
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7746514081954956,
      "learning_rate": 3.275695517774343e-05,
      "loss": 1.7777,
      "step": 3570
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7262881398200989,
      "learning_rate": 3.270865533230294e-05,
      "loss": 1.6731,
      "step": 3580
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.0046117305755615,
      "learning_rate": 3.266035548686244e-05,
      "loss": 1.721,
      "step": 3590
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9441021084785461,
      "learning_rate": 3.261205564142195e-05,
      "loss": 1.6578,
      "step": 3600
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9893788695335388,
      "learning_rate": 3.256375579598146e-05,
      "loss": 1.8768,
      "step": 3610
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0194084644317627,
      "learning_rate": 3.251545595054096e-05,
      "loss": 1.7999,
      "step": 3620
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.96236652135849,
      "learning_rate": 3.2467156105100464e-05,
      "loss": 1.7279,
      "step": 3630
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0938498973846436,
      "learning_rate": 3.241885625965997e-05,
      "loss": 1.7991,
      "step": 3640
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9796074628829956,
      "learning_rate": 3.237055641421948e-05,
      "loss": 1.7909,
      "step": 3650
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7783299088478088,
      "learning_rate": 3.232225656877898e-05,
      "loss": 1.704,
      "step": 3660
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8769110441207886,
      "learning_rate": 3.2273956723338486e-05,
      "loss": 1.8498,
      "step": 3670
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9211007356643677,
      "learning_rate": 3.222565687789799e-05,
      "loss": 1.8643,
      "step": 3680
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.5204646587371826,
      "learning_rate": 3.21773570324575e-05,
      "loss": 1.897,
      "step": 3690
    },
    {
      "epoch": 0.71,
      "grad_norm": 4.8912835121154785,
      "learning_rate": 3.2129057187017e-05,
      "loss": 1.7734,
      "step": 3700
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.47921139001846313,
      "learning_rate": 3.208075734157651e-05,
      "loss": 1.8719,
      "step": 3710
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6309918761253357,
      "learning_rate": 3.2032457496136014e-05,
      "loss": 1.8806,
      "step": 3720
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7219112515449524,
      "learning_rate": 3.1984157650695515e-05,
      "loss": 1.7691,
      "step": 3730
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5935982465744019,
      "learning_rate": 3.193585780525503e-05,
      "loss": 1.8089,
      "step": 3740
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.34590378403663635,
      "learning_rate": 3.188755795981453e-05,
      "loss": 1.801,
      "step": 3750
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6960171461105347,
      "learning_rate": 3.1839258114374036e-05,
      "loss": 1.8473,
      "step": 3760
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0035260915756226,
      "learning_rate": 3.179095826893354e-05,
      "loss": 1.7403,
      "step": 3770
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7509918212890625,
      "learning_rate": 3.174265842349305e-05,
      "loss": 1.7007,
      "step": 3780
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9127028584480286,
      "learning_rate": 3.169435857805255e-05,
      "loss": 1.8226,
      "step": 3790
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.66764497756958,
      "learning_rate": 3.164605873261206e-05,
      "loss": 1.743,
      "step": 3800
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9251821041107178,
      "learning_rate": 3.1597758887171565e-05,
      "loss": 1.6502,
      "step": 3810
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8771219253540039,
      "learning_rate": 3.1549459041731065e-05,
      "loss": 1.7713,
      "step": 3820
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9407772421836853,
      "learning_rate": 3.150115919629057e-05,
      "loss": 1.8042,
      "step": 3830
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7783704996109009,
      "learning_rate": 3.145285935085008e-05,
      "loss": 1.7954,
      "step": 3840
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.736393928527832,
      "learning_rate": 3.1404559505409586e-05,
      "loss": 1.7223,
      "step": 3850
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7629534602165222,
      "learning_rate": 3.1356259659969086e-05,
      "loss": 1.8027,
      "step": 3860
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.194239616394043,
      "learning_rate": 3.1307959814528594e-05,
      "loss": 1.8298,
      "step": 3870
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1051857471466064,
      "learning_rate": 3.12596599690881e-05,
      "loss": 1.6658,
      "step": 3880
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9854755401611328,
      "learning_rate": 3.12113601236476e-05,
      "loss": 1.7692,
      "step": 3890
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.067099690437317,
      "learning_rate": 3.1163060278207115e-05,
      "loss": 1.6873,
      "step": 3900
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.248687267303467,
      "learning_rate": 3.1114760432766615e-05,
      "loss": 1.7371,
      "step": 3910
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6698527336120605,
      "learning_rate": 3.106646058732612e-05,
      "loss": 1.8115,
      "step": 3920
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3519132435321808,
      "learning_rate": 3.101816074188563e-05,
      "loss": 1.8271,
      "step": 3930
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.159604787826538,
      "learning_rate": 3.0969860896445136e-05,
      "loss": 1.8039,
      "step": 3940
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.002046585083008,
      "learning_rate": 3.092156105100464e-05,
      "loss": 1.6921,
      "step": 3950
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5919793844223022,
      "learning_rate": 3.0873261205564144e-05,
      "loss": 1.8587,
      "step": 3960
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.4690206050872803,
      "learning_rate": 3.082496136012365e-05,
      "loss": 1.8177,
      "step": 3970
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6867234706878662,
      "learning_rate": 3.077666151468315e-05,
      "loss": 1.6549,
      "step": 3980
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6077977418899536,
      "learning_rate": 3.072836166924266e-05,
      "loss": 1.743,
      "step": 3990
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.408031940460205,
      "learning_rate": 3.0680061823802165e-05,
      "loss": 1.7497,
      "step": 4000
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.2666159868240356,
      "learning_rate": 3.063176197836167e-05,
      "loss": 1.7999,
      "step": 4010
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1346065998077393,
      "learning_rate": 3.058346213292117e-05,
      "loss": 1.8521,
      "step": 4020
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.2625555992126465,
      "learning_rate": 3.0535162287480687e-05,
      "loss": 1.9468,
      "step": 4030
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.6718356609344482,
      "learning_rate": 3.0486862442040187e-05,
      "loss": 1.6345,
      "step": 4040
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1254067420959473,
      "learning_rate": 3.043856259659969e-05,
      "loss": 1.8366,
      "step": 4050
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.996619462966919,
      "learning_rate": 3.0390262751159198e-05,
      "loss": 1.899,
      "step": 4060
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8697918653488159,
      "learning_rate": 3.03419629057187e-05,
      "loss": 1.6787,
      "step": 4070
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.0703434944152832,
      "learning_rate": 3.0293663060278212e-05,
      "loss": 1.6988,
      "step": 4080
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.3613711595535278,
      "learning_rate": 3.0245363214837712e-05,
      "loss": 1.7819,
      "step": 4090
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.648961067199707,
      "learning_rate": 3.0197063369397223e-05,
      "loss": 1.7909,
      "step": 4100
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.164534568786621,
      "learning_rate": 3.0148763523956723e-05,
      "loss": 1.7612,
      "step": 4110
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2119975090026855,
      "learning_rate": 3.0100463678516227e-05,
      "loss": 1.7444,
      "step": 4120
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4958864450454712,
      "learning_rate": 3.0052163833075737e-05,
      "loss": 1.797,
      "step": 4130
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.565512776374817,
      "learning_rate": 3.0003863987635237e-05,
      "loss": 1.8413,
      "step": 4140
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.895157814025879,
      "learning_rate": 2.9955564142194748e-05,
      "loss": 1.7707,
      "step": 4150
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7454637289047241,
      "learning_rate": 2.990726429675425e-05,
      "loss": 1.8806,
      "step": 4160
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2903695106506348,
      "learning_rate": 2.985896445131376e-05,
      "loss": 1.8911,
      "step": 4170
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.40668386220932007,
      "learning_rate": 2.9810664605873262e-05,
      "loss": 1.8404,
      "step": 4180
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4692107141017914,
      "learning_rate": 2.976236476043277e-05,
      "loss": 1.6996,
      "step": 4190
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9305148124694824,
      "learning_rate": 2.9714064914992273e-05,
      "loss": 1.7239,
      "step": 4200
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.419952392578125,
      "learning_rate": 2.9665765069551777e-05,
      "loss": 2.0083,
      "step": 4210
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3166271448135376,
      "learning_rate": 2.9617465224111284e-05,
      "loss": 1.8958,
      "step": 4220
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5418872833251953,
      "learning_rate": 2.9569165378670788e-05,
      "loss": 1.861,
      "step": 4230
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8745366930961609,
      "learning_rate": 2.9520865533230298e-05,
      "loss": 1.8932,
      "step": 4240
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3760173320770264,
      "learning_rate": 2.94725656877898e-05,
      "loss": 1.838,
      "step": 4250
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3521155118942261,
      "learning_rate": 2.942426584234931e-05,
      "loss": 1.7544,
      "step": 4260
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3983619511127472,
      "learning_rate": 2.937596599690881e-05,
      "loss": 1.7936,
      "step": 4270
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9660288691520691,
      "learning_rate": 2.932766615146832e-05,
      "loss": 1.7979,
      "step": 4280
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.178480863571167,
      "learning_rate": 2.9279366306027823e-05,
      "loss": 1.7312,
      "step": 4290
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.40452834963798523,
      "learning_rate": 2.9231066460587324e-05,
      "loss": 1.7784,
      "step": 4300
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7592437267303467,
      "learning_rate": 2.9182766615146834e-05,
      "loss": 1.7992,
      "step": 4310
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.0766725540161133,
      "learning_rate": 2.9134466769706338e-05,
      "loss": 1.9092,
      "step": 4320
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.8504652380943298,
      "learning_rate": 2.9086166924265845e-05,
      "loss": 1.7282,
      "step": 4330
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9410026669502258,
      "learning_rate": 2.903786707882535e-05,
      "loss": 1.8655,
      "step": 4340
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7438737154006958,
      "learning_rate": 2.8989567233384856e-05,
      "loss": 1.9029,
      "step": 4350
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0939964056015015,
      "learning_rate": 2.894126738794436e-05,
      "loss": 1.9014,
      "step": 4360
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5141893029212952,
      "learning_rate": 2.8892967542503863e-05,
      "loss": 1.7589,
      "step": 4370
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.40310201048851013,
      "learning_rate": 2.884466769706337e-05,
      "loss": 1.8863,
      "step": 4380
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3073132038116455,
      "learning_rate": 2.8796367851622874e-05,
      "loss": 1.9176,
      "step": 4390
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1221649646759033,
      "learning_rate": 2.8748068006182384e-05,
      "loss": 1.9064,
      "step": 4400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.9058177471160889,
      "learning_rate": 2.8699768160741885e-05,
      "loss": 1.8948,
      "step": 4410
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1190804243087769,
      "learning_rate": 2.8651468315301395e-05,
      "loss": 1.7145,
      "step": 4420
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.9463432431221008,
      "learning_rate": 2.8603168469860895e-05,
      "loss": 1.6583,
      "step": 4430
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.759257435798645,
      "learning_rate": 2.8554868624420406e-05,
      "loss": 1.711,
      "step": 4440
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.1947062015533447,
      "learning_rate": 2.850656877897991e-05,
      "loss": 1.7367,
      "step": 4450
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.1869605779647827,
      "learning_rate": 2.845826893353941e-05,
      "loss": 1.8822,
      "step": 4460
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.8532469272613525,
      "learning_rate": 2.840996908809892e-05,
      "loss": 2.0063,
      "step": 4470
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8976095914840698,
      "learning_rate": 2.8361669242658424e-05,
      "loss": 1.7229,
      "step": 4480
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.7647833824157715,
      "learning_rate": 2.831336939721793e-05,
      "loss": 1.9365,
      "step": 4490
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3021470010280609,
      "learning_rate": 2.8265069551777435e-05,
      "loss": 1.9834,
      "step": 4500
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.563032627105713,
      "learning_rate": 2.8216769706336942e-05,
      "loss": 1.7558,
      "step": 4510
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9342589378356934,
      "learning_rate": 2.8168469860896446e-05,
      "loss": 1.8113,
      "step": 4520
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.1083544492721558,
      "learning_rate": 2.8120170015455956e-05,
      "loss": 1.7601,
      "step": 4530
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5953812003135681,
      "learning_rate": 2.8071870170015456e-05,
      "loss": 1.8603,
      "step": 4540
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.9482628107070923,
      "learning_rate": 2.802357032457496e-05,
      "loss": 1.7808,
      "step": 4550
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5629094839096069,
      "learning_rate": 2.797527047913447e-05,
      "loss": 1.9912,
      "step": 4560
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.6312754154205322,
      "learning_rate": 2.792697063369397e-05,
      "loss": 1.7446,
      "step": 4570
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5910216569900513,
      "learning_rate": 2.787867078825348e-05,
      "loss": 1.7067,
      "step": 4580
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6360446810722351,
      "learning_rate": 2.783037094281298e-05,
      "loss": 1.7813,
      "step": 4590
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.539537787437439,
      "learning_rate": 2.7782071097372492e-05,
      "loss": 1.8118,
      "step": 4600
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.2094404697418213,
      "learning_rate": 2.7733771251931996e-05,
      "loss": 1.9464,
      "step": 4610
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7720455527305603,
      "learning_rate": 2.7685471406491503e-05,
      "loss": 1.8653,
      "step": 4620
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.13388204574585,
      "learning_rate": 2.7637171561051007e-05,
      "loss": 1.8936,
      "step": 4630
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.5142600536346436,
      "learning_rate": 2.758887171561051e-05,
      "loss": 1.6587,
      "step": 4640
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5593554973602295,
      "learning_rate": 2.7540571870170017e-05,
      "loss": 1.585,
      "step": 4650
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3699125051498413,
      "learning_rate": 2.749227202472952e-05,
      "loss": 1.7116,
      "step": 4660
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4002012014389038,
      "learning_rate": 2.7443972179289028e-05,
      "loss": 1.7016,
      "step": 4670
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6842978000640869,
      "learning_rate": 2.7395672333848532e-05,
      "loss": 1.7018,
      "step": 4680
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7571304440498352,
      "learning_rate": 2.7347372488408042e-05,
      "loss": 1.7644,
      "step": 4690
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6967572569847107,
      "learning_rate": 2.7299072642967543e-05,
      "loss": 1.7105,
      "step": 4700
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8141378164291382,
      "learning_rate": 2.7250772797527046e-05,
      "loss": 1.8715,
      "step": 4710
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5446387529373169,
      "learning_rate": 2.7202472952086557e-05,
      "loss": 1.8615,
      "step": 4720
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6891428828239441,
      "learning_rate": 2.7154173106646057e-05,
      "loss": 1.7421,
      "step": 4730
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.3087947368621826,
      "learning_rate": 2.7105873261205568e-05,
      "loss": 1.8633,
      "step": 4740
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9120994806289673,
      "learning_rate": 2.705757341576507e-05,
      "loss": 1.9267,
      "step": 4750
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.3674354553222656,
      "learning_rate": 2.700927357032458e-05,
      "loss": 1.8173,
      "step": 4760
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6083394289016724,
      "learning_rate": 2.6960973724884082e-05,
      "loss": 1.6855,
      "step": 4770
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7593944668769836,
      "learning_rate": 2.691267387944359e-05,
      "loss": 1.6763,
      "step": 4780
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7499257922172546,
      "learning_rate": 2.6864374034003093e-05,
      "loss": 1.7196,
      "step": 4790
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.9418731331825256,
      "learning_rate": 2.6816074188562596e-05,
      "loss": 1.6667,
      "step": 4800
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0169302225112915,
      "learning_rate": 2.6767774343122104e-05,
      "loss": 1.6718,
      "step": 4810
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.7847115993499756,
      "learning_rate": 2.6719474497681607e-05,
      "loss": 1.8175,
      "step": 4820
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5184422135353088,
      "learning_rate": 2.6671174652241114e-05,
      "loss": 1.7209,
      "step": 4830
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1376874446868896,
      "learning_rate": 2.6622874806800618e-05,
      "loss": 1.7241,
      "step": 4840
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4426356554031372,
      "learning_rate": 2.657457496136013e-05,
      "loss": 1.8133,
      "step": 4850
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1113834381103516,
      "learning_rate": 2.652627511591963e-05,
      "loss": 1.758,
      "step": 4860
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.911383867263794,
      "learning_rate": 2.647797527047914e-05,
      "loss": 1.7981,
      "step": 4870
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.920925498008728,
      "learning_rate": 2.6429675425038643e-05,
      "loss": 1.8036,
      "step": 4880
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0456477403640747,
      "learning_rate": 2.6381375579598143e-05,
      "loss": 1.7858,
      "step": 4890
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2214597463607788,
      "learning_rate": 2.6333075734157654e-05,
      "loss": 1.9617,
      "step": 4900
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6581180095672607,
      "learning_rate": 2.6284775888717157e-05,
      "loss": 1.8636,
      "step": 4910
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6263030171394348,
      "learning_rate": 2.6236476043276665e-05,
      "loss": 1.8548,
      "step": 4920
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.9525907635688782,
      "learning_rate": 2.6188176197836168e-05,
      "loss": 1.8113,
      "step": 4930
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6914472579956055,
      "learning_rate": 2.6139876352395675e-05,
      "loss": 1.6809,
      "step": 4940
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8786447644233704,
      "learning_rate": 2.609157650695518e-05,
      "loss": 1.875,
      "step": 4950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3589678704738617,
      "learning_rate": 2.6043276661514683e-05,
      "loss": 1.8407,
      "step": 4960
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.952319324016571,
      "learning_rate": 2.599497681607419e-05,
      "loss": 1.7629,
      "step": 4970
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4983777105808258,
      "learning_rate": 2.5946676970633694e-05,
      "loss": 1.6896,
      "step": 4980
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5099972486495972,
      "learning_rate": 2.58983771251932e-05,
      "loss": 1.8182,
      "step": 4990
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.3619416952133179,
      "learning_rate": 2.5850077279752704e-05,
      "loss": 1.7416,
      "step": 5000
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.9676586985588074,
      "learning_rate": 2.5801777434312215e-05,
      "loss": 1.7515,
      "step": 5010
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7753196954727173,
      "learning_rate": 2.5753477588871715e-05,
      "loss": 1.7174,
      "step": 5020
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8058635592460632,
      "learning_rate": 2.5705177743431226e-05,
      "loss": 1.7244,
      "step": 5030
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.16617751121521,
      "learning_rate": 2.565687789799073e-05,
      "loss": 1.7812,
      "step": 5040
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.280645489692688,
      "learning_rate": 2.560857805255023e-05,
      "loss": 1.6776,
      "step": 5050
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9854001998901367,
      "learning_rate": 2.556027820710974e-05,
      "loss": 1.742,
      "step": 5060
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.122049331665039,
      "learning_rate": 2.5511978361669244e-05,
      "loss": 1.8242,
      "step": 5070
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8811620473861694,
      "learning_rate": 2.546367851622875e-05,
      "loss": 1.8175,
      "step": 5080
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8039363622665405,
      "learning_rate": 2.5415378670788255e-05,
      "loss": 1.8099,
      "step": 5090
    },
    {
      "epoch": 0.99,
      "grad_norm": 5.1862711906433105,
      "learning_rate": 2.536707882534776e-05,
      "loss": 1.7665,
      "step": 5100
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.330246686935425,
      "learning_rate": 2.5318778979907265e-05,
      "loss": 1.8364,
      "step": 5110
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.0044752359390259,
      "learning_rate": 2.5270479134466772e-05,
      "loss": 1.7742,
      "step": 5120
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2225233316421509,
      "learning_rate": 2.5222179289026276e-05,
      "loss": 1.7107,
      "step": 5130
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6001816987991333,
      "learning_rate": 2.517387944358578e-05,
      "loss": 1.9283,
      "step": 5140
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.864374041557312,
      "learning_rate": 2.5125579598145287e-05,
      "loss": 1.8675,
      "step": 5150
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.4388521909713745,
      "learning_rate": 2.507727975270479e-05,
      "loss": 1.7327,
      "step": 5160
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6993513703346252,
      "learning_rate": 2.50289799072643e-05,
      "loss": 1.6755,
      "step": 5170
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.821923017501831,
      "eval_runtime": 1275.5055,
      "eval_samples_per_second": 8.116,
      "eval_steps_per_second": 1.014,
      "step": 5176
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5367766618728638,
      "learning_rate": 2.49806800618238e-05,
      "loss": 1.6642,
      "step": 5180
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6921691298484802,
      "learning_rate": 2.493238021638331e-05,
      "loss": 1.9217,
      "step": 5190
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6136415004730225,
      "learning_rate": 2.4884080370942815e-05,
      "loss": 1.7411,
      "step": 5200
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.5606710314750671,
      "learning_rate": 2.483578052550232e-05,
      "loss": 1.7245,
      "step": 5210
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6710585355758667,
      "learning_rate": 2.4787480680061826e-05,
      "loss": 1.8929,
      "step": 5220
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.8460647463798523,
      "learning_rate": 2.473918083462133e-05,
      "loss": 1.8083,
      "step": 5230
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.8547000288963318,
      "learning_rate": 2.4690880989180837e-05,
      "loss": 1.6903,
      "step": 5240
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.712891697883606,
      "learning_rate": 2.4642581143740344e-05,
      "loss": 1.8033,
      "step": 5250
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.8080639839172363,
      "learning_rate": 2.4594281298299844e-05,
      "loss": 1.8018,
      "step": 5260
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1384025812149048,
      "learning_rate": 2.454598145285935e-05,
      "loss": 1.823,
      "step": 5270
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6889530420303345,
      "learning_rate": 2.449768160741886e-05,
      "loss": 1.7159,
      "step": 5280
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.8393989205360413,
      "learning_rate": 2.4449381761978362e-05,
      "loss": 1.7368,
      "step": 5290
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.055131196975708,
      "learning_rate": 2.440108191653787e-05,
      "loss": 1.8434,
      "step": 5300
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.7440245747566223,
      "learning_rate": 2.4352782071097373e-05,
      "loss": 1.6449,
      "step": 5310
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.7901580333709717,
      "learning_rate": 2.430448222565688e-05,
      "loss": 1.6709,
      "step": 5320
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.007852554321289,
      "learning_rate": 2.4256182380216387e-05,
      "loss": 1.915,
      "step": 5330
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.9749202728271484,
      "learning_rate": 2.4207882534775888e-05,
      "loss": 1.9076,
      "step": 5340
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.5928714275360107,
      "learning_rate": 2.4159582689335395e-05,
      "loss": 1.8417,
      "step": 5350
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.0079911947250366,
      "learning_rate": 2.4111282843894902e-05,
      "loss": 1.7664,
      "step": 5360
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6639702320098877,
      "learning_rate": 2.4062982998454405e-05,
      "loss": 1.8597,
      "step": 5370
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.7422946691513062,
      "learning_rate": 2.4014683153013913e-05,
      "loss": 1.8202,
      "step": 5380
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.320507049560547,
      "learning_rate": 2.3966383307573416e-05,
      "loss": 1.8472,
      "step": 5390
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.8666160106658936,
      "learning_rate": 2.3918083462132923e-05,
      "loss": 1.8183,
      "step": 5400
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.783306360244751,
      "learning_rate": 2.386978361669243e-05,
      "loss": 1.9216,
      "step": 5410
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.2091046571731567,
      "learning_rate": 2.382148377125193e-05,
      "loss": 1.7228,
      "step": 5420
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.015040636062622,
      "learning_rate": 2.3773183925811438e-05,
      "loss": 1.6704,
      "step": 5430
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.0364587306976318,
      "learning_rate": 2.3724884080370945e-05,
      "loss": 1.7371,
      "step": 5440
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.42018240690231323,
      "learning_rate": 2.367658423493045e-05,
      "loss": 1.8912,
      "step": 5450
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.4513986110687256,
      "learning_rate": 2.3628284389489956e-05,
      "loss": 1.7996,
      "step": 5460
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.2957791090011597,
      "learning_rate": 2.357998454404946e-05,
      "loss": 1.8217,
      "step": 5470
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.0547443628311157,
      "learning_rate": 2.3531684698608966e-05,
      "loss": 1.7359,
      "step": 5480
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.7706958651542664,
      "learning_rate": 2.3483384853168474e-05,
      "loss": 1.82,
      "step": 5490
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.8155974745750427,
      "learning_rate": 2.3435085007727977e-05,
      "loss": 1.7557,
      "step": 5500
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.633791208267212,
      "learning_rate": 2.338678516228748e-05,
      "loss": 1.7527,
      "step": 5510
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6205016374588013,
      "learning_rate": 2.3338485316846988e-05,
      "loss": 1.7373,
      "step": 5520
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.860826313495636,
      "learning_rate": 2.329018547140649e-05,
      "loss": 1.7789,
      "step": 5530
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.4346952438354492,
      "learning_rate": 2.3241885625966e-05,
      "loss": 1.6622,
      "step": 5540
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.0372672080993652,
      "learning_rate": 2.3193585780525502e-05,
      "loss": 1.6745,
      "step": 5550
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.4968046247959137,
      "learning_rate": 2.314528593508501e-05,
      "loss": 1.7646,
      "step": 5560
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.388348937034607,
      "learning_rate": 2.3096986089644517e-05,
      "loss": 1.9432,
      "step": 5570
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.7120236754417419,
      "learning_rate": 2.304868624420402e-05,
      "loss": 1.6089,
      "step": 5580
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.1872464418411255,
      "learning_rate": 2.3000386398763524e-05,
      "loss": 1.8568,
      "step": 5590
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.097604513168335,
      "learning_rate": 2.295208655332303e-05,
      "loss": 1.9746,
      "step": 5600
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.8340398073196411,
      "learning_rate": 2.2903786707882535e-05,
      "loss": 1.7898,
      "step": 5610
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6342223286628723,
      "learning_rate": 2.2855486862442042e-05,
      "loss": 1.9411,
      "step": 5620
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.8777482509613037,
      "learning_rate": 2.2807187017001546e-05,
      "loss": 1.7365,
      "step": 5630
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.8011227250099182,
      "learning_rate": 2.2758887171561053e-05,
      "loss": 1.6918,
      "step": 5640
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.7162116169929504,
      "learning_rate": 2.271058732612056e-05,
      "loss": 1.9171,
      "step": 5650
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.1677528619766235,
      "learning_rate": 2.2662287480680063e-05,
      "loss": 1.6947,
      "step": 5660
    },
    {
      "epoch": 1.1,
      "grad_norm": 4.0270466804504395,
      "learning_rate": 2.261398763523957e-05,
      "loss": 1.795,
      "step": 5670
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.7551114559173584,
      "learning_rate": 2.2565687789799074e-05,
      "loss": 1.8528,
      "step": 5680
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.742636203765869,
      "learning_rate": 2.2517387944358578e-05,
      "loss": 1.7004,
      "step": 5690
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.9265470504760742,
      "learning_rate": 2.2469088098918085e-05,
      "loss": 1.7673,
      "step": 5700
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.121819019317627,
      "learning_rate": 2.242078825347759e-05,
      "loss": 1.7021,
      "step": 5710
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.158016562461853,
      "learning_rate": 2.2372488408037096e-05,
      "loss": 1.6019,
      "step": 5720
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.300257921218872,
      "learning_rate": 2.2324188562596603e-05,
      "loss": 1.7333,
      "step": 5730
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.8908286094665527,
      "learning_rate": 2.2275888717156107e-05,
      "loss": 1.7356,
      "step": 5740
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.0130606889724731,
      "learning_rate": 2.2227588871715614e-05,
      "loss": 1.7698,
      "step": 5750
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.4466780126094818,
      "learning_rate": 2.2179289026275117e-05,
      "loss": 1.7215,
      "step": 5760
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.6106011867523193,
      "learning_rate": 2.213098918083462e-05,
      "loss": 1.827,
      "step": 5770
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6867032647132874,
      "learning_rate": 2.2082689335394128e-05,
      "loss": 1.7611,
      "step": 5780
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6032460927963257,
      "learning_rate": 2.2034389489953632e-05,
      "loss": 1.7518,
      "step": 5790
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.3225445747375488,
      "learning_rate": 2.198608964451314e-05,
      "loss": 1.7391,
      "step": 5800
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.8797994256019592,
      "learning_rate": 2.1937789799072646e-05,
      "loss": 1.6888,
      "step": 5810
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6260128617286682,
      "learning_rate": 2.188948995363215e-05,
      "loss": 1.7197,
      "step": 5820
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.1607050895690918,
      "learning_rate": 2.1841190108191657e-05,
      "loss": 1.7198,
      "step": 5830
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.5246379375457764,
      "learning_rate": 2.179289026275116e-05,
      "loss": 1.798,
      "step": 5840
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.1346957683563232,
      "learning_rate": 2.1744590417310664e-05,
      "loss": 1.6458,
      "step": 5850
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.8470166921615601,
      "learning_rate": 2.169629057187017e-05,
      "loss": 1.7669,
      "step": 5860
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.00077486038208,
      "learning_rate": 2.1647990726429675e-05,
      "loss": 1.8366,
      "step": 5870
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.4164867401123047,
      "learning_rate": 2.1599690880989182e-05,
      "loss": 1.7832,
      "step": 5880
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.0446971654891968,
      "learning_rate": 2.155139103554869e-05,
      "loss": 1.7338,
      "step": 5890
    },
    {
      "epoch": 1.14,
      "grad_norm": 3.3021433353424072,
      "learning_rate": 2.1503091190108193e-05,
      "loss": 1.8132,
      "step": 5900
    },
    {
      "epoch": 1.14,
      "grad_norm": 3.440307378768921,
      "learning_rate": 2.14547913446677e-05,
      "loss": 1.7284,
      "step": 5910
    },
    {
      "epoch": 1.14,
      "grad_norm": 5.844152450561523,
      "learning_rate": 2.1406491499227204e-05,
      "loss": 1.8368,
      "step": 5920
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.415817141532898,
      "learning_rate": 2.1358191653786707e-05,
      "loss": 1.7657,
      "step": 5930
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.8775248527526855,
      "learning_rate": 2.1309891808346214e-05,
      "loss": 2.1569,
      "step": 5940
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.9225434064865112,
      "learning_rate": 2.1261591962905718e-05,
      "loss": 1.7802,
      "step": 5950
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.128440022468567,
      "learning_rate": 2.1213292117465225e-05,
      "loss": 1.6741,
      "step": 5960
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.6205745935440063,
      "learning_rate": 2.1164992272024732e-05,
      "loss": 1.8502,
      "step": 5970
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.47412610054016113,
      "learning_rate": 2.1116692426584236e-05,
      "loss": 1.8066,
      "step": 5980
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.0361721515655518,
      "learning_rate": 2.1068392581143743e-05,
      "loss": 1.8121,
      "step": 5990
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6156060695648193,
      "learning_rate": 2.1020092735703247e-05,
      "loss": 1.787,
      "step": 6000
    },
    {
      "epoch": 1.16,
      "grad_norm": 6.194090843200684,
      "learning_rate": 2.097179289026275e-05,
      "loss": 1.7151,
      "step": 6010
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1981613636016846,
      "learning_rate": 2.0923493044822257e-05,
      "loss": 1.7955,
      "step": 6020
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1221563816070557,
      "learning_rate": 2.087519319938176e-05,
      "loss": 1.8136,
      "step": 6030
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6723880767822266,
      "learning_rate": 2.0826893353941268e-05,
      "loss": 1.8523,
      "step": 6040
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.9765571355819702,
      "learning_rate": 2.0778593508500775e-05,
      "loss": 1.8452,
      "step": 6050
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.7929781079292297,
      "learning_rate": 2.073029366306028e-05,
      "loss": 1.7736,
      "step": 6060
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.1459753513336182,
      "learning_rate": 2.0681993817619786e-05,
      "loss": 1.7046,
      "step": 6070
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.84046471118927,
      "learning_rate": 2.063369397217929e-05,
      "loss": 1.7195,
      "step": 6080
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.743475615978241,
      "learning_rate": 2.0585394126738797e-05,
      "loss": 1.7709,
      "step": 6090
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.8696849942207336,
      "learning_rate": 2.05370942812983e-05,
      "loss": 1.6326,
      "step": 6100
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.789992570877075,
      "learning_rate": 2.0488794435857804e-05,
      "loss": 1.8265,
      "step": 6110
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.8205782771110535,
      "learning_rate": 2.044049459041731e-05,
      "loss": 1.8734,
      "step": 6120
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.766667366027832,
      "learning_rate": 2.039219474497682e-05,
      "loss": 1.8354,
      "step": 6130
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6630812287330627,
      "learning_rate": 2.0343894899536322e-05,
      "loss": 1.8083,
      "step": 6140
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.4700840711593628,
      "learning_rate": 2.029559505409583e-05,
      "loss": 1.7719,
      "step": 6150
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.5570284128189087,
      "learning_rate": 2.0247295208655333e-05,
      "loss": 1.7288,
      "step": 6160
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.3132717609405518,
      "learning_rate": 2.019899536321484e-05,
      "loss": 1.825,
      "step": 6170
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.4673601388931274,
      "learning_rate": 2.0150695517774344e-05,
      "loss": 1.8848,
      "step": 6180
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.8647847175598145,
      "learning_rate": 2.0102395672333847e-05,
      "loss": 1.7789,
      "step": 6190
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.4816884696483612,
      "learning_rate": 2.0054095826893355e-05,
      "loss": 1.747,
      "step": 6200
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9389230608940125,
      "learning_rate": 2.000579598145286e-05,
      "loss": 1.7285,
      "step": 6210
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.408402681350708,
      "learning_rate": 1.9957496136012365e-05,
      "loss": 1.6612,
      "step": 6220
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.1598246097564697,
      "learning_rate": 1.9909196290571872e-05,
      "loss": 1.8324,
      "step": 6230
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.4526006281375885,
      "learning_rate": 1.9860896445131376e-05,
      "loss": 1.839,
      "step": 6240
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.8035086989402771,
      "learning_rate": 1.9812596599690883e-05,
      "loss": 1.8248,
      "step": 6250
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.0286169052124023,
      "learning_rate": 1.9764296754250387e-05,
      "loss": 1.7085,
      "step": 6260
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.3520978689193726,
      "learning_rate": 1.971599690880989e-05,
      "loss": 1.6889,
      "step": 6270
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.7821326851844788,
      "learning_rate": 1.9667697063369398e-05,
      "loss": 1.7362,
      "step": 6280
    },
    {
      "epoch": 1.22,
      "grad_norm": 4.219598770141602,
      "learning_rate": 1.9619397217928905e-05,
      "loss": 1.7075,
      "step": 6290
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6797482967376709,
      "learning_rate": 1.957109737248841e-05,
      "loss": 1.8695,
      "step": 6300
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.728024423122406,
      "learning_rate": 1.9522797527047916e-05,
      "loss": 1.6759,
      "step": 6310
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.8828529119491577,
      "learning_rate": 1.947449768160742e-05,
      "loss": 1.7323,
      "step": 6320
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.9507023692131042,
      "learning_rate": 1.9426197836166926e-05,
      "loss": 1.7896,
      "step": 6330
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1458581686019897,
      "learning_rate": 1.9377897990726433e-05,
      "loss": 1.6605,
      "step": 6340
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.741858959197998,
      "learning_rate": 1.9329598145285934e-05,
      "loss": 1.8159,
      "step": 6350
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.7806625366210938,
      "learning_rate": 1.928129829984544e-05,
      "loss": 1.7645,
      "step": 6360
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.6578199863433838,
      "learning_rate": 1.9232998454404948e-05,
      "loss": 1.8348,
      "step": 6370
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7393175959587097,
      "learning_rate": 1.918469860896445e-05,
      "loss": 1.8174,
      "step": 6380
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.1651790142059326,
      "learning_rate": 1.913639876352396e-05,
      "loss": 1.868,
      "step": 6390
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.7127273678779602,
      "learning_rate": 1.9088098918083462e-05,
      "loss": 1.7178,
      "step": 6400
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0809539556503296,
      "learning_rate": 1.903979907264297e-05,
      "loss": 1.8227,
      "step": 6410
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.4460676908493042,
      "learning_rate": 1.8991499227202476e-05,
      "loss": 1.9507,
      "step": 6420
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.487350344657898,
      "learning_rate": 1.8943199381761977e-05,
      "loss": 1.754,
      "step": 6430
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.8023983240127563,
      "learning_rate": 1.8894899536321484e-05,
      "loss": 1.7574,
      "step": 6440
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.325333595275879,
      "learning_rate": 1.884659969088099e-05,
      "loss": 1.9715,
      "step": 6450
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.0818297863006592,
      "learning_rate": 1.8798299845440495e-05,
      "loss": 1.7909,
      "step": 6460
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.0087991952896118,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 1.8236,
      "step": 6470
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.101700782775879,
      "learning_rate": 1.8701700154559505e-05,
      "loss": 1.7201,
      "step": 6480
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.46765971183776855,
      "learning_rate": 1.8653400309119013e-05,
      "loss": 1.7889,
      "step": 6490
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.5828108191490173,
      "learning_rate": 1.860510046367852e-05,
      "loss": 1.7194,
      "step": 6500
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.9803919792175293,
      "learning_rate": 1.8556800618238023e-05,
      "loss": 1.6702,
      "step": 6510
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.1902605295181274,
      "learning_rate": 1.8508500772797527e-05,
      "loss": 1.7197,
      "step": 6520
    },
    {
      "epoch": 1.26,
      "grad_norm": 4.084400177001953,
      "learning_rate": 1.8460200927357034e-05,
      "loss": 1.8165,
      "step": 6530
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.8524136543273926,
      "learning_rate": 1.8411901081916538e-05,
      "loss": 1.6991,
      "step": 6540
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5111300349235535,
      "learning_rate": 1.8363601236476045e-05,
      "loss": 1.8244,
      "step": 6550
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.8933581709861755,
      "learning_rate": 1.831530139103555e-05,
      "loss": 1.9198,
      "step": 6560
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.960831642150879,
      "learning_rate": 1.8267001545595056e-05,
      "loss": 1.847,
      "step": 6570
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.5137455463409424,
      "learning_rate": 1.8218701700154563e-05,
      "loss": 1.7534,
      "step": 6580
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.2949910163879395,
      "learning_rate": 1.8170401854714066e-05,
      "loss": 1.7922,
      "step": 6590
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.3292042016983032,
      "learning_rate": 1.812210200927357e-05,
      "loss": 1.8182,
      "step": 6600
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.105957269668579,
      "learning_rate": 1.8073802163833077e-05,
      "loss": 1.8267,
      "step": 6610
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.270212173461914,
      "learning_rate": 1.802550231839258e-05,
      "loss": 1.8436,
      "step": 6620
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.0328294038772583,
      "learning_rate": 1.7977202472952088e-05,
      "loss": 1.6743,
      "step": 6630
    },
    {
      "epoch": 1.28,
      "grad_norm": 6.9818854331970215,
      "learning_rate": 1.792890262751159e-05,
      "loss": 1.7492,
      "step": 6640
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.9267703890800476,
      "learning_rate": 1.78806027820711e-05,
      "loss": 1.871,
      "step": 6650
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.9538522958755493,
      "learning_rate": 1.7832302936630606e-05,
      "loss": 1.8832,
      "step": 6660
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.6095372438430786,
      "learning_rate": 1.778400309119011e-05,
      "loss": 1.7606,
      "step": 6670
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.5843925476074219,
      "learning_rate": 1.7735703245749617e-05,
      "loss": 1.8104,
      "step": 6680
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.0924863815307617,
      "learning_rate": 1.768740340030912e-05,
      "loss": 1.8016,
      "step": 6690
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.0739332437515259,
      "learning_rate": 1.7639103554868624e-05,
      "loss": 1.6511,
      "step": 6700
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6073552966117859,
      "learning_rate": 1.759080370942813e-05,
      "loss": 1.8634,
      "step": 6710
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.0323277711868286,
      "learning_rate": 1.7542503863987635e-05,
      "loss": 1.7463,
      "step": 6720
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.445826768875122,
      "learning_rate": 1.7494204018547142e-05,
      "loss": 1.7403,
      "step": 6730
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.2374942302703857,
      "learning_rate": 1.744590417310665e-05,
      "loss": 1.8226,
      "step": 6740
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6073966026306152,
      "learning_rate": 1.7397604327666153e-05,
      "loss": 1.7314,
      "step": 6750
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.084965467453003,
      "learning_rate": 1.734930448222566e-05,
      "loss": 1.7739,
      "step": 6760
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.2907735109329224,
      "learning_rate": 1.7301004636785163e-05,
      "loss": 1.8466,
      "step": 6770
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6851858496665955,
      "learning_rate": 1.7252704791344667e-05,
      "loss": 1.8395,
      "step": 6780
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.5647093057632446,
      "learning_rate": 1.7204404945904174e-05,
      "loss": 1.7982,
      "step": 6790
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.36342597007751465,
      "learning_rate": 1.7156105100463678e-05,
      "loss": 1.738,
      "step": 6800
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.5484960079193115,
      "learning_rate": 1.7107805255023185e-05,
      "loss": 1.7918,
      "step": 6810
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6259851455688477,
      "learning_rate": 1.7059505409582692e-05,
      "loss": 1.8846,
      "step": 6820
    },
    {
      "epoch": 1.32,
      "grad_norm": 4.799650192260742,
      "learning_rate": 1.7011205564142196e-05,
      "loss": 1.6965,
      "step": 6830
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.1680262088775635,
      "learning_rate": 1.6962905718701703e-05,
      "loss": 1.7698,
      "step": 6840
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.9473084807395935,
      "learning_rate": 1.6914605873261207e-05,
      "loss": 1.6774,
      "step": 6850
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.7083736658096313,
      "learning_rate": 1.686630602782071e-05,
      "loss": 1.7451,
      "step": 6860
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.48804301023483276,
      "learning_rate": 1.6818006182380217e-05,
      "loss": 1.7877,
      "step": 6870
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.3265457153320312,
      "learning_rate": 1.676970633693972e-05,
      "loss": 1.6747,
      "step": 6880
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6604970097541809,
      "learning_rate": 1.6721406491499228e-05,
      "loss": 1.7908,
      "step": 6890
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6856279373168945,
      "learning_rate": 1.6673106646058735e-05,
      "loss": 1.6823,
      "step": 6900
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.8170640468597412,
      "learning_rate": 1.662480680061824e-05,
      "loss": 1.6961,
      "step": 6910
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6795716881752014,
      "learning_rate": 1.6576506955177746e-05,
      "loss": 1.7619,
      "step": 6920
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.0144232511520386,
      "learning_rate": 1.652820710973725e-05,
      "loss": 1.7291,
      "step": 6930
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7577117085456848,
      "learning_rate": 1.6479907264296753e-05,
      "loss": 1.8362,
      "step": 6940
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7881552577018738,
      "learning_rate": 1.643160741885626e-05,
      "loss": 1.7089,
      "step": 6950
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.0025568008422852,
      "learning_rate": 1.6383307573415764e-05,
      "loss": 1.8289,
      "step": 6960
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4199655055999756,
      "learning_rate": 1.633500772797527e-05,
      "loss": 1.8746,
      "step": 6970
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.7611662149429321,
      "learning_rate": 1.628670788253478e-05,
      "loss": 1.6635,
      "step": 6980
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3818378448486328,
      "learning_rate": 1.6238408037094282e-05,
      "loss": 1.704,
      "step": 6990
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.7198696732521057,
      "learning_rate": 1.619010819165379e-05,
      "loss": 1.7077,
      "step": 7000
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4796793460845947,
      "learning_rate": 1.6141808346213293e-05,
      "loss": 1.7688,
      "step": 7010
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.4926370084285736,
      "learning_rate": 1.6093508500772797e-05,
      "loss": 1.6966,
      "step": 7020
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.8355515003204346,
      "learning_rate": 1.6045208655332304e-05,
      "loss": 1.7931,
      "step": 7030
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.3863280117511749,
      "learning_rate": 1.5996908809891807e-05,
      "loss": 1.7954,
      "step": 7040
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.7700392603874207,
      "learning_rate": 1.5948608964451314e-05,
      "loss": 1.8012,
      "step": 7050
    },
    {
      "epoch": 1.36,
      "grad_norm": 3.912139415740967,
      "learning_rate": 1.590030911901082e-05,
      "loss": 1.8925,
      "step": 7060
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6876583695411682,
      "learning_rate": 1.5852009273570325e-05,
      "loss": 1.9519,
      "step": 7070
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6858184933662415,
      "learning_rate": 1.5803709428129832e-05,
      "loss": 1.9046,
      "step": 7080
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.8060601353645325,
      "learning_rate": 1.5755409582689336e-05,
      "loss": 1.6671,
      "step": 7090
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.0791033506393433,
      "learning_rate": 1.5707109737248843e-05,
      "loss": 1.7353,
      "step": 7100
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6894525289535522,
      "learning_rate": 1.5658809891808347e-05,
      "loss": 1.9225,
      "step": 7110
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.191961407661438,
      "learning_rate": 1.561051004636785e-05,
      "loss": 1.7777,
      "step": 7120
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.5146758556365967,
      "learning_rate": 1.5562210200927358e-05,
      "loss": 1.7213,
      "step": 7130
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.5893048048019409,
      "learning_rate": 1.5513910355486865e-05,
      "loss": 1.862,
      "step": 7140
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.681187093257904,
      "learning_rate": 1.5465610510046368e-05,
      "loss": 1.7311,
      "step": 7150
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.2708680629730225,
      "learning_rate": 1.5417310664605875e-05,
      "loss": 1.702,
      "step": 7160
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.9262456297874451,
      "learning_rate": 1.536901081916538e-05,
      "loss": 1.7498,
      "step": 7170
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.8682775497436523,
      "learning_rate": 1.5320710973724886e-05,
      "loss": 1.7715,
      "step": 7180
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.7551391124725342,
      "learning_rate": 1.527241112828439e-05,
      "loss": 1.7663,
      "step": 7190
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.107599973678589,
      "learning_rate": 1.5224111282843895e-05,
      "loss": 1.8826,
      "step": 7200
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1232355833053589,
      "learning_rate": 1.51758114374034e-05,
      "loss": 1.7818,
      "step": 7210
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.700033962726593,
      "learning_rate": 1.5127511591962906e-05,
      "loss": 1.8185,
      "step": 7220
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.2778767347335815,
      "learning_rate": 1.5079211746522411e-05,
      "loss": 1.792,
      "step": 7230
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7481131553649902,
      "learning_rate": 1.5030911901081918e-05,
      "loss": 1.8578,
      "step": 7240
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5768538117408752,
      "learning_rate": 1.4982612055641424e-05,
      "loss": 1.6938,
      "step": 7250
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.1222953796386719,
      "learning_rate": 1.493431221020093e-05,
      "loss": 1.9269,
      "step": 7260
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.9188638925552368,
      "learning_rate": 1.4886012364760433e-05,
      "loss": 1.8022,
      "step": 7270
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.0661660432815552,
      "learning_rate": 1.4837712519319938e-05,
      "loss": 1.7677,
      "step": 7280
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.306930422782898,
      "learning_rate": 1.4789412673879444e-05,
      "loss": 1.7154,
      "step": 7290
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.562353253364563,
      "learning_rate": 1.4741112828438949e-05,
      "loss": 1.79,
      "step": 7300
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6936051845550537,
      "learning_rate": 1.4692812982998455e-05,
      "loss": 1.8603,
      "step": 7310
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.8285740613937378,
      "learning_rate": 1.4644513137557962e-05,
      "loss": 1.7127,
      "step": 7320
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6811075210571289,
      "learning_rate": 1.4596213292117467e-05,
      "loss": 1.8538,
      "step": 7330
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.2453731298446655,
      "learning_rate": 1.4547913446676972e-05,
      "loss": 1.7576,
      "step": 7340
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7907713055610657,
      "learning_rate": 1.4499613601236478e-05,
      "loss": 1.7593,
      "step": 7350
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.3427788019180298,
      "learning_rate": 1.4451313755795981e-05,
      "loss": 1.8019,
      "step": 7360
    },
    {
      "epoch": 1.42,
      "grad_norm": 4.476157188415527,
      "learning_rate": 1.4403013910355487e-05,
      "loss": 1.7295,
      "step": 7370
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.4940566420555115,
      "learning_rate": 1.4354714064914992e-05,
      "loss": 1.6979,
      "step": 7380
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.4219595193862915,
      "learning_rate": 1.4306414219474498e-05,
      "loss": 1.9775,
      "step": 7390
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6846726536750793,
      "learning_rate": 1.4258114374034005e-05,
      "loss": 1.6402,
      "step": 7400
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.0950368642807007,
      "learning_rate": 1.420981452859351e-05,
      "loss": 1.9231,
      "step": 7410
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.4839012622833252,
      "learning_rate": 1.4161514683153016e-05,
      "loss": 1.7859,
      "step": 7420
    },
    {
      "epoch": 1.44,
      "grad_norm": 7.6807661056518555,
      "learning_rate": 1.4113214837712521e-05,
      "loss": 1.8211,
      "step": 7430
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6666727066040039,
      "learning_rate": 1.4064914992272025e-05,
      "loss": 1.6979,
      "step": 7440
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.480426549911499,
      "learning_rate": 1.401661514683153e-05,
      "loss": 1.9678,
      "step": 7450
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1249990463256836,
      "learning_rate": 1.3968315301391035e-05,
      "loss": 1.7537,
      "step": 7460
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.9582526683807373,
      "learning_rate": 1.392001545595054e-05,
      "loss": 1.7659,
      "step": 7470
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.1212888956069946,
      "learning_rate": 1.3871715610510048e-05,
      "loss": 1.748,
      "step": 7480
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.416823387145996,
      "learning_rate": 1.3823415765069553e-05,
      "loss": 1.6968,
      "step": 7490
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.9199999570846558,
      "learning_rate": 1.3775115919629059e-05,
      "loss": 1.7236,
      "step": 7500
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.4507453143596649,
      "learning_rate": 1.3726816074188564e-05,
      "loss": 1.7648,
      "step": 7510
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5360945463180542,
      "learning_rate": 1.367851622874807e-05,
      "loss": 1.8116,
      "step": 7520
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.3724048435688019,
      "learning_rate": 1.3630216383307573e-05,
      "loss": 1.7814,
      "step": 7530
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.0870321989059448,
      "learning_rate": 1.3581916537867079e-05,
      "loss": 1.8014,
      "step": 7540
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.159498929977417,
      "learning_rate": 1.3533616692426584e-05,
      "loss": 1.8457,
      "step": 7550
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.7480931878089905,
      "learning_rate": 1.3485316846986091e-05,
      "loss": 1.7704,
      "step": 7560
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6044743657112122,
      "learning_rate": 1.3437017001545596e-05,
      "loss": 1.6126,
      "step": 7570
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.052465796470642,
      "learning_rate": 1.3388717156105102e-05,
      "loss": 1.8102,
      "step": 7580
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7833836674690247,
      "learning_rate": 1.3340417310664607e-05,
      "loss": 1.7769,
      "step": 7590
    },
    {
      "epoch": 1.47,
      "grad_norm": 2.557352066040039,
      "learning_rate": 1.3292117465224113e-05,
      "loss": 1.8304,
      "step": 7600
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.5543111562728882,
      "learning_rate": 1.3243817619783616e-05,
      "loss": 1.8539,
      "step": 7610
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7545560598373413,
      "learning_rate": 1.3195517774343122e-05,
      "loss": 1.682,
      "step": 7620
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.7960435152053833,
      "learning_rate": 1.3147217928902627e-05,
      "loss": 1.7264,
      "step": 7630
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.6087411642074585,
      "learning_rate": 1.3098918083462134e-05,
      "loss": 1.7621,
      "step": 7640
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5033656358718872,
      "learning_rate": 1.305061823802164e-05,
      "loss": 1.9666,
      "step": 7650
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.6613574028015137,
      "learning_rate": 1.3002318392581145e-05,
      "loss": 1.7027,
      "step": 7660
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.4487505853176117,
      "learning_rate": 1.295401854714065e-05,
      "loss": 1.7149,
      "step": 7670
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.5815539360046387,
      "learning_rate": 1.2905718701700156e-05,
      "loss": 1.7591,
      "step": 7680
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7001557350158691,
      "learning_rate": 1.285741885625966e-05,
      "loss": 1.6958,
      "step": 7690
    },
    {
      "epoch": 1.49,
      "grad_norm": 2.5272276401519775,
      "learning_rate": 1.2809119010819165e-05,
      "loss": 1.8976,
      "step": 7700
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.4922465085983276,
      "learning_rate": 1.276081916537867e-05,
      "loss": 1.824,
      "step": 7710
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2134466171264648,
      "learning_rate": 1.2712519319938177e-05,
      "loss": 1.6845,
      "step": 7720
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7228949069976807,
      "learning_rate": 1.2664219474497683e-05,
      "loss": 1.8722,
      "step": 7730
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.719942569732666,
      "learning_rate": 1.2615919629057188e-05,
      "loss": 1.8561,
      "step": 7740
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0612505674362183,
      "learning_rate": 1.2567619783616693e-05,
      "loss": 2.0279,
      "step": 7750
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7905570268630981,
      "learning_rate": 1.2519319938176199e-05,
      "loss": 1.8866,
      "step": 7760
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0237246751785278,
      "learning_rate": 1.2471020092735704e-05,
      "loss": 1.6927,
      "step": 7770
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8403518795967102,
      "learning_rate": 1.242272024729521e-05,
      "loss": 1.6894,
      "step": 7780
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.493682384490967,
      "learning_rate": 1.2374420401854715e-05,
      "loss": 1.6354,
      "step": 7790
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.9508348107337952,
      "learning_rate": 1.232612055641422e-05,
      "loss": 1.696,
      "step": 7800
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.9693992733955383,
      "learning_rate": 1.2277820710973726e-05,
      "loss": 1.8266,
      "step": 7810
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.1059434413909912,
      "learning_rate": 1.2229520865533231e-05,
      "loss": 1.8076,
      "step": 7820
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6081205010414124,
      "learning_rate": 1.2181221020092737e-05,
      "loss": 1.7428,
      "step": 7830
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.2907663583755493,
      "learning_rate": 1.2132921174652242e-05,
      "loss": 1.7329,
      "step": 7840
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.44420325756073,
      "learning_rate": 1.2084621329211747e-05,
      "loss": 1.8091,
      "step": 7850
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.9125678539276123,
      "learning_rate": 1.2036321483771253e-05,
      "loss": 1.8384,
      "step": 7860
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.2168575525283813,
      "learning_rate": 1.1988021638330758e-05,
      "loss": 1.8202,
      "step": 7870
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0051162242889404,
      "learning_rate": 1.1939721792890263e-05,
      "loss": 1.7974,
      "step": 7880
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.300376296043396,
      "learning_rate": 1.1891421947449769e-05,
      "loss": 1.6895,
      "step": 7890
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.8413434624671936,
      "learning_rate": 1.1843122102009274e-05,
      "loss": 1.8959,
      "step": 7900
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.9489471912384033,
      "learning_rate": 1.179482225656878e-05,
      "loss": 1.8095,
      "step": 7910
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.236559510231018,
      "learning_rate": 1.1746522411128285e-05,
      "loss": 1.7599,
      "step": 7920
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6810106635093689,
      "learning_rate": 1.169822256568779e-05,
      "loss": 1.8013,
      "step": 7930
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.8462718725204468,
      "learning_rate": 1.1649922720247296e-05,
      "loss": 1.6182,
      "step": 7940
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.8338057398796082,
      "learning_rate": 1.1601622874806801e-05,
      "loss": 1.7521,
      "step": 7950
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.5547748804092407,
      "learning_rate": 1.1553323029366307e-05,
      "loss": 1.7604,
      "step": 7960
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.6809028387069702,
      "learning_rate": 1.1505023183925812e-05,
      "loss": 1.8678,
      "step": 7970
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.6073206663131714,
      "learning_rate": 1.1456723338485317e-05,
      "loss": 1.733,
      "step": 7980
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.5446584224700928,
      "learning_rate": 1.1408423493044823e-05,
      "loss": 1.5499,
      "step": 7990
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.8687673807144165,
      "learning_rate": 1.1360123647604328e-05,
      "loss": 1.6174,
      "step": 8000
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0854567289352417,
      "learning_rate": 1.1311823802163834e-05,
      "loss": 1.6892,
      "step": 8010
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.1196318864822388,
      "learning_rate": 1.1263523956723339e-05,
      "loss": 1.7788,
      "step": 8020
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.7200971841812134,
      "learning_rate": 1.1215224111282844e-05,
      "loss": 2.1262,
      "step": 8030
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.5611074566841125,
      "learning_rate": 1.116692426584235e-05,
      "loss": 1.8601,
      "step": 8040
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.9105265140533447,
      "learning_rate": 1.1118624420401855e-05,
      "loss": 1.7666,
      "step": 8050
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.7278109788894653,
      "learning_rate": 1.107032457496136e-05,
      "loss": 1.869,
      "step": 8060
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.717992901802063,
      "learning_rate": 1.1022024729520866e-05,
      "loss": 1.669,
      "step": 8070
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.7815313339233398,
      "learning_rate": 1.0973724884080371e-05,
      "loss": 1.735,
      "step": 8080
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.0204346179962158,
      "learning_rate": 1.0925425038639877e-05,
      "loss": 1.6905,
      "step": 8090
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5295989513397217,
      "learning_rate": 1.0877125193199382e-05,
      "loss": 1.8338,
      "step": 8100
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6356815099716187,
      "learning_rate": 1.0828825347758887e-05,
      "loss": 1.7775,
      "step": 8110
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.4135736227035522,
      "learning_rate": 1.0780525502318393e-05,
      "loss": 1.7363,
      "step": 8120
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.009015440940857,
      "learning_rate": 1.0732225656877898e-05,
      "loss": 1.6858,
      "step": 8130
    },
    {
      "epoch": 1.57,
      "grad_norm": 2.4267425537109375,
      "learning_rate": 1.0683925811437404e-05,
      "loss": 1.7274,
      "step": 8140
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6147231459617615,
      "learning_rate": 1.0635625965996909e-05,
      "loss": 1.8579,
      "step": 8150
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.6945925951004028,
      "learning_rate": 1.0587326120556414e-05,
      "loss": 1.8461,
      "step": 8160
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.8263392448425293,
      "learning_rate": 1.0539026275115921e-05,
      "loss": 1.7098,
      "step": 8170
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6762809157371521,
      "learning_rate": 1.0490726429675425e-05,
      "loss": 1.7274,
      "step": 8180
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.657701015472412,
      "learning_rate": 1.044242658423493e-05,
      "loss": 1.9027,
      "step": 8190
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.7612354159355164,
      "learning_rate": 1.0394126738794436e-05,
      "loss": 1.7826,
      "step": 8200
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.5802116394042969,
      "learning_rate": 1.0345826893353943e-05,
      "loss": 1.8842,
      "step": 8210
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6614865064620972,
      "learning_rate": 1.0297527047913447e-05,
      "loss": 1.7219,
      "step": 8220
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.2682195901870728,
      "learning_rate": 1.0249227202472952e-05,
      "loss": 1.6568,
      "step": 8230
    },
    {
      "epoch": 1.59,
      "grad_norm": 5.26732063293457,
      "learning_rate": 1.0200927357032458e-05,
      "loss": 1.8485,
      "step": 8240
    },
    {
      "epoch": 1.59,
      "grad_norm": 3.848432779312134,
      "learning_rate": 1.0152627511591965e-05,
      "loss": 1.747,
      "step": 8250
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3575292825698853,
      "learning_rate": 1.0104327666151468e-05,
      "loss": 1.7656,
      "step": 8260
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6447606682777405,
      "learning_rate": 1.0056027820710974e-05,
      "loss": 1.762,
      "step": 8270
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.614368200302124,
      "learning_rate": 1.0007727975270479e-05,
      "loss": 1.7812,
      "step": 8280
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.9550772905349731,
      "learning_rate": 9.959428129829986e-06,
      "loss": 1.7575,
      "step": 8290
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.9861422181129456,
      "learning_rate": 9.91112828438949e-06,
      "loss": 1.8283,
      "step": 8300
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.6478327512741089,
      "learning_rate": 9.862828438948995e-06,
      "loss": 1.6952,
      "step": 8310
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.198880910873413,
      "learning_rate": 9.8145285935085e-06,
      "loss": 1.7606,
      "step": 8320
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6887014508247375,
      "learning_rate": 9.766228748068008e-06,
      "loss": 1.6816,
      "step": 8330
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.8621624708175659,
      "learning_rate": 9.717928902627511e-06,
      "loss": 1.6453,
      "step": 8340
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.173203706741333,
      "learning_rate": 9.669629057187017e-06,
      "loss": 1.7114,
      "step": 8350
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.3721109628677368,
      "learning_rate": 9.621329211746522e-06,
      "loss": 1.9534,
      "step": 8360
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1754709482192993,
      "learning_rate": 9.57302936630603e-06,
      "loss": 1.6697,
      "step": 8370
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.6716232299804688,
      "learning_rate": 9.524729520865535e-06,
      "loss": 1.7567,
      "step": 8380
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.130441904067993,
      "learning_rate": 9.476429675425038e-06,
      "loss": 1.7482,
      "step": 8390
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0404316186904907,
      "learning_rate": 9.428129829984544e-06,
      "loss": 1.6393,
      "step": 8400
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.949567198753357,
      "learning_rate": 9.37982998454405e-06,
      "loss": 1.7731,
      "step": 8410
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.7445955276489258,
      "learning_rate": 9.331530139103556e-06,
      "loss": 1.5888,
      "step": 8420
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.7719708681106567,
      "learning_rate": 9.28323029366306e-06,
      "loss": 1.8356,
      "step": 8430
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.7541943788528442,
      "learning_rate": 9.234930448222565e-06,
      "loss": 1.8795,
      "step": 8440
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1521836519241333,
      "learning_rate": 9.186630602782072e-06,
      "loss": 1.8295,
      "step": 8450
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.2976171970367432,
      "learning_rate": 9.138330757341578e-06,
      "loss": 1.7384,
      "step": 8460
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.0134612321853638,
      "learning_rate": 9.090030911901081e-06,
      "loss": 1.6533,
      "step": 8470
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.7866435050964355,
      "learning_rate": 9.041731066460587e-06,
      "loss": 1.6798,
      "step": 8480
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.02323317527771,
      "learning_rate": 8.993431221020094e-06,
      "loss": 1.8322,
      "step": 8490
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.232962965965271,
      "learning_rate": 8.9451313755796e-06,
      "loss": 1.8364,
      "step": 8500
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.5848536491394043,
      "learning_rate": 8.896831530139103e-06,
      "loss": 1.7971,
      "step": 8510
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.690986156463623,
      "learning_rate": 8.848531684698608e-06,
      "loss": 1.8245,
      "step": 8520
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.9801536202430725,
      "learning_rate": 8.800231839258116e-06,
      "loss": 1.812,
      "step": 8530
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.4690587818622589,
      "learning_rate": 8.751931993817621e-06,
      "loss": 1.8122,
      "step": 8540
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.0483973026275635,
      "learning_rate": 8.703632148377125e-06,
      "loss": 1.9172,
      "step": 8550
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.48461082577705383,
      "learning_rate": 8.65533230293663e-06,
      "loss": 1.7745,
      "step": 8560
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0604469776153564,
      "learning_rate": 8.607032457496137e-06,
      "loss": 1.5398,
      "step": 8570
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.1908392906188965,
      "learning_rate": 8.558732612055642e-06,
      "loss": 1.915,
      "step": 8580
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.2230687141418457,
      "learning_rate": 8.510432766615148e-06,
      "loss": 1.7212,
      "step": 8590
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.6524379849433899,
      "learning_rate": 8.462132921174652e-06,
      "loss": 1.8289,
      "step": 8600
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0790197849273682,
      "learning_rate": 8.413833075734159e-06,
      "loss": 1.8456,
      "step": 8610
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.8431172966957092,
      "learning_rate": 8.365533230293664e-06,
      "loss": 1.7204,
      "step": 8620
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.8653132319450378,
      "learning_rate": 8.31723338485317e-06,
      "loss": 1.7073,
      "step": 8630
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.582675039768219,
      "learning_rate": 8.268933539412673e-06,
      "loss": 1.8128,
      "step": 8640
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.2082810401916504,
      "learning_rate": 8.22063369397218e-06,
      "loss": 1.7517,
      "step": 8650
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.7514665722846985,
      "learning_rate": 8.172333848531686e-06,
      "loss": 1.8357,
      "step": 8660
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.345914840698242,
      "learning_rate": 8.124034003091191e-06,
      "loss": 1.8712,
      "step": 8670
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.5987033247947693,
      "learning_rate": 8.075734157650695e-06,
      "loss": 1.8382,
      "step": 8680
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.2333391904830933,
      "learning_rate": 8.027434312210202e-06,
      "loss": 1.744,
      "step": 8690
    },
    {
      "epoch": 1.68,
      "grad_norm": 2.3989291191101074,
      "learning_rate": 7.979134466769707e-06,
      "loss": 1.7969,
      "step": 8700
    },
    {
      "epoch": 1.68,
      "grad_norm": 2.8919010162353516,
      "learning_rate": 7.930834621329213e-06,
      "loss": 1.7242,
      "step": 8710
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.554331660270691,
      "learning_rate": 7.882534775888716e-06,
      "loss": 1.7337,
      "step": 8720
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.9410523772239685,
      "learning_rate": 7.834234930448223e-06,
      "loss": 1.7145,
      "step": 8730
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.7774796485900879,
      "learning_rate": 7.785935085007729e-06,
      "loss": 1.8235,
      "step": 8740
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.5222113132476807,
      "learning_rate": 7.737635239567234e-06,
      "loss": 1.6722,
      "step": 8750
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.0892268419265747,
      "learning_rate": 7.689335394126738e-06,
      "loss": 1.7893,
      "step": 8760
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.8203588128089905,
      "learning_rate": 7.641035548686245e-06,
      "loss": 1.8758,
      "step": 8770
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.7595809698104858,
      "learning_rate": 7.59273570324575e-06,
      "loss": 1.884,
      "step": 8780
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.8440730571746826,
      "learning_rate": 7.544435857805256e-06,
      "loss": 1.8682,
      "step": 8790
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.4772385358810425,
      "learning_rate": 7.496136012364761e-06,
      "loss": 1.6768,
      "step": 8800
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.1793431043624878,
      "learning_rate": 7.447836166924266e-06,
      "loss": 1.6554,
      "step": 8810
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.9329006671905518,
      "learning_rate": 7.399536321483772e-06,
      "loss": 1.8411,
      "step": 8820
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.2993887662887573,
      "learning_rate": 7.351236476043277e-06,
      "loss": 1.7503,
      "step": 8830
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.4154372215270996,
      "learning_rate": 7.302936630602783e-06,
      "loss": 1.9299,
      "step": 8840
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.9033726453781128,
      "learning_rate": 7.254636785162287e-06,
      "loss": 1.7228,
      "step": 8850
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.922819972038269,
      "learning_rate": 7.206336939721793e-06,
      "loss": 1.8363,
      "step": 8860
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.2211195230484009,
      "learning_rate": 7.158037094281299e-06,
      "loss": 1.8037,
      "step": 8870
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.7682902812957764,
      "learning_rate": 7.109737248840804e-06,
      "loss": 1.915,
      "step": 8880
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.9873459339141846,
      "learning_rate": 7.061437403400309e-06,
      "loss": 1.7937,
      "step": 8890
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.5861284136772156,
      "learning_rate": 7.013137557959815e-06,
      "loss": 1.9213,
      "step": 8900
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.6346063613891602,
      "learning_rate": 6.96483771251932e-06,
      "loss": 1.8271,
      "step": 8910
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.9897431135177612,
      "learning_rate": 6.916537867078826e-06,
      "loss": 1.6626,
      "step": 8920
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.4949307441711426,
      "learning_rate": 6.86823802163833e-06,
      "loss": 1.6736,
      "step": 8930
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.1885143518447876,
      "learning_rate": 6.8199381761978365e-06,
      "loss": 1.7675,
      "step": 8940
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.8992759585380554,
      "learning_rate": 6.771638330757342e-06,
      "loss": 1.8655,
      "step": 8950
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5817810297012329,
      "learning_rate": 6.723338485316847e-06,
      "loss": 1.7351,
      "step": 8960
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7657814025878906,
      "learning_rate": 6.675038639876352e-06,
      "loss": 1.9355,
      "step": 8970
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5404664278030396,
      "learning_rate": 6.626738794435858e-06,
      "loss": 1.7575,
      "step": 8980
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.586418867111206,
      "learning_rate": 6.5784389489953635e-06,
      "loss": 1.6856,
      "step": 8990
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.8445854187011719,
      "learning_rate": 6.530139103554869e-06,
      "loss": 1.8415,
      "step": 9000
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.0292526483535767,
      "learning_rate": 6.481839258114375e-06,
      "loss": 1.9605,
      "step": 9010
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.820344090461731,
      "learning_rate": 6.43353941267388e-06,
      "loss": 1.6962,
      "step": 9020
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.9341855645179749,
      "learning_rate": 6.385239567233385e-06,
      "loss": 1.6492,
      "step": 9030
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6406064033508301,
      "learning_rate": 6.3369397217928904e-06,
      "loss": 1.7814,
      "step": 9040
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.0164414644241333,
      "learning_rate": 6.288639876352397e-06,
      "loss": 1.8728,
      "step": 9050
    },
    {
      "epoch": 1.75,
      "grad_norm": 5.587667465209961,
      "learning_rate": 6.240340030911901e-06,
      "loss": 1.8846,
      "step": 9060
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.0746920108795166,
      "learning_rate": 6.192040185471407e-06,
      "loss": 1.7933,
      "step": 9070
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.4018522500991821,
      "learning_rate": 6.143740340030912e-06,
      "loss": 1.886,
      "step": 9080
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.922802209854126,
      "learning_rate": 6.095440494590417e-06,
      "loss": 1.8348,
      "step": 9090
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.068893551826477,
      "learning_rate": 6.047140649149923e-06,
      "loss": 1.6084,
      "step": 9100
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.3106731176376343,
      "learning_rate": 5.998840803709428e-06,
      "loss": 1.7003,
      "step": 9110
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8127177357673645,
      "learning_rate": 5.9505409582689335e-06,
      "loss": 1.7333,
      "step": 9120
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.7249202728271484,
      "learning_rate": 5.902241112828439e-06,
      "loss": 1.6224,
      "step": 9130
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.1007177829742432,
      "learning_rate": 5.853941267387944e-06,
      "loss": 1.8908,
      "step": 9140
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.713845431804657,
      "learning_rate": 5.80564142194745e-06,
      "loss": 1.8571,
      "step": 9150
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.7204345464706421,
      "learning_rate": 5.757341576506955e-06,
      "loss": 1.8755,
      "step": 9160
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.7729547023773193,
      "learning_rate": 5.7090417310664605e-06,
      "loss": 1.9112,
      "step": 9170
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.627335250377655,
      "learning_rate": 5.660741885625966e-06,
      "loss": 1.7722,
      "step": 9180
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6077315807342529,
      "learning_rate": 5.612442040185472e-06,
      "loss": 1.9243,
      "step": 9190
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.2072781324386597,
      "learning_rate": 5.564142194744977e-06,
      "loss": 1.7643,
      "step": 9200
    },
    {
      "epoch": 1.78,
      "grad_norm": 9.762593269348145,
      "learning_rate": 5.515842349304483e-06,
      "loss": 1.6784,
      "step": 9210
    },
    {
      "epoch": 1.78,
      "grad_norm": 3.861443519592285,
      "learning_rate": 5.4675425038639875e-06,
      "loss": 1.7631,
      "step": 9220
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.396063804626465,
      "learning_rate": 5.419242658423494e-06,
      "loss": 1.7345,
      "step": 9230
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7958176136016846,
      "learning_rate": 5.370942812982998e-06,
      "loss": 1.7733,
      "step": 9240
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.3886229991912842,
      "learning_rate": 5.3226429675425045e-06,
      "loss": 1.8606,
      "step": 9250
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.9280738830566406,
      "learning_rate": 5.274343122102009e-06,
      "loss": 1.7499,
      "step": 9260
    },
    {
      "epoch": 1.79,
      "grad_norm": 4.303549766540527,
      "learning_rate": 5.226043276661515e-06,
      "loss": 1.7596,
      "step": 9270
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.7388694286346436,
      "learning_rate": 5.17774343122102e-06,
      "loss": 1.646,
      "step": 9280
    },
    {
      "epoch": 1.79,
      "grad_norm": 3.6876373291015625,
      "learning_rate": 5.129443585780526e-06,
      "loss": 1.823,
      "step": 9290
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.1067858934402466,
      "learning_rate": 5.0811437403400306e-06,
      "loss": 1.9216,
      "step": 9300
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.860492467880249,
      "learning_rate": 5.032843894899537e-06,
      "loss": 1.7673,
      "step": 9310
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.3714590072631836,
      "learning_rate": 4.984544049459041e-06,
      "loss": 1.7786,
      "step": 9320
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.156168818473816,
      "learning_rate": 4.936244204018548e-06,
      "loss": 1.7898,
      "step": 9330
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.527188777923584,
      "learning_rate": 4.887944358578052e-06,
      "loss": 1.7147,
      "step": 9340
    },
    {
      "epoch": 1.81,
      "grad_norm": 2.0144739151000977,
      "learning_rate": 4.839644513137558e-06,
      "loss": 1.7885,
      "step": 9350
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.756521463394165,
      "learning_rate": 4.791344667697063e-06,
      "loss": 1.6927,
      "step": 9360
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9970149397850037,
      "learning_rate": 4.743044822256569e-06,
      "loss": 1.6938,
      "step": 9370
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.0524674654006958,
      "learning_rate": 4.694744976816074e-06,
      "loss": 1.8037,
      "step": 9380
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.0682162046432495,
      "learning_rate": 4.64644513137558e-06,
      "loss": 1.8213,
      "step": 9390
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.3975163698196411,
      "learning_rate": 4.598145285935085e-06,
      "loss": 1.7568,
      "step": 9400
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.576174020767212,
      "learning_rate": 4.549845440494591e-06,
      "loss": 1.8132,
      "step": 9410
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1294969320297241,
      "learning_rate": 4.501545595054096e-06,
      "loss": 1.6835,
      "step": 9420
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.5916757583618164,
      "learning_rate": 4.4532457496136015e-06,
      "loss": 1.7744,
      "step": 9430
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.9032318592071533,
      "learning_rate": 4.404945904173107e-06,
      "loss": 1.8335,
      "step": 9440
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.609347939491272,
      "learning_rate": 4.356646058732612e-06,
      "loss": 1.6991,
      "step": 9450
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.2273186445236206,
      "learning_rate": 4.308346213292118e-06,
      "loss": 1.8097,
      "step": 9460
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.778259813785553,
      "learning_rate": 4.260046367851623e-06,
      "loss": 1.9288,
      "step": 9470
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.3764934539794922,
      "learning_rate": 4.2117465224111284e-06,
      "loss": 1.7407,
      "step": 9480
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.9191023111343384,
      "learning_rate": 4.163446676970634e-06,
      "loss": 1.7929,
      "step": 9490
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.4221350848674774,
      "learning_rate": 4.115146831530139e-06,
      "loss": 1.8954,
      "step": 9500
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.0180779695510864,
      "learning_rate": 4.066846986089645e-06,
      "loss": 1.7649,
      "step": 9510
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.507514715194702,
      "learning_rate": 4.01854714064915e-06,
      "loss": 1.666,
      "step": 9520
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.051076889038086,
      "learning_rate": 3.970247295208655e-06,
      "loss": 1.8848,
      "step": 9530
    },
    {
      "epoch": 1.84,
      "grad_norm": 10.213396072387695,
      "learning_rate": 3.921947449768161e-06,
      "loss": 2.05,
      "step": 9540
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.9199389219284058,
      "learning_rate": 3.873647604327666e-06,
      "loss": 1.711,
      "step": 9550
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.0912866592407227,
      "learning_rate": 3.8253477588871716e-06,
      "loss": 1.8076,
      "step": 9560
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.1200344562530518,
      "learning_rate": 3.777047913446677e-06,
      "loss": 1.706,
      "step": 9570
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.409944772720337,
      "learning_rate": 3.7287480680061828e-06,
      "loss": 1.6414,
      "step": 9580
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.4020943641662598,
      "learning_rate": 3.6804482225656877e-06,
      "loss": 1.8604,
      "step": 9590
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.8397265076637268,
      "learning_rate": 3.6321483771251936e-06,
      "loss": 1.8327,
      "step": 9600
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.4754491448402405,
      "learning_rate": 3.583848531684699e-06,
      "loss": 1.7055,
      "step": 9610
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.1909176111221313,
      "learning_rate": 3.5355486862442043e-06,
      "loss": 1.7434,
      "step": 9620
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.1462182998657227,
      "learning_rate": 3.4872488408037097e-06,
      "loss": 1.8646,
      "step": 9630
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.4604111909866333,
      "learning_rate": 3.438948995363215e-06,
      "loss": 1.7567,
      "step": 9640
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.5792278051376343,
      "learning_rate": 3.3906491499227205e-06,
      "loss": 1.8201,
      "step": 9650
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.9978938102722168,
      "learning_rate": 3.342349304482226e-06,
      "loss": 1.8547,
      "step": 9660
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.859353065490723,
      "learning_rate": 3.2940494590417313e-06,
      "loss": 1.7283,
      "step": 9670
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.7497342228889465,
      "learning_rate": 3.2457496136012367e-06,
      "loss": 1.7363,
      "step": 9680
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.9165763258934021,
      "learning_rate": 3.197449768160742e-06,
      "loss": 1.6697,
      "step": 9690
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.2065337896347046,
      "learning_rate": 3.1491499227202475e-06,
      "loss": 1.8106,
      "step": 9700
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.5602689385414124,
      "learning_rate": 3.100850077279753e-06,
      "loss": 1.6911,
      "step": 9710
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.5545883774757385,
      "learning_rate": 3.0525502318392582e-06,
      "loss": 1.9554,
      "step": 9720
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.8602769374847412,
      "learning_rate": 3.0042503863987636e-06,
      "loss": 1.8079,
      "step": 9730
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.4627169370651245,
      "learning_rate": 2.955950540958269e-06,
      "loss": 1.7591,
      "step": 9740
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.0087920427322388,
      "learning_rate": 2.9076506955177744e-06,
      "loss": 1.8205,
      "step": 9750
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.49042996764183044,
      "learning_rate": 2.85935085007728e-06,
      "loss": 1.8223,
      "step": 9760
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.6517759561538696,
      "learning_rate": 2.811051004636785e-06,
      "loss": 1.8197,
      "step": 9770
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.7441182136535645,
      "learning_rate": 2.7627511591962906e-06,
      "loss": 1.7397,
      "step": 9780
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.753214716911316,
      "learning_rate": 2.714451313755796e-06,
      "loss": 1.7401,
      "step": 9790
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.7737526893615723,
      "learning_rate": 2.6661514683153014e-06,
      "loss": 1.7745,
      "step": 9800
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.1883704662322998,
      "learning_rate": 2.6178516228748067e-06,
      "loss": 1.793,
      "step": 9810
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.2923448085784912,
      "learning_rate": 2.569551777434312e-06,
      "loss": 1.7989,
      "step": 9820
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.739108681678772,
      "learning_rate": 2.5212519319938175e-06,
      "loss": 1.6708,
      "step": 9830
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.602681577205658,
      "learning_rate": 2.472952086553323e-06,
      "loss": 1.6072,
      "step": 9840
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.251086950302124,
      "learning_rate": 2.4246522411128283e-06,
      "loss": 1.8324,
      "step": 9850
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.2607067823410034,
      "learning_rate": 2.3763523956723337e-06,
      "loss": 1.6875,
      "step": 9860
    },
    {
      "epoch": 1.91,
      "grad_norm": 2.9772236347198486,
      "learning_rate": 2.328052550231839e-06,
      "loss": 1.8292,
      "step": 9870
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.5073024034500122,
      "learning_rate": 2.2797527047913445e-06,
      "loss": 1.7022,
      "step": 9880
    },
    {
      "epoch": 1.91,
      "grad_norm": 6.669209957122803,
      "learning_rate": 2.23145285935085e-06,
      "loss": 1.7934,
      "step": 9890
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.44852861762046814,
      "learning_rate": 2.1831530139103553e-06,
      "loss": 1.7163,
      "step": 9900
    },
    {
      "epoch": 1.91,
      "grad_norm": 7.2179999351501465,
      "learning_rate": 2.1348531684698606e-06,
      "loss": 1.7933,
      "step": 9910
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.9225682020187378,
      "learning_rate": 2.0865533230293665e-06,
      "loss": 1.7603,
      "step": 9920
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.94617760181427,
      "learning_rate": 2.038253477588872e-06,
      "loss": 1.6746,
      "step": 9930
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.755794107913971,
      "learning_rate": 1.9899536321483772e-06,
      "loss": 1.7399,
      "step": 9940
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.0714517831802368,
      "learning_rate": 1.9416537867078826e-06,
      "loss": 1.5993,
      "step": 9950
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.1427415609359741,
      "learning_rate": 1.8933539412673882e-06,
      "loss": 1.822,
      "step": 9960
    },
    {
      "epoch": 1.93,
      "grad_norm": 2.3591294288635254,
      "learning_rate": 1.8450540958268936e-06,
      "loss": 1.6736,
      "step": 9970
    },
    {
      "epoch": 1.93,
      "grad_norm": 2.4841058254241943,
      "learning_rate": 1.796754250386399e-06,
      "loss": 1.8753,
      "step": 9980
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.71187824010849,
      "learning_rate": 1.7484544049459044e-06,
      "loss": 1.6946,
      "step": 9990
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.128287434577942,
      "learning_rate": 1.7001545595054098e-06,
      "loss": 1.9468,
      "step": 10000
    }
  ],
  "logging_steps": 10,
  "max_steps": 10352,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 4.633315637170176e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
