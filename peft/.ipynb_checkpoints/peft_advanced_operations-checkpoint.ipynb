{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT 进阶操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 自定义模型适配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from peft import LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = nn.Sequential(\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 2)\n",
    ")\n",
    "net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "2.weight\n",
      "2.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in net1.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(target_modules=[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = get_peft_model(net1, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(\n",
       "        in_features=10, out_features=10, bias=True\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 多适配器加载与切换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = nn.Sequential(\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 2)\n",
    ")\n",
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = LoraConfig(target_modules=[\"0\"])\n",
    "model2 = get_peft_model(net2, config1)\n",
    "model2.save_pretrained(\"./loraA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = LoraConfig(target_modules=[\"2\"])\n",
    "model2 = get_peft_model(net2, config2)\n",
    "model2.save_pretrained(\"./loraB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = nn.Sequential(\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 2)\n",
    ")\n",
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(\n",
       "        in_features=10, out_features=10, bias=True\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (loraA): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (loraA): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (loraA): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = PeftModel.from_pretrained(net2, model_id=\"./loraA/\", adapter_name=\"loraA\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(\n",
       "        in_features=10, out_features=10, bias=True\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (loraA): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (loraA): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (loraA): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Linear(\n",
       "        in_features=10, out_features=2, bias=True\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (loraB): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (loraB): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (loraB): Linear(in_features=8, out_features=2, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_adapter(\"./loraB/\", adapter_name=\"loraB\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loraA'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.active_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0515, -1.3579]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.0.weight Parameter containing:\n",
      "tensor([[ 0.0986, -0.0116,  0.0064,  0.0869,  0.2262, -0.3124,  0.1880,  0.3149,\n",
      "          0.2943, -0.0315],\n",
      "        [-0.0699, -0.0435,  0.0111, -0.1133,  0.3130,  0.0972, -0.2215,  0.1551,\n",
      "          0.2324,  0.0888],\n",
      "        [ 0.2493,  0.1299,  0.2266, -0.1462,  0.1131,  0.3011,  0.1412,  0.1223,\n",
      "          0.2984,  0.1015],\n",
      "        [ 0.1902,  0.0493, -0.0610,  0.0432, -0.2254, -0.2858,  0.1830, -0.0072,\n",
      "         -0.3141, -0.1154],\n",
      "        [-0.1394,  0.2665,  0.1222, -0.2287, -0.1341, -0.0824, -0.2547, -0.0844,\n",
      "          0.2754,  0.2924],\n",
      "        [-0.1255,  0.1472, -0.1192,  0.1369, -0.2551, -0.0734,  0.0825,  0.2721,\n",
      "          0.1332,  0.2202],\n",
      "        [ 0.2424,  0.0797, -0.0516,  0.2836, -0.0615, -0.0863,  0.1314,  0.2934,\n",
      "         -0.2413,  0.1712],\n",
      "        [ 0.1404, -0.1963, -0.2448, -0.1210,  0.0751,  0.1120, -0.0822,  0.1745,\n",
      "          0.0505,  0.2288],\n",
      "        [-0.2516, -0.2477, -0.0183, -0.1723, -0.1651,  0.2466, -0.0038,  0.0557,\n",
      "          0.0989, -0.1819],\n",
      "        [ 0.1085, -0.0637,  0.1741,  0.0849, -0.2190, -0.0978, -0.3000, -0.1884,\n",
      "          0.1080, -0.0885]])\n",
      "base_model.model.0.bias Parameter containing:\n",
      "tensor([-0.2671,  0.0970, -0.2438, -0.1769, -0.0733, -0.0233,  0.0663, -0.2083,\n",
      "         0.1190,  0.1972])\n",
      "base_model.model.0.lora_A.loraA.weight Parameter containing:\n",
      "tensor([[ 0.3028,  0.0997, -0.0919,  0.0745,  0.0629, -0.2509, -0.0513, -0.1735,\n",
      "          0.1442, -0.3141],\n",
      "        [ 0.2739,  0.0333,  0.0267,  0.2722, -0.0705, -0.0109,  0.1769,  0.0311,\n",
      "          0.3159, -0.2809],\n",
      "        [-0.0828,  0.1572, -0.0483,  0.2229, -0.0512,  0.2074,  0.0546, -0.0414,\n",
      "          0.2727, -0.1675],\n",
      "        [ 0.2154,  0.1958, -0.1842, -0.1363, -0.0945,  0.0239,  0.2254,  0.0295,\n",
      "         -0.0553, -0.0894],\n",
      "        [ 0.1200, -0.1996, -0.3120,  0.0882, -0.3053,  0.1058, -0.2171,  0.3111,\n",
      "          0.3057, -0.0749],\n",
      "        [ 0.1605,  0.0428,  0.2389,  0.1708, -0.2286, -0.0020, -0.2466, -0.0828,\n",
      "         -0.2667, -0.2970],\n",
      "        [-0.2008, -0.1300, -0.0703, -0.0044,  0.2105,  0.1476, -0.2721, -0.2891,\n",
      "          0.2193,  0.0534],\n",
      "        [ 0.1130, -0.1667,  0.2394,  0.2537,  0.1036, -0.3028, -0.0861,  0.1435,\n",
      "         -0.0810, -0.2027]])\n",
      "base_model.model.0.lora_B.loraA.weight Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "base_model.model.2.weight Parameter containing:\n",
      "tensor([[-2.1176e-01,  2.3368e-01, -2.7855e-01,  1.0136e-03,  2.0829e-01,\n",
      "         -9.0417e-03,  1.0318e-01,  1.3207e-01, -3.3472e-02,  1.1437e-01],\n",
      "        [-2.1287e-01, -4.0895e-02, -3.0118e-01, -1.4885e-02,  1.7008e-04,\n",
      "          1.5871e-01,  2.3700e-01,  2.8977e-01,  1.2658e-01, -3.0241e-01]])\n",
      "base_model.model.2.bias Parameter containing:\n",
      "tensor([ 0.0341, -0.2563])\n",
      "base_model.model.2.lora_A.loraB.weight Parameter containing:\n",
      "tensor([[ 0.3001, -0.3075,  0.1194,  0.0620,  0.1965,  0.2684, -0.0672, -0.2917,\n",
      "         -0.2035, -0.1232],\n",
      "        [-0.0494, -0.0224,  0.2237, -0.0471,  0.2160,  0.0876, -0.3150, -0.2140,\n",
      "         -0.2043,  0.2178],\n",
      "        [-0.2928,  0.2868, -0.0391, -0.0366,  0.2056,  0.0255, -0.1428, -0.2541,\n",
      "         -0.0663,  0.1103],\n",
      "        [ 0.0383, -0.1350, -0.1745, -0.1332, -0.0085,  0.0570, -0.1609,  0.0773,\n",
      "          0.2093,  0.0550],\n",
      "        [ 0.1241, -0.0489,  0.2592,  0.0915,  0.0224, -0.2829, -0.0066, -0.0837,\n",
      "         -0.0426, -0.0388],\n",
      "        [-0.0430,  0.1183,  0.1897,  0.1717, -0.0156, -0.1578, -0.2238,  0.2760,\n",
      "          0.0793,  0.0422],\n",
      "        [-0.0790, -0.2429,  0.0966,  0.2370,  0.2553, -0.0066, -0.1935, -0.0787,\n",
      "         -0.2230,  0.1387],\n",
      "        [ 0.0676, -0.1387, -0.2727,  0.0904,  0.0302, -0.3072, -0.0585, -0.3021,\n",
      "          0.2977, -0.0376]])\n",
      "base_model.model.2.lora_B.loraB.weight Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    if name in [\"base_model.model.0.lora_A.loraA.weight\", \"base_model.model.0.lora_B.loraA.weight\"]:\n",
    "        param.data = torch.ones_like(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 92.0650, -21.8470]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.set_adapter(\"loraB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loraB'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.active_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0515, -1.3579]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 禁用适配器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.set_adapter(\"loraA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 92.0650, -21.8470]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0515, -1.3579]])\n"
     ]
    }
   ],
   "source": [
    "with model2.disable_adapter():\n",
    "    print(model2(torch.arange(0, 10).view(1, 10).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
