{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2QSwwm8EWtt"
   },
   "source": [
    "数据集与模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3jahoj5EUiO"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C__4iRdkD_RW"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qV2JVRwzD_RW",
    "outputId": "135c53a3-8658-4d24-a291-ee608ad4edd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'instruction', 'output'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"yahma/alpaca-cleaned\", split=\"train[:8000]\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFGw5wvfD_RX",
    "outputId": "67d99729-35e4-48a2-cf39-96418bf126f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ['', '', ''],\n",
       " 'instruction': ['Give three tips for staying healthy.',\n",
       "  'What are the three primary colors?',\n",
       "  'Describe the structure of an atom.'],\n",
       " 'output': ['1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       "  'The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).',\n",
       "  \"An atom is the basic building block of all matter and is made up of three types of particles: protons, neutrons, and electrons. The structure of an atom can be described as a nucleus at the center surrounded by a cloud of electrons.\\n\\nThe nucleus of an atom is made up of protons and neutrons. Protons are positively charged particles and neutrons are neutral particles with no charge. Both of these particles are located in the nucleus of the atom, which is at the center of the atom and contains most of the atom's mass.\\n\\nSurrounding the nucleus of the atom is a cloud of electrons. Electrons are negatively charged particles that are in constant motion around the nucleus. The electron cloud is divided into shells or orbitals, and each shell can hold a certain number of electrons. The number of electrons in the outermost shell, called the valence shell, determines the chemical properties of the atom. \\n\\nIn a neutral atom, the number of protons in the nucleus is equal to the number of electrons in the electron cloud, so the positive and negative charges balance out and the atom has no overall charge. The number of protons, also called the atomic number, determines what element the atom is.\"]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "72bb08571cdf45ea9a187504440d7fea",
      "aaa50cb471ca407ba81af23f8d939023",
      "87e4ed0c175541efad26f8d9e26f0fb2"
     ]
    },
    "id": "b6vbjp40D_RX",
    "outputId": "08a01bde-b0f7-4fd7-8c6d-59acb9d339f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bb08571cdf45ea9a187504440d7fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\徐逸飞\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\徐逸飞\\.cache\\huggingface\\hub\\models--bigscience--bloom-1b1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa50cb471ca407ba81af23f8d939023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e4ed0c175541efad26f8d9e26f0fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BloomTokenizerFast(name_or_path='bigscience/bloom-1b1', vocab_size=250680, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b1\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXaE2CcpD_RX"
   },
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 256\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\"\\n\".join([\"Human: \" + example[\"instruction\"], example[\"input\"]]).strip() + \"\\n\\nAssistant: \")\n",
    "    response = tokenizer(example[\"output\"] + tokenizer.eos_token)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"]\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a516ddd2809948e99b2f024290627377"
     ]
    },
    "id": "XqiW7x2SD_RX",
    "outputId": "10b2a5ed-9e5e-415a-8cbe-1d6867141ffd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a516ddd2809948e99b2f024290627377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLjLXRIwD_RX",
    "outputId": "c3179281-3ad0-42f7-ebdf-7983a5fc0478"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What are the three primary colors?\\n\\nAssistant: The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).</s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjcdSO_VD_RY",
    "outputId": "3902aab5-f022-4426-b34a-d4376471b2af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(filter(lambda x: x != -100, tokenized_ds[1][\"labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "b0ea5156200a4555aea1c217f743001e",
      "65daea5d1037438088e10f7bbb9ee50a"
     ]
    },
    "id": "UJTkME-FD_RY",
    "outputId": "ae205c66-d700-4fca-e2c0-cd6a50e3c3bd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ea5156200a4555aea1c217f743001e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65daea5d1037438088e10f7bbb9ee50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b1\", low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYHa3W2ZD_RY",
    "outputId": "f0c458c5-beed-41a9-861d-1c7202931324"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrefixTuningConfig(peft_type=<PeftType.PREFIX_TUNING: 'PREFIX_TUNING'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, num_virtual_tokens=10, token_dim=None, num_transformer_submodules=None, num_attention_heads=None, num_layers=None, encoder_hidden_size=None, prefix_projection=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PrefixTuningConfig, get_peft_model, TaskType\n",
    "\n",
    "config = PrefixTuningConfig(task_type=TaskType.CAUSAL_LM, num_virtual_tokens=10, prefix_projection=True)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyWPz4FSD_RY"
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALgCI7adD_RY",
    "outputId": "f57f4306-11ab-4dec-e07c-ec6886253960"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (default): PrefixEncoder(\n",
       "    (embedding): Embedding(10, 1536)\n",
       "    (transform): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1536, out_features=73728, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prompt_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZYCsF3OD_RY",
    "outputId": "539294fb-4c64-4632-9773-47554a74c24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 115,696,128 || all params: 1,181,010,432 || trainable%: 9.796367996857796\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIZZGyivD_RZ"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./chatbot\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERqGrNKXD_RZ"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d26dd5618b344581a7716c6957a4ebd9"
     ]
    },
    "id": "tbK5MTGeD_RZ",
    "outputId": "9cba061f-3e7d-473d-a0d2-d851d34e337f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26dd5618b344581a7716c6957a4ebd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.484, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2931, 'learning_rate': 4.9e-05, 'epoch': 0.02}\n",
      "{'loss': 2.136, 'learning_rate': 4.85e-05, 'epoch': 0.03}\n",
      "{'loss': 2.1706, 'learning_rate': 4.8e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0298, 'learning_rate': 4.75e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9578, 'learning_rate': 4.7e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1358, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8626, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8911, 'learning_rate': 4.55e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9588, 'learning_rate': 4.5e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7925, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8493, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0942, 'learning_rate': 4.35e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9398, 'learning_rate': 4.3e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8094, 'learning_rate': 4.25e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8911, 'learning_rate': 4.2e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9767, 'learning_rate': 4.15e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7669, 'learning_rate': 4.1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8841, 'learning_rate': 4.05e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7971, 'learning_rate': 4e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9508, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8346, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7643, 'learning_rate': 3.85e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7961, 'learning_rate': 3.8e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9506, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7983, 'learning_rate': 3.7e-05, 'epoch': 0.26}\n",
      "{'loss': 1.769, 'learning_rate': 3.65e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7678, 'learning_rate': 3.6e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8141, 'learning_rate': 3.55e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7338, 'learning_rate': 3.5e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7557, 'learning_rate': 3.45e-05, 'epoch': 0.31}\n",
      "{'loss': 1.74, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8014, 'learning_rate': 3.35e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7581, 'learning_rate': 3.3e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6968, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7629, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7867, 'learning_rate': 3.15e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7904, 'learning_rate': 3.1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8027, 'learning_rate': 3.05e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8104, 'learning_rate': 3e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9407, 'learning_rate': 2.95e-05, 'epoch': 0.41}\n",
      "{'loss': 1.7882, 'learning_rate': 2.9e-05, 'epoch': 0.42}\n",
      "{'loss': 2.0658, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7285, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8929, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.45}\n",
      "{'loss': 1.6964, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.46}\n",
      "{'loss': 1.944, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.47}\n",
      "{'loss': 1.958, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.48}\n",
      "{'loss': 1.694, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7795, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7517, 'learning_rate': 2.45e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7928, 'learning_rate': 2.4e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7729, 'learning_rate': 2.35e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7527, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7261, 'learning_rate': 2.25e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6955, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7063, 'learning_rate': 2.15e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8043, 'learning_rate': 2.1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7856, 'learning_rate': 2.05e-05, 'epoch': 0.59}\n",
      "{'loss': 1.5695, 'learning_rate': 2e-05, 'epoch': 0.6}\n",
      "{'loss': 1.6851, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7602, 'learning_rate': 1.9e-05, 'epoch': 0.62}\n",
      "{'loss': 1.6358, 'learning_rate': 1.85e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7534, 'learning_rate': 1.8e-05, 'epoch': 0.64}\n",
      "{'loss': 1.968, 'learning_rate': 1.75e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8811, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7873, 'learning_rate': 1.65e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8585, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7026, 'learning_rate': 1.55e-05, 'epoch': 0.69}\n",
      "{'loss': 1.746, 'learning_rate': 1.5e-05, 'epoch': 0.7}\n",
      "{'loss': 1.7839, 'learning_rate': 1.45e-05, 'epoch': 0.71}\n",
      "{'loss': 1.7945, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.72}\n",
      "{'loss': 1.6744, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.73}\n",
      "{'loss': 1.6554, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.74}\n",
      "{'loss': 1.7964, 'learning_rate': 1.25e-05, 'epoch': 0.75}\n",
      "{'loss': 1.8287, 'learning_rate': 1.2e-05, 'epoch': 0.76}\n",
      "{'loss': 1.7492, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.77}\n",
      "{'loss': 1.9551, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.78}\n",
      "{'loss': 1.5955, 'learning_rate': 1.05e-05, 'epoch': 0.79}\n",
      "{'loss': 1.7283, 'learning_rate': 1e-05, 'epoch': 0.8}\n",
      "{'loss': 1.9703, 'learning_rate': 9.5e-06, 'epoch': 0.81}\n",
      "{'loss': 1.9229, 'learning_rate': 9e-06, 'epoch': 0.82}\n",
      "{'loss': 1.6751, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.83}\n",
      "{'loss': 1.7391, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.84}\n",
      "{'loss': 1.8355, 'learning_rate': 7.5e-06, 'epoch': 0.85}\n",
      "{'loss': 1.8794, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 1.7755, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.87}\n",
      "{'loss': 1.8154, 'learning_rate': 6e-06, 'epoch': 0.88}\n",
      "{'loss': 1.8828, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 1.846, 'learning_rate': 5e-06, 'epoch': 0.9}\n",
      "{'loss': 1.6886, 'learning_rate': 4.5e-06, 'epoch': 0.91}\n",
      "{'loss': 1.7267, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 1.6918, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.93}\n",
      "{'loss': 1.7753, 'learning_rate': 3e-06, 'epoch': 0.94}\n",
      "{'loss': 1.7054, 'learning_rate': 2.5e-06, 'epoch': 0.95}\n",
      "{'loss': 1.7402, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.96}\n",
      "{'loss': 1.7202, 'learning_rate': 1.5e-06, 'epoch': 0.97}\n",
      "{'loss': 1.7186, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.98}\n",
      "{'loss': 1.6456, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.99}\n",
      "{'loss': 1.6402, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 1903.1187, 'train_samples_per_second': 4.204, 'train_steps_per_second': 0.525, 'train_loss': 1.8318476066589355, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=1.8318476066589355, metrics={'train_runtime': 1903.1187, 'train_samples_per_second': 4.204, 'train_steps_per_second': 0.525, 'train_loss': 1.8318476066589355, 'epoch': 1.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LossLoggingCallback(TrainerCallback):\n",
    "    def __init__(self, output_dir):\n",
    "        self.output_dir = output_dir\n",
    "        self.losses = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if 'loss' in logs:\n",
    "            self.losses.append(logs['loss'])\n",
    "            with open(f\"{self.output_dir}/losses.txt\", \"a\") as f:\n",
    "                f.write(f\"{state.global_step}: {logs['loss']}\\n\")\n",
    "\n",
    "trainer.add_callback(LossLoggingCallback(output_dir=\"./\"))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGYI1LRpD_RZ",
    "outputId": "12e561db-7732-476d-8bc1-945448661bed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: How to prepare an exam?\\n\\nAssistant: Preparing for the upcoming exam can be challenging, especially if you haven't taken a class before and don't feel comfortable with the materials being presented. Here are a few helpful tips to help you with the exam preparation process:\\n\\n1. Know the Test Pre-Tests (TPT):\\nAs recommended by some of the test authorities, take time to familiarize yourself with the test prior to taking the exam. This will help you avoid problems during the exam and ensure that you do not find yourself feeling confused or overwhelmed at the time the test is coming up.\\n\\n2. Practice\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b1\")\n",
    "model = PeftModel.from_pretrained(model, \"/kaggle/working/chatbot/checkpoint-4000\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b1\")\n",
    "model = model.cuda()\n",
    "ipt = tokenizer(\"Human: {}\\n{}\".format(\"How to prepare an exam?\", \"\").strip() + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
    "tokenizer.decode(model.generate(**ipt, max_length=128, do_sample=True)[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
