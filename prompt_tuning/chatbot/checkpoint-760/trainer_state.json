{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.76,
  "eval_steps": 500,
  "global_step": 760,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.6870361566543579,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 2.4391,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6608906388282776,
      "learning_rate": 4.9e-05,
      "loss": 2.4893,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5243343114852905,
      "learning_rate": 4.85e-05,
      "loss": 2.4627,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.57200026512146,
      "learning_rate": 4.8e-05,
      "loss": 2.5278,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3944616317749023,
      "learning_rate": 4.75e-05,
      "loss": 2.6109,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9582581520080566,
      "learning_rate": 4.7e-05,
      "loss": 2.3909,
      "step": 60
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.15701425075531,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 2.4162,
      "step": 70
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.310897350311279,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.5592,
      "step": 80
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0848174095153809,
      "learning_rate": 4.55e-05,
      "loss": 2.4701,
      "step": 90
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9100693464279175,
      "learning_rate": 4.5e-05,
      "loss": 2.2615,
      "step": 100
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8064520359039307,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 2.1659,
      "step": 110
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.942606449127197,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.3789,
      "step": 120
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.327280521392822,
      "learning_rate": 4.35e-05,
      "loss": 2.0539,
      "step": 130
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.644955635070801,
      "learning_rate": 4.3e-05,
      "loss": 2.1171,
      "step": 140
    },
    {
      "epoch": 0.15,
      "grad_norm": 11.997719764709473,
      "learning_rate": 4.25e-05,
      "loss": 2.0674,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1074724197387695,
      "learning_rate": 4.2e-05,
      "loss": 2.1475,
      "step": 160
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.1811017990112305,
      "learning_rate": 4.15e-05,
      "loss": 2.0617,
      "step": 170
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.8143200874328613,
      "learning_rate": 4.1e-05,
      "loss": 2.0819,
      "step": 180
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.8766496181488037,
      "learning_rate": 4.05e-05,
      "loss": 2.1633,
      "step": 190
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.9494924545288086,
      "learning_rate": 4e-05,
      "loss": 2.2017,
      "step": 200
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.083515167236328,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 2.0355,
      "step": 210
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5962917804718018,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.9358,
      "step": 220
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.452695369720459,
      "learning_rate": 3.85e-05,
      "loss": 2.0159,
      "step": 230
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.257032871246338,
      "learning_rate": 3.8e-05,
      "loss": 2.0023,
      "step": 240
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.83630895614624,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 2.0006,
      "step": 250
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.093113899230957,
      "learning_rate": 3.7e-05,
      "loss": 1.9894,
      "step": 260
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.7863786220550537,
      "learning_rate": 3.65e-05,
      "loss": 1.9553,
      "step": 270
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.943046569824219,
      "learning_rate": 3.6e-05,
      "loss": 2.0399,
      "step": 280
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.547587871551514,
      "learning_rate": 3.55e-05,
      "loss": 1.9494,
      "step": 290
    },
    {
      "epoch": 0.3,
      "grad_norm": 7.323053359985352,
      "learning_rate": 3.5e-05,
      "loss": 1.9444,
      "step": 300
    },
    {
      "epoch": 0.31,
      "grad_norm": 4.130950927734375,
      "learning_rate": 3.45e-05,
      "loss": 1.9372,
      "step": 310
    },
    {
      "epoch": 0.32,
      "grad_norm": 14.688751220703125,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.9383,
      "step": 320
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.5410637855529785,
      "learning_rate": 3.35e-05,
      "loss": 2.0647,
      "step": 330
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.5745023488998413,
      "learning_rate": 3.3e-05,
      "loss": 2.1042,
      "step": 340
    },
    {
      "epoch": 0.35,
      "grad_norm": 5.503964900970459,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 2.0128,
      "step": 350
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.6022908687591553,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.9848,
      "step": 360
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.4175314903259277,
      "learning_rate": 3.15e-05,
      "loss": 1.9197,
      "step": 370
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.717776775360107,
      "learning_rate": 3.1e-05,
      "loss": 2.032,
      "step": 380
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.920449733734131,
      "learning_rate": 3.05e-05,
      "loss": 1.9469,
      "step": 390
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.391157150268555,
      "learning_rate": 3e-05,
      "loss": 2.2138,
      "step": 400
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.19682502746582,
      "learning_rate": 2.95e-05,
      "loss": 2.0539,
      "step": 410
    },
    {
      "epoch": 0.42,
      "grad_norm": 5.230288028717041,
      "learning_rate": 2.9e-05,
      "loss": 1.8327,
      "step": 420
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.397407531738281,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 1.9347,
      "step": 430
    },
    {
      "epoch": 0.44,
      "grad_norm": 7.066709518432617,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.8698,
      "step": 440
    },
    {
      "epoch": 0.45,
      "grad_norm": 28.584409713745117,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 2.017,
      "step": 450
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.052536487579346,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 2.0546,
      "step": 460
    },
    {
      "epoch": 0.47,
      "grad_norm": 4.416062831878662,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 1.894,
      "step": 470
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6943247318267822,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.7557,
      "step": 480
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.79905366897583,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 1.9787,
      "step": 490
    },
    {
      "epoch": 0.5,
      "grad_norm": 15.31166934967041,
      "learning_rate": 2.5e-05,
      "loss": 1.9457,
      "step": 500
    },
    {
      "epoch": 0.51,
      "grad_norm": 7.347099304199219,
      "learning_rate": 2.45e-05,
      "loss": 1.8485,
      "step": 510
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.7078397274017334,
      "learning_rate": 2.4e-05,
      "loss": 1.9258,
      "step": 520
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.162527561187744,
      "learning_rate": 2.35e-05,
      "loss": 1.9353,
      "step": 530
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.3117501735687256,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 2.012,
      "step": 540
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.376501083374023,
      "learning_rate": 2.25e-05,
      "loss": 1.9245,
      "step": 550
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.120516300201416,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.9975,
      "step": 560
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.7491207122802734,
      "learning_rate": 2.15e-05,
      "loss": 1.8968,
      "step": 570
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.35284423828125,
      "learning_rate": 2.1e-05,
      "loss": 1.8347,
      "step": 580
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.495387077331543,
      "learning_rate": 2.05e-05,
      "loss": 1.9507,
      "step": 590
    },
    {
      "epoch": 0.6,
      "grad_norm": 7.028389930725098,
      "learning_rate": 2e-05,
      "loss": 2.0982,
      "step": 600
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.104323387145996,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 1.804,
      "step": 610
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.529031753540039,
      "learning_rate": 1.9e-05,
      "loss": 1.8554,
      "step": 620
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.05096697807312,
      "learning_rate": 1.85e-05,
      "loss": 1.9133,
      "step": 630
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4347541332244873,
      "learning_rate": 1.8e-05,
      "loss": 2.1438,
      "step": 640
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6905996799468994,
      "learning_rate": 1.75e-05,
      "loss": 1.8425,
      "step": 650
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.824453353881836,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 2.1236,
      "step": 660
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7918866872787476,
      "learning_rate": 1.65e-05,
      "loss": 1.8309,
      "step": 670
    },
    {
      "epoch": 0.68,
      "grad_norm": 5.8652143478393555,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.799,
      "step": 680
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.375917434692383,
      "learning_rate": 1.55e-05,
      "loss": 2.0229,
      "step": 690
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.961401462554932,
      "learning_rate": 1.5e-05,
      "loss": 1.8294,
      "step": 700
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.6290934085845947,
      "learning_rate": 1.45e-05,
      "loss": 1.9226,
      "step": 710
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.0041160583496094,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 1.8617,
      "step": 720
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.7108278274536133,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 1.8995,
      "step": 730
    },
    {
      "epoch": 0.74,
      "grad_norm": 6.270410537719727,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 1.8949,
      "step": 740
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.541668891906738,
      "learning_rate": 1.25e-05,
      "loss": 2.293,
      "step": 750
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.434535503387451,
      "learning_rate": 1.2e-05,
      "loss": 1.9989,
      "step": 760
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 20,
  "total_flos": 3387649948581888.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
