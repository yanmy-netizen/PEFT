{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9319938176197837,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.6952130794525146,
      "learning_rate": 4.99517001545595e-05,
      "loss": 2.3613,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.183243751525879,
      "learning_rate": 4.9903400309119017e-05,
      "loss": 2.5768,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1986126899719238,
      "learning_rate": 4.985510046367852e-05,
      "loss": 2.3788,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.387294888496399,
      "learning_rate": 4.9806800618238024e-05,
      "loss": 2.4473,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1235780715942383,
      "learning_rate": 4.975850077279753e-05,
      "loss": 2.4996,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.736091613769531,
      "learning_rate": 4.971020092735704e-05,
      "loss": 2.4346,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.822939395904541,
      "learning_rate": 4.966190108191654e-05,
      "loss": 2.3759,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.313560962677002,
      "learning_rate": 4.9613601236476046e-05,
      "loss": 2.3025,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9182207584381104,
      "learning_rate": 4.956530139103555e-05,
      "loss": 2.3724,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.117903232574463,
      "learning_rate": 4.951700154559505e-05,
      "loss": 2.4049,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.1914827823638916,
      "learning_rate": 4.946870170015456e-05,
      "loss": 2.3989,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.259281635284424,
      "learning_rate": 4.942040185471407e-05,
      "loss": 2.4131,
      "step": 120
    },
    {
      "epoch": 0.03,
      "grad_norm": 4.3069682121276855,
      "learning_rate": 4.9372102009273574e-05,
      "loss": 2.3845,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9793556928634644,
      "learning_rate": 4.9323802163833074e-05,
      "loss": 2.2621,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.0242269039154053,
      "learning_rate": 4.927550231839259e-05,
      "loss": 2.1371,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.1038546562194824,
      "learning_rate": 4.922720247295209e-05,
      "loss": 2.1287,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.3663008213043213,
      "learning_rate": 4.917890262751159e-05,
      "loss": 2.1448,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.087797164916992,
      "learning_rate": 4.91306027820711e-05,
      "loss": 2.0251,
      "step": 180
    },
    {
      "epoch": 0.04,
      "grad_norm": 5.996822834014893,
      "learning_rate": 4.90823029366306e-05,
      "loss": 2.0962,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.3530635833740234,
      "learning_rate": 4.903400309119011e-05,
      "loss": 2.2075,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.8747148513793945,
      "learning_rate": 4.898570324574962e-05,
      "loss": 2.052,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.3040990829467773,
      "learning_rate": 4.8937403400309124e-05,
      "loss": 1.9337,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9122782945632935,
      "learning_rate": 4.8889103554868625e-05,
      "loss": 1.9931,
      "step": 230
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.6003308296203613,
      "learning_rate": 4.884080370942813e-05,
      "loss": 2.1124,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.9456045627593994,
      "learning_rate": 4.879250386398764e-05,
      "loss": 1.8863,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.4297473430633545,
      "learning_rate": 4.874420401854714e-05,
      "loss": 1.8988,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.2641115188598633,
      "learning_rate": 4.8695904173106646e-05,
      "loss": 2.0068,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.9935734272003174,
      "learning_rate": 4.864760432766615e-05,
      "loss": 2.007,
      "step": 280
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.1890127658843994,
      "learning_rate": 4.859930448222566e-05,
      "loss": 1.998,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.5513503551483154,
      "learning_rate": 4.855100463678516e-05,
      "loss": 1.9437,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.7734007835388184,
      "learning_rate": 4.8502704791344675e-05,
      "loss": 2.0917,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.7612900733947754,
      "learning_rate": 4.8454404945904175e-05,
      "loss": 1.979,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 4.001107692718506,
      "learning_rate": 4.840610510046368e-05,
      "loss": 1.8691,
      "step": 330
    },
    {
      "epoch": 0.07,
      "grad_norm": 5.443861484527588,
      "learning_rate": 4.835780525502319e-05,
      "loss": 1.9055,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.551750898361206,
      "learning_rate": 4.830950540958269e-05,
      "loss": 1.8947,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 8.722006797790527,
      "learning_rate": 4.8261205564142196e-05,
      "loss": 1.8771,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.28235125541687,
      "learning_rate": 4.8212905718701704e-05,
      "loss": 1.8091,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7078304290771484,
      "learning_rate": 4.816460587326121e-05,
      "loss": 1.8064,
      "step": 380
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.568758487701416,
      "learning_rate": 4.811630602782071e-05,
      "loss": 1.9166,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7732477188110352,
      "learning_rate": 4.806800618238022e-05,
      "loss": 1.8279,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.656886577606201,
      "learning_rate": 4.8019706336939725e-05,
      "loss": 1.8925,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 22.87028694152832,
      "learning_rate": 4.797140649149923e-05,
      "loss": 2.1203,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.4611101150512695,
      "learning_rate": 4.792310664605873e-05,
      "loss": 1.8683,
      "step": 430
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.83835506439209,
      "learning_rate": 4.787480680061824e-05,
      "loss": 1.8912,
      "step": 440
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.7936975955963135,
      "learning_rate": 4.782650695517775e-05,
      "loss": 1.9135,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.774324893951416,
      "learning_rate": 4.777820710973725e-05,
      "loss": 1.9763,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.7948038578033447,
      "learning_rate": 4.772990726429676e-05,
      "loss": 1.9199,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.1624581813812256,
      "learning_rate": 4.768160741885626e-05,
      "loss": 1.8332,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 40.05567169189453,
      "learning_rate": 4.763330757341577e-05,
      "loss": 1.8372,
      "step": 490
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9748016595840454,
      "learning_rate": 4.7585007727975275e-05,
      "loss": 1.9393,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.452067852020264,
      "learning_rate": 4.7536707882534776e-05,
      "loss": 1.9101,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.2443437576293945,
      "learning_rate": 4.748840803709428e-05,
      "loss": 1.8814,
      "step": 520
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.585831642150879,
      "learning_rate": 4.744010819165379e-05,
      "loss": 1.8528,
      "step": 530
    },
    {
      "epoch": 0.1,
      "grad_norm": 10.75661849975586,
      "learning_rate": 4.73918083462133e-05,
      "loss": 1.9778,
      "step": 540
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.361304521560669,
      "learning_rate": 4.73435085007728e-05,
      "loss": 1.8977,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 26.470163345336914,
      "learning_rate": 4.7295208655332304e-05,
      "loss": 1.8497,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 4.57697057723999,
      "learning_rate": 4.724690880989181e-05,
      "loss": 1.9307,
      "step": 570
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.849081039428711,
      "learning_rate": 4.719860896445132e-05,
      "loss": 1.8797,
      "step": 580
    },
    {
      "epoch": 0.11,
      "grad_norm": 4.037753105163574,
      "learning_rate": 4.715030911901082e-05,
      "loss": 1.9652,
      "step": 590
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.7869791984558105,
      "learning_rate": 4.7102009273570326e-05,
      "loss": 1.9669,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.200281143188477,
      "learning_rate": 4.705370942812983e-05,
      "loss": 2.0297,
      "step": 610
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.3953386545181274,
      "learning_rate": 4.700540958268933e-05,
      "loss": 1.9454,
      "step": 620
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6511081457138062,
      "learning_rate": 4.695710973724885e-05,
      "loss": 2.0874,
      "step": 630
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.012295961380005,
      "learning_rate": 4.690880989180835e-05,
      "loss": 1.9898,
      "step": 640
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.812899351119995,
      "learning_rate": 4.6860510046367854e-05,
      "loss": 1.7943,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.7036640644073486,
      "learning_rate": 4.681221020092736e-05,
      "loss": 1.9486,
      "step": 660
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.9193990230560303,
      "learning_rate": 4.676391035548687e-05,
      "loss": 1.951,
      "step": 670
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.7719452381134033,
      "learning_rate": 4.671561051004637e-05,
      "loss": 1.9582,
      "step": 680
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.5993008613586426,
      "learning_rate": 4.6667310664605876e-05,
      "loss": 1.9697,
      "step": 690
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1069839000701904,
      "learning_rate": 4.661901081916538e-05,
      "loss": 1.7461,
      "step": 700
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.370456695556641,
      "learning_rate": 4.6570710973724883e-05,
      "loss": 2.0404,
      "step": 710
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.728409290313721,
      "learning_rate": 4.652241112828439e-05,
      "loss": 2.1074,
      "step": 720
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.0455079078674316,
      "learning_rate": 4.64741112828439e-05,
      "loss": 1.795,
      "step": 730
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1296138763427734,
      "learning_rate": 4.6425811437403405e-05,
      "loss": 1.9309,
      "step": 740
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.455259323120117,
      "learning_rate": 4.6377511591962905e-05,
      "loss": 1.9298,
      "step": 750
    },
    {
      "epoch": 0.15,
      "grad_norm": 10.165374755859375,
      "learning_rate": 4.632921174652241e-05,
      "loss": 1.9967,
      "step": 760
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.626016616821289,
      "learning_rate": 4.628091190108192e-05,
      "loss": 1.8854,
      "step": 770
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.502910614013672,
      "learning_rate": 4.623261205564142e-05,
      "loss": 1.9135,
      "step": 780
    },
    {
      "epoch": 0.15,
      "grad_norm": 37.3153190612793,
      "learning_rate": 4.618431221020093e-05,
      "loss": 1.9801,
      "step": 790
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.253145694732666,
      "learning_rate": 4.6136012364760434e-05,
      "loss": 1.848,
      "step": 800
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.363650321960449,
      "learning_rate": 4.608771251931994e-05,
      "loss": 1.926,
      "step": 810
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.9635963439941406,
      "learning_rate": 4.603941267387945e-05,
      "loss": 1.8989,
      "step": 820
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.169500350952148,
      "learning_rate": 4.5991112828438955e-05,
      "loss": 2.0606,
      "step": 830
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.9269747734069824,
      "learning_rate": 4.5942812982998455e-05,
      "loss": 1.9664,
      "step": 840
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.0796103477478027,
      "learning_rate": 4.589451313755796e-05,
      "loss": 1.8007,
      "step": 850
    },
    {
      "epoch": 0.17,
      "grad_norm": 12.981791496276855,
      "learning_rate": 4.584621329211747e-05,
      "loss": 1.9093,
      "step": 860
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.416938543319702,
      "learning_rate": 4.579791344667697e-05,
      "loss": 1.8857,
      "step": 870
    },
    {
      "epoch": 0.17,
      "grad_norm": 12.409919738769531,
      "learning_rate": 4.574961360123648e-05,
      "loss": 1.978,
      "step": 880
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.251299858093262,
      "learning_rate": 4.5701313755795984e-05,
      "loss": 1.8833,
      "step": 890
    },
    {
      "epoch": 0.17,
      "grad_norm": 13.004460334777832,
      "learning_rate": 4.565301391035549e-05,
      "loss": 1.9861,
      "step": 900
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.003139019012451,
      "learning_rate": 4.560471406491499e-05,
      "loss": 2.0302,
      "step": 910
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.5728323459625244,
      "learning_rate": 4.5556414219474505e-05,
      "loss": 1.9378,
      "step": 920
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.3800220489501953,
      "learning_rate": 4.5508114374034005e-05,
      "loss": 1.8472,
      "step": 930
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9931972026824951,
      "learning_rate": 4.5459814528593506e-05,
      "loss": 2.0399,
      "step": 940
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.643507719039917,
      "learning_rate": 4.541151468315302e-05,
      "loss": 1.9019,
      "step": 950
    },
    {
      "epoch": 0.19,
      "grad_norm": 8.236115455627441,
      "learning_rate": 4.536321483771252e-05,
      "loss": 1.9523,
      "step": 960
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.160095453262329,
      "learning_rate": 4.531491499227203e-05,
      "loss": 1.7054,
      "step": 970
    },
    {
      "epoch": 0.19,
      "grad_norm": 9.300468444824219,
      "learning_rate": 4.5266615146831534e-05,
      "loss": 1.8157,
      "step": 980
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4965473413467407,
      "learning_rate": 4.521831530139104e-05,
      "loss": 1.8892,
      "step": 990
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.333144664764404,
      "learning_rate": 4.517001545595054e-05,
      "loss": 1.9278,
      "step": 1000
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.5562005043029785,
      "learning_rate": 4.512171561051005e-05,
      "loss": 1.8374,
      "step": 1010
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.3903586864471436,
      "learning_rate": 4.5073415765069556e-05,
      "loss": 1.8438,
      "step": 1020
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.716273307800293,
      "learning_rate": 4.5025115919629056e-05,
      "loss": 1.9008,
      "step": 1030
    },
    {
      "epoch": 0.2,
      "grad_norm": 6.0370707511901855,
      "learning_rate": 4.497681607418856e-05,
      "loss": 1.8675,
      "step": 1040
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.450009346008301,
      "learning_rate": 4.492851622874807e-05,
      "loss": 1.8888,
      "step": 1050
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.462710857391357,
      "learning_rate": 4.488021638330758e-05,
      "loss": 1.9466,
      "step": 1060
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.8886890411376953,
      "learning_rate": 4.483191653786708e-05,
      "loss": 1.8108,
      "step": 1070
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1387217044830322,
      "learning_rate": 4.478361669242659e-05,
      "loss": 1.9413,
      "step": 1080
    },
    {
      "epoch": 0.21,
      "grad_norm": 11.819329261779785,
      "learning_rate": 4.473531684698609e-05,
      "loss": 1.7817,
      "step": 1090
    },
    {
      "epoch": 0.21,
      "grad_norm": 4.312195301055908,
      "learning_rate": 4.468701700154559e-05,
      "loss": 1.9266,
      "step": 1100
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.0746054649353027,
      "learning_rate": 4.4638717156105106e-05,
      "loss": 1.9308,
      "step": 1110
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.454268932342529,
      "learning_rate": 4.4590417310664606e-05,
      "loss": 1.9332,
      "step": 1120
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8852344751358032,
      "learning_rate": 4.454211746522411e-05,
      "loss": 1.8946,
      "step": 1130
    },
    {
      "epoch": 0.22,
      "grad_norm": 11.299515724182129,
      "learning_rate": 4.449381761978362e-05,
      "loss": 1.9049,
      "step": 1140
    },
    {
      "epoch": 0.22,
      "grad_norm": 11.07925796508789,
      "learning_rate": 4.444551777434313e-05,
      "loss": 1.889,
      "step": 1150
    },
    {
      "epoch": 0.22,
      "grad_norm": 6.145484924316406,
      "learning_rate": 4.439721792890263e-05,
      "loss": 1.7332,
      "step": 1160
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.778743028640747,
      "learning_rate": 4.4348918083462135e-05,
      "loss": 1.9254,
      "step": 1170
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.811751842498779,
      "learning_rate": 4.430061823802164e-05,
      "loss": 1.8122,
      "step": 1180
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.745587348937988,
      "learning_rate": 4.425231839258114e-05,
      "loss": 1.7709,
      "step": 1190
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.549016952514648,
      "learning_rate": 4.420401854714065e-05,
      "loss": 2.0004,
      "step": 1200
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.961223602294922,
      "learning_rate": 4.4155718701700156e-05,
      "loss": 1.9025,
      "step": 1210
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.562114715576172,
      "learning_rate": 4.4107418856259663e-05,
      "loss": 1.9785,
      "step": 1220
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.991974353790283,
      "learning_rate": 4.4059119010819164e-05,
      "loss": 1.9266,
      "step": 1230
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.509738922119141,
      "learning_rate": 4.401081916537868e-05,
      "loss": 1.8367,
      "step": 1240
    },
    {
      "epoch": 0.24,
      "grad_norm": 15.9738130569458,
      "learning_rate": 4.396251931993818e-05,
      "loss": 1.7226,
      "step": 1250
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.1144256591796875,
      "learning_rate": 4.3914219474497685e-05,
      "loss": 1.8011,
      "step": 1260
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.7025392055511475,
      "learning_rate": 4.386591962905719e-05,
      "loss": 1.9474,
      "step": 1270
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.1804072856903076,
      "learning_rate": 4.381761978361669e-05,
      "loss": 1.9226,
      "step": 1280
    },
    {
      "epoch": 0.25,
      "grad_norm": 18.124618530273438,
      "learning_rate": 4.37693199381762e-05,
      "loss": 2.0048,
      "step": 1290
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.767136812210083,
      "learning_rate": 4.3721020092735707e-05,
      "loss": 1.9171,
      "step": 1300
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.05792236328125,
      "learning_rate": 4.3672720247295214e-05,
      "loss": 1.7904,
      "step": 1310
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.1671011447906494,
      "learning_rate": 4.3624420401854714e-05,
      "loss": 1.9665,
      "step": 1320
    },
    {
      "epoch": 0.26,
      "grad_norm": 5.876224517822266,
      "learning_rate": 4.357612055641422e-05,
      "loss": 1.7598,
      "step": 1330
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2059117555618286,
      "learning_rate": 4.352782071097373e-05,
      "loss": 1.9327,
      "step": 1340
    },
    {
      "epoch": 0.26,
      "grad_norm": 25.940826416015625,
      "learning_rate": 4.347952086553323e-05,
      "loss": 2.0656,
      "step": 1350
    },
    {
      "epoch": 0.26,
      "grad_norm": 10.639177322387695,
      "learning_rate": 4.3431221020092735e-05,
      "loss": 1.811,
      "step": 1360
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.580872058868408,
      "learning_rate": 4.338292117465224e-05,
      "loss": 1.7938,
      "step": 1370
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.211583614349365,
      "learning_rate": 4.333462132921175e-05,
      "loss": 1.8614,
      "step": 1380
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.600402355194092,
      "learning_rate": 4.328632148377125e-05,
      "loss": 1.8669,
      "step": 1390
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.359062433242798,
      "learning_rate": 4.3238021638330764e-05,
      "loss": 1.8299,
      "step": 1400
    },
    {
      "epoch": 0.27,
      "grad_norm": 6.040949821472168,
      "learning_rate": 4.3189721792890264e-05,
      "loss": 1.8542,
      "step": 1410
    },
    {
      "epoch": 0.27,
      "grad_norm": 47.24175262451172,
      "learning_rate": 4.314142194744977e-05,
      "loss": 1.8005,
      "step": 1420
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.3951847553253174,
      "learning_rate": 4.309312210200928e-05,
      "loss": 2.086,
      "step": 1430
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.438138008117676,
      "learning_rate": 4.304482225656878e-05,
      "loss": 1.9315,
      "step": 1440
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.959702014923096,
      "learning_rate": 4.2996522411128286e-05,
      "loss": 1.8363,
      "step": 1450
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.117316722869873,
      "learning_rate": 4.294822256568779e-05,
      "loss": 1.7365,
      "step": 1460
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.5448826551437378,
      "learning_rate": 4.28999227202473e-05,
      "loss": 1.7805,
      "step": 1470
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.13176155090332,
      "learning_rate": 4.28516228748068e-05,
      "loss": 1.756,
      "step": 1480
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.0978899002075195,
      "learning_rate": 4.280332302936631e-05,
      "loss": 1.7931,
      "step": 1490
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.88679838180542,
      "learning_rate": 4.2755023183925814e-05,
      "loss": 1.8555,
      "step": 1500
    },
    {
      "epoch": 0.29,
      "grad_norm": 12.140260696411133,
      "learning_rate": 4.270672333848532e-05,
      "loss": 1.8076,
      "step": 1510
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.564975738525391,
      "learning_rate": 4.265842349304482e-05,
      "loss": 1.9383,
      "step": 1520
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.09921932220459,
      "learning_rate": 4.261012364760433e-05,
      "loss": 1.8708,
      "step": 1530
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1268646717071533,
      "learning_rate": 4.2561823802163836e-05,
      "loss": 1.7426,
      "step": 1540
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9633113145828247,
      "learning_rate": 4.2513523956723336e-05,
      "loss": 1.8095,
      "step": 1550
    },
    {
      "epoch": 0.3,
      "grad_norm": 9.931534767150879,
      "learning_rate": 4.246522411128285e-05,
      "loss": 1.7244,
      "step": 1560
    },
    {
      "epoch": 0.3,
      "grad_norm": 13.340558052062988,
      "learning_rate": 4.241692426584235e-05,
      "loss": 1.8882,
      "step": 1570
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.895544528961182,
      "learning_rate": 4.236862442040186e-05,
      "loss": 1.8738,
      "step": 1580
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.08443546295166,
      "learning_rate": 4.2320324574961365e-05,
      "loss": 1.8909,
      "step": 1590
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.1307764053344727,
      "learning_rate": 4.2272024729520865e-05,
      "loss": 1.9133,
      "step": 1600
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.7121036052703857,
      "learning_rate": 4.222372488408037e-05,
      "loss": 1.837,
      "step": 1610
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.723223090171814,
      "learning_rate": 4.217542503863988e-05,
      "loss": 1.8976,
      "step": 1620
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.699071168899536,
      "learning_rate": 4.2127125193199386e-05,
      "loss": 1.9347,
      "step": 1630
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.5151283740997314,
      "learning_rate": 4.2078825347758886e-05,
      "loss": 1.8207,
      "step": 1640
    },
    {
      "epoch": 0.32,
      "grad_norm": 17.385149002075195,
      "learning_rate": 4.2030525502318393e-05,
      "loss": 1.814,
      "step": 1650
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1188859939575195,
      "learning_rate": 4.19822256568779e-05,
      "loss": 1.8751,
      "step": 1660
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.519043445587158,
      "learning_rate": 4.193392581143741e-05,
      "loss": 1.8335,
      "step": 1670
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.5805091857910156,
      "learning_rate": 4.188562596599691e-05,
      "loss": 1.8547,
      "step": 1680
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.916931629180908,
      "learning_rate": 4.1837326120556415e-05,
      "loss": 1.8901,
      "step": 1690
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.8464996814727783,
      "learning_rate": 4.178902627511592e-05,
      "loss": 1.7813,
      "step": 1700
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.9669604301452637,
      "learning_rate": 4.174072642967542e-05,
      "loss": 1.943,
      "step": 1710
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.6229796409606934,
      "learning_rate": 4.1692426584234936e-05,
      "loss": 1.7764,
      "step": 1720
    },
    {
      "epoch": 0.33,
      "grad_norm": 11.162008285522461,
      "learning_rate": 4.1644126738794437e-05,
      "loss": 1.7107,
      "step": 1730
    },
    {
      "epoch": 0.34,
      "grad_norm": 35.83546829223633,
      "learning_rate": 4.1595826893353944e-05,
      "loss": 1.8399,
      "step": 1740
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8140829801559448,
      "learning_rate": 4.154752704791345e-05,
      "loss": 1.8398,
      "step": 1750
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.990091323852539,
      "learning_rate": 4.149922720247296e-05,
      "loss": 1.9031,
      "step": 1760
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.497929573059082,
      "learning_rate": 4.145092735703246e-05,
      "loss": 1.8933,
      "step": 1770
    },
    {
      "epoch": 0.34,
      "grad_norm": 25.236906051635742,
      "learning_rate": 4.1402627511591965e-05,
      "loss": 1.9138,
      "step": 1780
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.930001735687256,
      "learning_rate": 4.135432766615147e-05,
      "loss": 1.9421,
      "step": 1790
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.230068683624268,
      "learning_rate": 4.130602782071097e-05,
      "loss": 1.9049,
      "step": 1800
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.650096893310547,
      "learning_rate": 4.125772797527048e-05,
      "loss": 1.8888,
      "step": 1810
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.7961456775665283,
      "learning_rate": 4.120942812982999e-05,
      "loss": 1.9154,
      "step": 1820
    },
    {
      "epoch": 0.35,
      "grad_norm": 5.16135311126709,
      "learning_rate": 4.1161128284389494e-05,
      "loss": 1.8156,
      "step": 1830
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.73392915725708,
      "learning_rate": 4.1112828438948994e-05,
      "loss": 1.7253,
      "step": 1840
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.9019685983657837,
      "learning_rate": 4.10645285935085e-05,
      "loss": 1.8935,
      "step": 1850
    },
    {
      "epoch": 0.36,
      "grad_norm": 7.488630294799805,
      "learning_rate": 4.101622874806801e-05,
      "loss": 1.7425,
      "step": 1860
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.938796520233154,
      "learning_rate": 4.096792890262751e-05,
      "loss": 1.8772,
      "step": 1870
    },
    {
      "epoch": 0.36,
      "grad_norm": 11.727036476135254,
      "learning_rate": 4.091962905718702e-05,
      "loss": 1.9816,
      "step": 1880
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.230480194091797,
      "learning_rate": 4.087132921174652e-05,
      "loss": 1.702,
      "step": 1890
    },
    {
      "epoch": 0.37,
      "grad_norm": 26.87595558166504,
      "learning_rate": 4.082302936630603e-05,
      "loss": 1.8935,
      "step": 1900
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.163985252380371,
      "learning_rate": 4.077472952086554e-05,
      "loss": 1.9435,
      "step": 1910
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.403268814086914,
      "learning_rate": 4.0726429675425044e-05,
      "loss": 1.7532,
      "step": 1920
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.475089073181152,
      "learning_rate": 4.0678129829984544e-05,
      "loss": 1.8185,
      "step": 1930
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.465537071228027,
      "learning_rate": 4.062982998454405e-05,
      "loss": 1.9508,
      "step": 1940
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.773558497428894,
      "learning_rate": 4.058153013910356e-05,
      "loss": 1.8661,
      "step": 1950
    },
    {
      "epoch": 0.38,
      "grad_norm": 5.039844512939453,
      "learning_rate": 4.053323029366306e-05,
      "loss": 1.91,
      "step": 1960
    },
    {
      "epoch": 0.38,
      "grad_norm": 11.313459396362305,
      "learning_rate": 4.0484930448222566e-05,
      "loss": 1.9924,
      "step": 1970
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3732187747955322,
      "learning_rate": 4.043663060278207e-05,
      "loss": 2.049,
      "step": 1980
    },
    {
      "epoch": 0.38,
      "grad_norm": 5.918323040008545,
      "learning_rate": 4.038833075734158e-05,
      "loss": 1.9459,
      "step": 1990
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.248070001602173,
      "learning_rate": 4.034003091190108e-05,
      "loss": 1.9556,
      "step": 2000
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.132269859313965,
      "learning_rate": 4.0291731066460594e-05,
      "loss": 1.8646,
      "step": 2010
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.669501304626465,
      "learning_rate": 4.0243431221020095e-05,
      "loss": 1.9783,
      "step": 2020
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.25454044342041,
      "learning_rate": 4.0195131375579595e-05,
      "loss": 1.8164,
      "step": 2030
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.350891590118408,
      "learning_rate": 4.014683153013911e-05,
      "loss": 1.8148,
      "step": 2040
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.4193339347839355,
      "learning_rate": 4.009853168469861e-05,
      "loss": 1.7839,
      "step": 2050
    },
    {
      "epoch": 0.4,
      "grad_norm": 10.461792945861816,
      "learning_rate": 4.0050231839258116e-05,
      "loss": 1.7858,
      "step": 2060
    },
    {
      "epoch": 0.4,
      "grad_norm": 25.49658966064453,
      "learning_rate": 4.000193199381762e-05,
      "loss": 1.7509,
      "step": 2070
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.9863080978393555,
      "learning_rate": 3.995363214837713e-05,
      "loss": 1.8387,
      "step": 2080
    },
    {
      "epoch": 0.4,
      "grad_norm": 10.31047534942627,
      "learning_rate": 3.990533230293663e-05,
      "loss": 1.8179,
      "step": 2090
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.54580819606781,
      "learning_rate": 3.985703245749614e-05,
      "loss": 1.9323,
      "step": 2100
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.832729816436768,
      "learning_rate": 3.9808732612055645e-05,
      "loss": 1.9076,
      "step": 2110
    },
    {
      "epoch": 0.41,
      "grad_norm": 8.361499786376953,
      "learning_rate": 3.9760432766615145e-05,
      "loss": 1.8135,
      "step": 2120
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.010718822479248,
      "learning_rate": 3.971213292117465e-05,
      "loss": 1.8703,
      "step": 2130
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.622775554656982,
      "learning_rate": 3.966383307573416e-05,
      "loss": 1.7136,
      "step": 2140
    },
    {
      "epoch": 0.42,
      "grad_norm": 10.623066902160645,
      "learning_rate": 3.9615533230293666e-05,
      "loss": 1.9582,
      "step": 2150
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.7632899284362793,
      "learning_rate": 3.956723338485317e-05,
      "loss": 1.7981,
      "step": 2160
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.954681873321533,
      "learning_rate": 3.951893353941268e-05,
      "loss": 1.9413,
      "step": 2170
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.932830572128296,
      "learning_rate": 3.947063369397218e-05,
      "loss": 1.9025,
      "step": 2180
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.216355323791504,
      "learning_rate": 3.942233384853168e-05,
      "loss": 1.9041,
      "step": 2190
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.2635037899017334,
      "learning_rate": 3.9374034003091195e-05,
      "loss": 1.7896,
      "step": 2200
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.922110557556152,
      "learning_rate": 3.9325734157650695e-05,
      "loss": 1.7715,
      "step": 2210
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.041293144226074,
      "learning_rate": 3.92774343122102e-05,
      "loss": 1.7626,
      "step": 2220
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.818547248840332,
      "learning_rate": 3.922913446676971e-05,
      "loss": 1.8113,
      "step": 2230
    },
    {
      "epoch": 0.43,
      "grad_norm": 7.936916351318359,
      "learning_rate": 3.9180834621329217e-05,
      "loss": 1.8915,
      "step": 2240
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.147339344024658,
      "learning_rate": 3.913253477588872e-05,
      "loss": 1.8882,
      "step": 2250
    },
    {
      "epoch": 0.44,
      "grad_norm": 9.880908012390137,
      "learning_rate": 3.9084234930448224e-05,
      "loss": 1.7421,
      "step": 2260
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.234659194946289,
      "learning_rate": 3.903593508500773e-05,
      "loss": 1.9303,
      "step": 2270
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.3499672412872314,
      "learning_rate": 3.898763523956723e-05,
      "loss": 2.0678,
      "step": 2280
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.4243998527526855,
      "learning_rate": 3.893933539412674e-05,
      "loss": 1.8422,
      "step": 2290
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.432167053222656,
      "learning_rate": 3.8891035548686246e-05,
      "loss": 1.8645,
      "step": 2300
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.2146527767181396,
      "learning_rate": 3.884273570324575e-05,
      "loss": 2.0676,
      "step": 2310
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.1357760429382324,
      "learning_rate": 3.879443585780525e-05,
      "loss": 1.8436,
      "step": 2320
    },
    {
      "epoch": 0.45,
      "grad_norm": 12.311492919921875,
      "learning_rate": 3.874613601236477e-05,
      "loss": 1.9596,
      "step": 2330
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.2033400535583496,
      "learning_rate": 3.869783616692427e-05,
      "loss": 1.7825,
      "step": 2340
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.9871931076049805,
      "learning_rate": 3.8649536321483774e-05,
      "loss": 1.9361,
      "step": 2350
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.426130771636963,
      "learning_rate": 3.860123647604328e-05,
      "loss": 1.8318,
      "step": 2360
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.738211750984192,
      "learning_rate": 3.855293663060278e-05,
      "loss": 1.838,
      "step": 2370
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.150750160217285,
      "learning_rate": 3.850463678516229e-05,
      "loss": 1.6542,
      "step": 2380
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.557709693908691,
      "learning_rate": 3.8456336939721796e-05,
      "loss": 1.868,
      "step": 2390
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.5531798601150513,
      "learning_rate": 3.84080370942813e-05,
      "loss": 1.9073,
      "step": 2400
    },
    {
      "epoch": 0.47,
      "grad_norm": 5.179232120513916,
      "learning_rate": 3.83597372488408e-05,
      "loss": 1.8541,
      "step": 2410
    },
    {
      "epoch": 0.47,
      "grad_norm": 7.08230447769165,
      "learning_rate": 3.831143740340031e-05,
      "loss": 1.9529,
      "step": 2420
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.1318578720092773,
      "learning_rate": 3.826313755795982e-05,
      "loss": 1.8493,
      "step": 2430
    },
    {
      "epoch": 0.47,
      "grad_norm": 27.316499710083008,
      "learning_rate": 3.821483771251932e-05,
      "loss": 1.9506,
      "step": 2440
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.3565173149108887,
      "learning_rate": 3.8166537867078825e-05,
      "loss": 1.8307,
      "step": 2450
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.6094257831573486,
      "learning_rate": 3.811823802163833e-05,
      "loss": 1.8477,
      "step": 2460
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2411718368530273,
      "learning_rate": 3.806993817619784e-05,
      "loss": 1.9677,
      "step": 2470
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.029281139373779,
      "learning_rate": 3.802163833075734e-05,
      "loss": 1.8462,
      "step": 2480
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.875865936279297,
      "learning_rate": 3.797333848531685e-05,
      "loss": 1.8616,
      "step": 2490
    },
    {
      "epoch": 0.48,
      "grad_norm": 9.078120231628418,
      "learning_rate": 3.792503863987635e-05,
      "loss": 1.7976,
      "step": 2500
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7357147932052612,
      "learning_rate": 3.787673879443586e-05,
      "loss": 1.8465,
      "step": 2510
    },
    {
      "epoch": 0.49,
      "grad_norm": 11.69768238067627,
      "learning_rate": 3.782843894899537e-05,
      "loss": 1.8725,
      "step": 2520
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.920971393585205,
      "learning_rate": 3.778013910355487e-05,
      "loss": 1.8665,
      "step": 2530
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.428796291351318,
      "learning_rate": 3.7731839258114375e-05,
      "loss": 1.8354,
      "step": 2540
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.917808532714844,
      "learning_rate": 3.768353941267388e-05,
      "loss": 1.8074,
      "step": 2550
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.3973546028137207,
      "learning_rate": 3.763523956723339e-05,
      "loss": 1.8705,
      "step": 2560
    },
    {
      "epoch": 0.5,
      "grad_norm": 8.300432205200195,
      "learning_rate": 3.758693972179289e-05,
      "loss": 1.7768,
      "step": 2570
    },
    {
      "epoch": 0.5,
      "grad_norm": 14.064913749694824,
      "learning_rate": 3.7538639876352396e-05,
      "loss": 1.8406,
      "step": 2580
    },
    {
      "epoch": 0.5,
      "grad_norm": 6.962840557098389,
      "learning_rate": 3.7490340030911904e-05,
      "loss": 1.7676,
      "step": 2590
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.34713077545166,
      "learning_rate": 3.744204018547141e-05,
      "loss": 1.7879,
      "step": 2600
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.04306173324585,
      "learning_rate": 3.739374034003091e-05,
      "loss": 1.8239,
      "step": 2610
    },
    {
      "epoch": 0.51,
      "grad_norm": 6.602762699127197,
      "learning_rate": 3.734544049459042e-05,
      "loss": 1.9727,
      "step": 2620
    },
    {
      "epoch": 0.51,
      "grad_norm": 9.847169876098633,
      "learning_rate": 3.7297140649149925e-05,
      "loss": 1.8039,
      "step": 2630
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.194820880889893,
      "learning_rate": 3.7248840803709425e-05,
      "loss": 1.8609,
      "step": 2640
    },
    {
      "epoch": 0.51,
      "grad_norm": 16.273696899414062,
      "learning_rate": 3.720054095826894e-05,
      "loss": 1.972,
      "step": 2650
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.897979736328125,
      "learning_rate": 3.715224111282844e-05,
      "loss": 1.9279,
      "step": 2660
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.109610557556152,
      "learning_rate": 3.710394126738795e-05,
      "loss": 1.8339,
      "step": 2670
    },
    {
      "epoch": 0.52,
      "grad_norm": 36.249473571777344,
      "learning_rate": 3.7055641421947454e-05,
      "loss": 1.8841,
      "step": 2680
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.692767858505249,
      "learning_rate": 3.7007341576506954e-05,
      "loss": 1.8882,
      "step": 2690
    },
    {
      "epoch": 0.52,
      "grad_norm": 12.493163108825684,
      "learning_rate": 3.695904173106646e-05,
      "loss": 1.7381,
      "step": 2700
    },
    {
      "epoch": 0.52,
      "grad_norm": 4.575489521026611,
      "learning_rate": 3.691074188562597e-05,
      "loss": 1.9245,
      "step": 2710
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.6878461837768555,
      "learning_rate": 3.6862442040185475e-05,
      "loss": 1.8788,
      "step": 2720
    },
    {
      "epoch": 0.53,
      "grad_norm": 10.225109100341797,
      "learning_rate": 3.6814142194744976e-05,
      "loss": 1.9688,
      "step": 2730
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.0398647785186768,
      "learning_rate": 3.676584234930448e-05,
      "loss": 1.9166,
      "step": 2740
    },
    {
      "epoch": 0.53,
      "grad_norm": 5.059499263763428,
      "learning_rate": 3.671754250386399e-05,
      "loss": 1.7876,
      "step": 2750
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.859312534332275,
      "learning_rate": 3.66692426584235e-05,
      "loss": 1.7395,
      "step": 2760
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.170384407043457,
      "learning_rate": 3.6620942812983e-05,
      "loss": 1.8261,
      "step": 2770
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.042862892150879,
      "learning_rate": 3.6572642967542504e-05,
      "loss": 1.9477,
      "step": 2780
    },
    {
      "epoch": 0.54,
      "grad_norm": 11.551658630371094,
      "learning_rate": 3.652434312210201e-05,
      "loss": 1.9024,
      "step": 2790
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.9315028190612793,
      "learning_rate": 3.647604327666151e-05,
      "loss": 1.9517,
      "step": 2800
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.722214221954346,
      "learning_rate": 3.6427743431221026e-05,
      "loss": 1.9341,
      "step": 2810
    },
    {
      "epoch": 0.54,
      "grad_norm": 8.21446418762207,
      "learning_rate": 3.6379443585780526e-05,
      "loss": 1.6734,
      "step": 2820
    },
    {
      "epoch": 0.55,
      "grad_norm": 5.189526081085205,
      "learning_rate": 3.633114374034003e-05,
      "loss": 1.8354,
      "step": 2830
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.014118194580078,
      "learning_rate": 3.628284389489954e-05,
      "loss": 1.785,
      "step": 2840
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.377841472625732,
      "learning_rate": 3.623454404945905e-05,
      "loss": 1.9194,
      "step": 2850
    },
    {
      "epoch": 0.55,
      "grad_norm": 9.87926959991455,
      "learning_rate": 3.618624420401855e-05,
      "loss": 1.9221,
      "step": 2860
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.3811988830566406,
      "learning_rate": 3.6137944358578054e-05,
      "loss": 1.8972,
      "step": 2870
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.9480912685394287,
      "learning_rate": 3.608964451313756e-05,
      "loss": 1.7153,
      "step": 2880
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.2037694454193115,
      "learning_rate": 3.604134466769706e-05,
      "loss": 1.8525,
      "step": 2890
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.439150810241699,
      "learning_rate": 3.599304482225657e-05,
      "loss": 2.0049,
      "step": 2900
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.301414966583252,
      "learning_rate": 3.5944744976816076e-05,
      "loss": 1.89,
      "step": 2910
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.3591151237487793,
      "learning_rate": 3.589644513137558e-05,
      "loss": 1.8819,
      "step": 2920
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.17438268661499,
      "learning_rate": 3.5848145285935083e-05,
      "loss": 1.9,
      "step": 2930
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.862037658691406,
      "learning_rate": 3.57998454404946e-05,
      "loss": 1.8599,
      "step": 2940
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.6656672954559326,
      "learning_rate": 3.57515455950541e-05,
      "loss": 1.7558,
      "step": 2950
    },
    {
      "epoch": 0.57,
      "grad_norm": 12.669565200805664,
      "learning_rate": 3.57032457496136e-05,
      "loss": 1.7715,
      "step": 2960
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.185690402984619,
      "learning_rate": 3.565494590417311e-05,
      "loss": 1.8303,
      "step": 2970
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.2230384349823,
      "learning_rate": 3.560664605873261e-05,
      "loss": 1.8816,
      "step": 2980
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.1517586708068848,
      "learning_rate": 3.555834621329212e-05,
      "loss": 1.9675,
      "step": 2990
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.408500671386719,
      "learning_rate": 3.5510046367851626e-05,
      "loss": 1.7506,
      "step": 3000
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.130856037139893,
      "learning_rate": 3.546174652241113e-05,
      "loss": 1.822,
      "step": 3010
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.327934741973877,
      "learning_rate": 3.5413446676970634e-05,
      "loss": 1.7838,
      "step": 3020
    },
    {
      "epoch": 0.59,
      "grad_norm": 7.1476149559021,
      "learning_rate": 3.536514683153014e-05,
      "loss": 1.8322,
      "step": 3030
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.430832862854004,
      "learning_rate": 3.531684698608965e-05,
      "loss": 1.7192,
      "step": 3040
    },
    {
      "epoch": 0.59,
      "grad_norm": 6.65607213973999,
      "learning_rate": 3.526854714064915e-05,
      "loss": 1.8056,
      "step": 3050
    },
    {
      "epoch": 0.59,
      "grad_norm": 10.39964485168457,
      "learning_rate": 3.5220247295208655e-05,
      "loss": 1.7576,
      "step": 3060
    },
    {
      "epoch": 0.59,
      "grad_norm": 10.10191535949707,
      "learning_rate": 3.517194744976816e-05,
      "loss": 1.9186,
      "step": 3070
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.976663827896118,
      "learning_rate": 3.512364760432767e-05,
      "loss": 1.8778,
      "step": 3080
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.288331031799316,
      "learning_rate": 3.507534775888717e-05,
      "loss": 1.6782,
      "step": 3090
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.503210067749023,
      "learning_rate": 3.5027047913446684e-05,
      "loss": 1.8281,
      "step": 3100
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.718104362487793,
      "learning_rate": 3.4978748068006184e-05,
      "loss": 1.7938,
      "step": 3110
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.895859479904175,
      "learning_rate": 3.4930448222565684e-05,
      "loss": 1.8566,
      "step": 3120
    },
    {
      "epoch": 0.6,
      "grad_norm": 5.523487091064453,
      "learning_rate": 3.48821483771252e-05,
      "loss": 1.8966,
      "step": 3130
    },
    {
      "epoch": 0.61,
      "grad_norm": 19.263002395629883,
      "learning_rate": 3.48338485316847e-05,
      "loss": 1.7655,
      "step": 3140
    },
    {
      "epoch": 0.61,
      "grad_norm": 9.711136817932129,
      "learning_rate": 3.4785548686244205e-05,
      "loss": 1.7887,
      "step": 3150
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.627271890640259,
      "learning_rate": 3.473724884080371e-05,
      "loss": 1.9361,
      "step": 3160
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.232484817504883,
      "learning_rate": 3.468894899536322e-05,
      "loss": 1.8201,
      "step": 3170
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.66845178604126,
      "learning_rate": 3.464064914992272e-05,
      "loss": 1.7993,
      "step": 3180
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.7626965045928955,
      "learning_rate": 3.459234930448223e-05,
      "loss": 1.9251,
      "step": 3190
    },
    {
      "epoch": 0.62,
      "grad_norm": 9.417237281799316,
      "learning_rate": 3.4544049459041734e-05,
      "loss": 1.7198,
      "step": 3200
    },
    {
      "epoch": 0.62,
      "grad_norm": 7.799199104309082,
      "learning_rate": 3.4495749613601234e-05,
      "loss": 1.8945,
      "step": 3210
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.9896304607391357,
      "learning_rate": 3.444744976816074e-05,
      "loss": 1.8436,
      "step": 3220
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.457015037536621,
      "learning_rate": 3.439914992272025e-05,
      "loss": 1.8038,
      "step": 3230
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.367854595184326,
      "learning_rate": 3.4350850077279756e-05,
      "loss": 1.912,
      "step": 3240
    },
    {
      "epoch": 0.63,
      "grad_norm": 7.4675517082214355,
      "learning_rate": 3.4302550231839256e-05,
      "loss": 1.9659,
      "step": 3250
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.150112628936768,
      "learning_rate": 3.425425038639877e-05,
      "loss": 1.8226,
      "step": 3260
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.91427755355835,
      "learning_rate": 3.420595054095827e-05,
      "loss": 1.8506,
      "step": 3270
    },
    {
      "epoch": 0.63,
      "grad_norm": 8.996949195861816,
      "learning_rate": 3.415765069551777e-05,
      "loss": 1.9493,
      "step": 3280
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.965056896209717,
      "learning_rate": 3.4109350850077284e-05,
      "loss": 1.9208,
      "step": 3290
    },
    {
      "epoch": 0.64,
      "grad_norm": 10.810364723205566,
      "learning_rate": 3.4061051004636785e-05,
      "loss": 1.9424,
      "step": 3300
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.325346946716309,
      "learning_rate": 3.401275115919629e-05,
      "loss": 1.7764,
      "step": 3310
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.9616990089416504,
      "learning_rate": 3.39644513137558e-05,
      "loss": 1.7425,
      "step": 3320
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5930992364883423,
      "learning_rate": 3.3916151468315306e-05,
      "loss": 1.9194,
      "step": 3330
    },
    {
      "epoch": 0.65,
      "grad_norm": 13.465858459472656,
      "learning_rate": 3.3867851622874806e-05,
      "loss": 1.9028,
      "step": 3340
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.028616905212402,
      "learning_rate": 3.381955177743431e-05,
      "loss": 1.9572,
      "step": 3350
    },
    {
      "epoch": 0.65,
      "grad_norm": 12.820734977722168,
      "learning_rate": 3.377125193199382e-05,
      "loss": 1.7704,
      "step": 3360
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.556613922119141,
      "learning_rate": 3.372295208655332e-05,
      "loss": 1.8628,
      "step": 3370
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.239555358886719,
      "learning_rate": 3.367465224111283e-05,
      "loss": 1.7967,
      "step": 3380
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.547943592071533,
      "learning_rate": 3.3626352395672335e-05,
      "loss": 1.7946,
      "step": 3390
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.9927279949188232,
      "learning_rate": 3.357805255023184e-05,
      "loss": 1.8809,
      "step": 3400
    },
    {
      "epoch": 0.66,
      "grad_norm": 6.699876308441162,
      "learning_rate": 3.352975270479134e-05,
      "loss": 1.8786,
      "step": 3410
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.505736827850342,
      "learning_rate": 3.3481452859350856e-05,
      "loss": 1.8167,
      "step": 3420
    },
    {
      "epoch": 0.66,
      "grad_norm": 5.060746669769287,
      "learning_rate": 3.3433153013910356e-05,
      "loss": 1.9419,
      "step": 3430
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.9902162551879883,
      "learning_rate": 3.3384853168469863e-05,
      "loss": 1.8842,
      "step": 3440
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.503751754760742,
      "learning_rate": 3.333655332302937e-05,
      "loss": 1.746,
      "step": 3450
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.684444427490234,
      "learning_rate": 3.328825347758887e-05,
      "loss": 1.8374,
      "step": 3460
    },
    {
      "epoch": 0.67,
      "grad_norm": 6.408141613006592,
      "learning_rate": 3.323995363214838e-05,
      "loss": 1.8009,
      "step": 3470
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.819361448287964,
      "learning_rate": 3.3191653786707885e-05,
      "loss": 1.7106,
      "step": 3480
    },
    {
      "epoch": 0.67,
      "grad_norm": 13.807634353637695,
      "learning_rate": 3.314335394126739e-05,
      "loss": 1.9423,
      "step": 3490
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.368885040283203,
      "learning_rate": 3.309505409582689e-05,
      "loss": 1.9393,
      "step": 3500
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.411798000335693,
      "learning_rate": 3.30467542503864e-05,
      "loss": 1.7554,
      "step": 3510
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.7509548664093018,
      "learning_rate": 3.2998454404945907e-05,
      "loss": 1.9719,
      "step": 3520
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.7330336570739746,
      "learning_rate": 3.295015455950541e-05,
      "loss": 1.931,
      "step": 3530
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9862231016159058,
      "learning_rate": 3.2901854714064914e-05,
      "loss": 1.8557,
      "step": 3540
    },
    {
      "epoch": 0.69,
      "grad_norm": 11.120268821716309,
      "learning_rate": 3.285355486862442e-05,
      "loss": 1.7841,
      "step": 3550
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.453091144561768,
      "learning_rate": 3.280525502318393e-05,
      "loss": 1.8065,
      "step": 3560
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.909779071807861,
      "learning_rate": 3.275695517774343e-05,
      "loss": 1.7864,
      "step": 3570
    },
    {
      "epoch": 0.69,
      "grad_norm": 14.695740699768066,
      "learning_rate": 3.270865533230294e-05,
      "loss": 1.8728,
      "step": 3580
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.755377769470215,
      "learning_rate": 3.266035548686244e-05,
      "loss": 1.7525,
      "step": 3590
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.507752418518066,
      "learning_rate": 3.261205564142195e-05,
      "loss": 1.9156,
      "step": 3600
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.164869785308838,
      "learning_rate": 3.256375579598146e-05,
      "loss": 1.8115,
      "step": 3610
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.6340601444244385,
      "learning_rate": 3.251545595054096e-05,
      "loss": 1.8544,
      "step": 3620
    },
    {
      "epoch": 0.7,
      "grad_norm": 16.50075340270996,
      "learning_rate": 3.2467156105100464e-05,
      "loss": 1.7901,
      "step": 3630
    },
    {
      "epoch": 0.7,
      "grad_norm": 15.10525131225586,
      "learning_rate": 3.241885625965997e-05,
      "loss": 1.8879,
      "step": 3640
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.488665819168091,
      "learning_rate": 3.237055641421948e-05,
      "loss": 1.8412,
      "step": 3650
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.85136079788208,
      "learning_rate": 3.232225656877898e-05,
      "loss": 1.7318,
      "step": 3660
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8085191249847412,
      "learning_rate": 3.2273956723338486e-05,
      "loss": 1.8383,
      "step": 3670
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.6460180282592773,
      "learning_rate": 3.222565687789799e-05,
      "loss": 1.7547,
      "step": 3680
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.381690502166748,
      "learning_rate": 3.21773570324575e-05,
      "loss": 1.8659,
      "step": 3690
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.055645227432251,
      "learning_rate": 3.2129057187017e-05,
      "loss": 1.8227,
      "step": 3700
    },
    {
      "epoch": 0.72,
      "grad_norm": 14.535872459411621,
      "learning_rate": 3.208075734157651e-05,
      "loss": 1.8652,
      "step": 3710
    },
    {
      "epoch": 0.72,
      "grad_norm": 12.670079231262207,
      "learning_rate": 3.2032457496136014e-05,
      "loss": 1.7452,
      "step": 3720
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.767311096191406,
      "learning_rate": 3.1984157650695515e-05,
      "loss": 1.8125,
      "step": 3730
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.47534704208374,
      "learning_rate": 3.193585780525503e-05,
      "loss": 1.8291,
      "step": 3740
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.9743971824646,
      "learning_rate": 3.188755795981453e-05,
      "loss": 1.9044,
      "step": 3750
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.4926745891571045,
      "learning_rate": 3.1839258114374036e-05,
      "loss": 1.8397,
      "step": 3760
    },
    {
      "epoch": 0.73,
      "grad_norm": 14.671433448791504,
      "learning_rate": 3.179095826893354e-05,
      "loss": 1.9185,
      "step": 3770
    },
    {
      "epoch": 0.73,
      "grad_norm": 31.361635208129883,
      "learning_rate": 3.174265842349305e-05,
      "loss": 1.8324,
      "step": 3780
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.921238660812378,
      "learning_rate": 3.169435857805255e-05,
      "loss": 1.8593,
      "step": 3790
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.04133939743042,
      "learning_rate": 3.164605873261206e-05,
      "loss": 1.7985,
      "step": 3800
    },
    {
      "epoch": 0.74,
      "grad_norm": 6.64030122756958,
      "learning_rate": 3.1597758887171565e-05,
      "loss": 1.8624,
      "step": 3810
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.578744649887085,
      "learning_rate": 3.1549459041731065e-05,
      "loss": 1.8128,
      "step": 3820
    },
    {
      "epoch": 0.74,
      "grad_norm": 6.266772747039795,
      "learning_rate": 3.150115919629057e-05,
      "loss": 1.8047,
      "step": 3830
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.170428514480591,
      "learning_rate": 3.145285935085008e-05,
      "loss": 1.7666,
      "step": 3840
    },
    {
      "epoch": 0.74,
      "grad_norm": 13.412786483764648,
      "learning_rate": 3.1404559505409586e-05,
      "loss": 1.8959,
      "step": 3850
    },
    {
      "epoch": 0.75,
      "grad_norm": 10.125597953796387,
      "learning_rate": 3.1356259659969086e-05,
      "loss": 1.8546,
      "step": 3860
    },
    {
      "epoch": 0.75,
      "grad_norm": 8.32446002960205,
      "learning_rate": 3.1307959814528594e-05,
      "loss": 1.8167,
      "step": 3870
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.3168509006500244,
      "learning_rate": 3.12596599690881e-05,
      "loss": 1.9014,
      "step": 3880
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.193466663360596,
      "learning_rate": 3.12113601236476e-05,
      "loss": 1.8629,
      "step": 3890
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.794082164764404,
      "learning_rate": 3.1163060278207115e-05,
      "loss": 1.9357,
      "step": 3900
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.342246055603027,
      "learning_rate": 3.1114760432766615e-05,
      "loss": 1.7186,
      "step": 3910
    },
    {
      "epoch": 0.76,
      "grad_norm": 13.526001930236816,
      "learning_rate": 3.106646058732612e-05,
      "loss": 1.9644,
      "step": 3920
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.673614978790283,
      "learning_rate": 3.101816074188563e-05,
      "loss": 1.7871,
      "step": 3930
    },
    {
      "epoch": 0.76,
      "grad_norm": 11.278708457946777,
      "learning_rate": 3.0969860896445136e-05,
      "loss": 1.8605,
      "step": 3940
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.49395751953125,
      "learning_rate": 3.092156105100464e-05,
      "loss": 1.9004,
      "step": 3950
    },
    {
      "epoch": 0.77,
      "grad_norm": 8.585956573486328,
      "learning_rate": 3.0873261205564144e-05,
      "loss": 1.9083,
      "step": 3960
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.1153156757354736,
      "learning_rate": 3.082496136012365e-05,
      "loss": 1.9296,
      "step": 3970
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.2455034255981445,
      "learning_rate": 3.077666151468315e-05,
      "loss": 1.8748,
      "step": 3980
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.106218338012695,
      "learning_rate": 3.072836166924266e-05,
      "loss": 1.8906,
      "step": 3990
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.3431499004364014,
      "learning_rate": 3.0680061823802165e-05,
      "loss": 1.7632,
      "step": 4000
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.695012092590332,
      "learning_rate": 3.063176197836167e-05,
      "loss": 1.8008,
      "step": 4010
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.035892963409424,
      "learning_rate": 3.058346213292117e-05,
      "loss": 1.8454,
      "step": 4020
    },
    {
      "epoch": 0.78,
      "grad_norm": 30.150453567504883,
      "learning_rate": 3.0535162287480687e-05,
      "loss": 1.853,
      "step": 4030
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.230598449707031,
      "learning_rate": 3.0486862442040187e-05,
      "loss": 1.7635,
      "step": 4040
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.6669822931289673,
      "learning_rate": 3.043856259659969e-05,
      "loss": 1.8942,
      "step": 4050
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.9608895778656006,
      "learning_rate": 3.0390262751159198e-05,
      "loss": 1.9065,
      "step": 4060
    },
    {
      "epoch": 0.79,
      "grad_norm": 6.687342643737793,
      "learning_rate": 3.03419629057187e-05,
      "loss": 1.8737,
      "step": 4070
    },
    {
      "epoch": 0.79,
      "grad_norm": 8.0501127243042,
      "learning_rate": 3.0293663060278212e-05,
      "loss": 1.8937,
      "step": 4080
    },
    {
      "epoch": 0.79,
      "grad_norm": 18.764541625976562,
      "learning_rate": 3.0245363214837712e-05,
      "loss": 1.9112,
      "step": 4090
    },
    {
      "epoch": 0.79,
      "grad_norm": 14.788373947143555,
      "learning_rate": 3.0197063369397223e-05,
      "loss": 1.894,
      "step": 4100
    },
    {
      "epoch": 0.79,
      "grad_norm": 5.934656143188477,
      "learning_rate": 3.0148763523956723e-05,
      "loss": 1.816,
      "step": 4110
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.305313587188721,
      "learning_rate": 3.0100463678516227e-05,
      "loss": 1.8119,
      "step": 4120
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.5685064792633057,
      "learning_rate": 3.0052163833075737e-05,
      "loss": 1.8523,
      "step": 4130
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.4885289669036865,
      "learning_rate": 3.0003863987635237e-05,
      "loss": 1.7759,
      "step": 4140
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.624350070953369,
      "learning_rate": 2.9955564142194748e-05,
      "loss": 1.7878,
      "step": 4150
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.537517547607422,
      "learning_rate": 2.990726429675425e-05,
      "loss": 1.8391,
      "step": 4160
    },
    {
      "epoch": 0.81,
      "grad_norm": 16.633520126342773,
      "learning_rate": 2.985896445131376e-05,
      "loss": 1.8546,
      "step": 4170
    },
    {
      "epoch": 0.81,
      "grad_norm": 8.61707878112793,
      "learning_rate": 2.9810664605873262e-05,
      "loss": 1.9456,
      "step": 4180
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.0839240550994873,
      "learning_rate": 2.976236476043277e-05,
      "loss": 1.752,
      "step": 4190
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.58247709274292,
      "learning_rate": 2.9714064914992273e-05,
      "loss": 1.9868,
      "step": 4200
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.0000483989715576,
      "learning_rate": 2.9665765069551777e-05,
      "loss": 1.7951,
      "step": 4210
    },
    {
      "epoch": 0.82,
      "grad_norm": 7.243297100067139,
      "learning_rate": 2.9617465224111284e-05,
      "loss": 1.9959,
      "step": 4220
    },
    {
      "epoch": 0.82,
      "grad_norm": 8.888246536254883,
      "learning_rate": 2.9569165378670788e-05,
      "loss": 1.9482,
      "step": 4230
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.596609592437744,
      "learning_rate": 2.9520865533230298e-05,
      "loss": 1.8775,
      "step": 4240
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.848600387573242,
      "learning_rate": 2.94725656877898e-05,
      "loss": 1.9096,
      "step": 4250
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.633194446563721,
      "learning_rate": 2.942426584234931e-05,
      "loss": 1.8687,
      "step": 4260
    },
    {
      "epoch": 0.82,
      "grad_norm": 10.988286972045898,
      "learning_rate": 2.937596599690881e-05,
      "loss": 1.729,
      "step": 4270
    },
    {
      "epoch": 0.83,
      "grad_norm": 16.272798538208008,
      "learning_rate": 2.932766615146832e-05,
      "loss": 1.7447,
      "step": 4280
    },
    {
      "epoch": 0.83,
      "grad_norm": 6.489350318908691,
      "learning_rate": 2.9279366306027823e-05,
      "loss": 1.8827,
      "step": 4290
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.810830116271973,
      "learning_rate": 2.9231066460587324e-05,
      "loss": 1.801,
      "step": 4300
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.87395715713501,
      "learning_rate": 2.9182766615146834e-05,
      "loss": 1.9475,
      "step": 4310
    },
    {
      "epoch": 0.83,
      "grad_norm": 7.569411754608154,
      "learning_rate": 2.9134466769706338e-05,
      "loss": 1.8838,
      "step": 4320
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.732181072235107,
      "learning_rate": 2.9086166924265845e-05,
      "loss": 1.8262,
      "step": 4330
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.9223012924194336,
      "learning_rate": 2.903786707882535e-05,
      "loss": 1.8592,
      "step": 4340
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.9733195304870605,
      "learning_rate": 2.8989567233384856e-05,
      "loss": 1.8807,
      "step": 4350
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.8796842098236084,
      "learning_rate": 2.894126738794436e-05,
      "loss": 1.8852,
      "step": 4360
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.974133253097534,
      "learning_rate": 2.8892967542503863e-05,
      "loss": 1.7668,
      "step": 4370
    },
    {
      "epoch": 0.85,
      "grad_norm": 5.218547344207764,
      "learning_rate": 2.884466769706337e-05,
      "loss": 1.6896,
      "step": 4380
    },
    {
      "epoch": 0.85,
      "grad_norm": 54.93999481201172,
      "learning_rate": 2.8796367851622874e-05,
      "loss": 1.9235,
      "step": 4390
    },
    {
      "epoch": 0.85,
      "grad_norm": 7.256985187530518,
      "learning_rate": 2.8748068006182384e-05,
      "loss": 1.8214,
      "step": 4400
    },
    {
      "epoch": 0.85,
      "grad_norm": 8.683930397033691,
      "learning_rate": 2.8699768160741885e-05,
      "loss": 1.8787,
      "step": 4410
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.8469903469085693,
      "learning_rate": 2.8651468315301395e-05,
      "loss": 1.7698,
      "step": 4420
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.034750938415527,
      "learning_rate": 2.8603168469860895e-05,
      "loss": 1.8656,
      "step": 4430
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.214473009109497,
      "learning_rate": 2.8554868624420406e-05,
      "loss": 1.8403,
      "step": 4440
    },
    {
      "epoch": 0.86,
      "grad_norm": 7.5228471755981445,
      "learning_rate": 2.850656877897991e-05,
      "loss": 1.6985,
      "step": 4450
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.6780142784118652,
      "learning_rate": 2.845826893353941e-05,
      "loss": 1.8583,
      "step": 4460
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.584518909454346,
      "learning_rate": 2.840996908809892e-05,
      "loss": 1.9952,
      "step": 4470
    },
    {
      "epoch": 0.87,
      "grad_norm": 5.885734558105469,
      "learning_rate": 2.8361669242658424e-05,
      "loss": 1.8123,
      "step": 4480
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.576707363128662,
      "learning_rate": 2.831336939721793e-05,
      "loss": 1.7631,
      "step": 4490
    },
    {
      "epoch": 0.87,
      "grad_norm": 4.756106853485107,
      "learning_rate": 2.8265069551777435e-05,
      "loss": 1.7889,
      "step": 4500
    },
    {
      "epoch": 0.87,
      "grad_norm": 5.150712013244629,
      "learning_rate": 2.8216769706336942e-05,
      "loss": 1.8709,
      "step": 4510
    },
    {
      "epoch": 0.87,
      "grad_norm": 5.518260478973389,
      "learning_rate": 2.8168469860896446e-05,
      "loss": 1.7832,
      "step": 4520
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.352888584136963,
      "learning_rate": 2.8120170015455956e-05,
      "loss": 1.8225,
      "step": 4530
    },
    {
      "epoch": 0.88,
      "grad_norm": 14.235574722290039,
      "learning_rate": 2.8071870170015456e-05,
      "loss": 1.807,
      "step": 4540
    },
    {
      "epoch": 0.88,
      "grad_norm": 13.059932708740234,
      "learning_rate": 2.802357032457496e-05,
      "loss": 1.8067,
      "step": 4550
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.099116802215576,
      "learning_rate": 2.797527047913447e-05,
      "loss": 1.773,
      "step": 4560
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.0683131217956543,
      "learning_rate": 2.792697063369397e-05,
      "loss": 2.0307,
      "step": 4570
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.402771472930908,
      "learning_rate": 2.787867078825348e-05,
      "loss": 1.644,
      "step": 4580
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.246496677398682,
      "learning_rate": 2.783037094281298e-05,
      "loss": 1.8234,
      "step": 4590
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.038213729858398,
      "learning_rate": 2.7782071097372492e-05,
      "loss": 1.8278,
      "step": 4600
    },
    {
      "epoch": 0.89,
      "grad_norm": 4.39078426361084,
      "learning_rate": 2.7733771251931996e-05,
      "loss": 1.8737,
      "step": 4610
    },
    {
      "epoch": 0.89,
      "grad_norm": 8.686684608459473,
      "learning_rate": 2.7685471406491503e-05,
      "loss": 1.6518,
      "step": 4620
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.816314697265625,
      "learning_rate": 2.7637171561051007e-05,
      "loss": 1.7148,
      "step": 4630
    },
    {
      "epoch": 0.9,
      "grad_norm": 5.672924041748047,
      "learning_rate": 2.758887171561051e-05,
      "loss": 1.8398,
      "step": 4640
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.544312953948975,
      "learning_rate": 2.7540571870170017e-05,
      "loss": 1.9128,
      "step": 4650
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.525166034698486,
      "learning_rate": 2.749227202472952e-05,
      "loss": 1.765,
      "step": 4660
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.205000877380371,
      "learning_rate": 2.7443972179289028e-05,
      "loss": 1.7891,
      "step": 4670
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.324753284454346,
      "learning_rate": 2.7395672333848532e-05,
      "loss": 1.9009,
      "step": 4680
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.744512557983398,
      "learning_rate": 2.7347372488408042e-05,
      "loss": 1.854,
      "step": 4690
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.063602924346924,
      "learning_rate": 2.7299072642967543e-05,
      "loss": 1.7736,
      "step": 4700
    },
    {
      "epoch": 0.91,
      "grad_norm": 11.019662857055664,
      "learning_rate": 2.7250772797527046e-05,
      "loss": 1.7942,
      "step": 4710
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.343208074569702,
      "learning_rate": 2.7202472952086557e-05,
      "loss": 1.8617,
      "step": 4720
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.9594831466674805,
      "learning_rate": 2.7154173106646057e-05,
      "loss": 1.8306,
      "step": 4730
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.478288173675537,
      "learning_rate": 2.7105873261205568e-05,
      "loss": 1.8856,
      "step": 4740
    },
    {
      "epoch": 0.92,
      "grad_norm": 9.162983894348145,
      "learning_rate": 2.705757341576507e-05,
      "loss": 1.8668,
      "step": 4750
    },
    {
      "epoch": 0.92,
      "grad_norm": 5.043046474456787,
      "learning_rate": 2.700927357032458e-05,
      "loss": 1.7327,
      "step": 4760
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.637532711029053,
      "learning_rate": 2.6960973724884082e-05,
      "loss": 1.8214,
      "step": 4770
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.547499418258667,
      "learning_rate": 2.691267387944359e-05,
      "loss": 1.8389,
      "step": 4780
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.102286338806152,
      "learning_rate": 2.6864374034003093e-05,
      "loss": 1.8107,
      "step": 4790
    },
    {
      "epoch": 0.93,
      "grad_norm": 20.83313751220703,
      "learning_rate": 2.6816074188562596e-05,
      "loss": 1.8655,
      "step": 4800
    },
    {
      "epoch": 0.93,
      "grad_norm": 12.837798118591309,
      "learning_rate": 2.6767774343122104e-05,
      "loss": 1.8616,
      "step": 4810
    },
    {
      "epoch": 0.93,
      "grad_norm": 4.161496639251709,
      "learning_rate": 2.6719474497681607e-05,
      "loss": 1.7565,
      "step": 4820
    },
    {
      "epoch": 0.93,
      "grad_norm": 11.044515609741211,
      "learning_rate": 2.6671174652241114e-05,
      "loss": 1.922,
      "step": 4830
    },
    {
      "epoch": 0.94,
      "grad_norm": 5.058773994445801,
      "learning_rate": 2.6622874806800618e-05,
      "loss": 1.7276,
      "step": 4840
    },
    {
      "epoch": 0.94,
      "grad_norm": 5.405282020568848,
      "learning_rate": 2.657457496136013e-05,
      "loss": 1.6957,
      "step": 4850
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.304145574569702,
      "learning_rate": 2.652627511591963e-05,
      "loss": 1.9834,
      "step": 4860
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.851999521255493,
      "learning_rate": 2.647797527047914e-05,
      "loss": 1.8751,
      "step": 4870
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.5381252765655518,
      "learning_rate": 2.6429675425038643e-05,
      "loss": 1.8659,
      "step": 4880
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.5893161296844482,
      "learning_rate": 2.6381375579598143e-05,
      "loss": 1.8357,
      "step": 4890
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.4533028602600098,
      "learning_rate": 2.6333075734157654e-05,
      "loss": 2.0245,
      "step": 4900
    },
    {
      "epoch": 0.95,
      "grad_norm": 6.550326347351074,
      "learning_rate": 2.6284775888717157e-05,
      "loss": 1.8473,
      "step": 4910
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.0358805656433105,
      "learning_rate": 2.6236476043276665e-05,
      "loss": 1.8959,
      "step": 4920
    },
    {
      "epoch": 0.95,
      "grad_norm": 29.766538619995117,
      "learning_rate": 2.6188176197836168e-05,
      "loss": 1.8355,
      "step": 4930
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.922609806060791,
      "learning_rate": 2.6139876352395675e-05,
      "loss": 1.722,
      "step": 4940
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.012467861175537,
      "learning_rate": 2.609157650695518e-05,
      "loss": 1.7449,
      "step": 4950
    },
    {
      "epoch": 0.96,
      "grad_norm": 16.27069664001465,
      "learning_rate": 2.6043276661514683e-05,
      "loss": 1.8067,
      "step": 4960
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.829069137573242,
      "learning_rate": 2.599497681607419e-05,
      "loss": 1.7348,
      "step": 4970
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.505657911300659,
      "learning_rate": 2.5946676970633694e-05,
      "loss": 1.7884,
      "step": 4980
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.5701606273651123,
      "learning_rate": 2.58983771251932e-05,
      "loss": 1.7058,
      "step": 4990
    },
    {
      "epoch": 0.97,
      "grad_norm": 5.172097206115723,
      "learning_rate": 2.5850077279752704e-05,
      "loss": 1.7784,
      "step": 5000
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.0945489406585693,
      "learning_rate": 2.5801777434312215e-05,
      "loss": 1.7199,
      "step": 5010
    },
    {
      "epoch": 0.97,
      "grad_norm": 9.599586486816406,
      "learning_rate": 2.5753477588871715e-05,
      "loss": 1.8426,
      "step": 5020
    },
    {
      "epoch": 0.97,
      "grad_norm": 34.91025924682617,
      "learning_rate": 2.5705177743431226e-05,
      "loss": 1.8214,
      "step": 5030
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.4057207107543945,
      "learning_rate": 2.565687789799073e-05,
      "loss": 1.8234,
      "step": 5040
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.540867328643799,
      "learning_rate": 2.560857805255023e-05,
      "loss": 1.9402,
      "step": 5050
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.587274551391602,
      "learning_rate": 2.556027820710974e-05,
      "loss": 1.7968,
      "step": 5060
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.5092294216156006,
      "learning_rate": 2.5511978361669244e-05,
      "loss": 1.8467,
      "step": 5070
    },
    {
      "epoch": 0.98,
      "grad_norm": 12.076401710510254,
      "learning_rate": 2.546367851622875e-05,
      "loss": 1.8253,
      "step": 5080
    },
    {
      "epoch": 0.98,
      "grad_norm": 37.75251770019531,
      "learning_rate": 2.5415378670788255e-05,
      "loss": 1.8194,
      "step": 5090
    },
    {
      "epoch": 0.99,
      "grad_norm": 6.088234901428223,
      "learning_rate": 2.536707882534776e-05,
      "loss": 1.8315,
      "step": 5100
    },
    {
      "epoch": 0.99,
      "grad_norm": 22.942522048950195,
      "learning_rate": 2.5318778979907265e-05,
      "loss": 1.7715,
      "step": 5110
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.325364589691162,
      "learning_rate": 2.5270479134466772e-05,
      "loss": 1.9555,
      "step": 5120
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.3649630546569824,
      "learning_rate": 2.5222179289026276e-05,
      "loss": 1.8942,
      "step": 5130
    },
    {
      "epoch": 0.99,
      "grad_norm": 8.365328788757324,
      "learning_rate": 2.517387944358578e-05,
      "loss": 1.9629,
      "step": 5140
    },
    {
      "epoch": 0.99,
      "grad_norm": 12.028253555297852,
      "learning_rate": 2.5125579598145287e-05,
      "loss": 1.6872,
      "step": 5150
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.221798419952393,
      "learning_rate": 2.507727975270479e-05,
      "loss": 1.8515,
      "step": 5160
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.5820393562316895,
      "learning_rate": 2.50289799072643e-05,
      "loss": 1.8104,
      "step": 5170
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.8513270616531372,
      "eval_runtime": 1370.5909,
      "eval_samples_per_second": 7.553,
      "eval_steps_per_second": 0.944,
      "step": 5176
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.150737285614014,
      "learning_rate": 2.49806800618238e-05,
      "loss": 1.9461,
      "step": 5180
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.33369779586792,
      "learning_rate": 2.493238021638331e-05,
      "loss": 2.0526,
      "step": 5190
    },
    {
      "epoch": 1.0,
      "grad_norm": 32.31013107299805,
      "learning_rate": 2.4884080370942815e-05,
      "loss": 1.7063,
      "step": 5200
    },
    {
      "epoch": 1.01,
      "grad_norm": 37.62224197387695,
      "learning_rate": 2.483578052550232e-05,
      "loss": 1.9008,
      "step": 5210
    },
    {
      "epoch": 1.01,
      "grad_norm": 4.9261674880981445,
      "learning_rate": 2.4787480680061826e-05,
      "loss": 1.8934,
      "step": 5220
    },
    {
      "epoch": 1.01,
      "grad_norm": 5.153416633605957,
      "learning_rate": 2.473918083462133e-05,
      "loss": 1.7317,
      "step": 5230
    },
    {
      "epoch": 1.01,
      "grad_norm": 6.359580993652344,
      "learning_rate": 2.4690880989180837e-05,
      "loss": 1.792,
      "step": 5240
    },
    {
      "epoch": 1.01,
      "grad_norm": 20.539865493774414,
      "learning_rate": 2.4642581143740344e-05,
      "loss": 1.7246,
      "step": 5250
    },
    {
      "epoch": 1.02,
      "grad_norm": 8.39706802368164,
      "learning_rate": 2.4594281298299844e-05,
      "loss": 2.044,
      "step": 5260
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.1741180419921875,
      "learning_rate": 2.454598145285935e-05,
      "loss": 1.8259,
      "step": 5270
    },
    {
      "epoch": 1.02,
      "grad_norm": 4.017375946044922,
      "learning_rate": 2.449768160741886e-05,
      "loss": 1.7971,
      "step": 5280
    },
    {
      "epoch": 1.02,
      "grad_norm": 7.527024745941162,
      "learning_rate": 2.4449381761978362e-05,
      "loss": 1.8032,
      "step": 5290
    },
    {
      "epoch": 1.02,
      "grad_norm": 5.75172233581543,
      "learning_rate": 2.440108191653787e-05,
      "loss": 1.8162,
      "step": 5300
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.665788650512695,
      "learning_rate": 2.4352782071097373e-05,
      "loss": 1.7425,
      "step": 5310
    },
    {
      "epoch": 1.03,
      "grad_norm": 6.051855087280273,
      "learning_rate": 2.430448222565688e-05,
      "loss": 1.9604,
      "step": 5320
    },
    {
      "epoch": 1.03,
      "grad_norm": 5.534664630889893,
      "learning_rate": 2.4256182380216387e-05,
      "loss": 1.7867,
      "step": 5330
    },
    {
      "epoch": 1.03,
      "grad_norm": 7.096324920654297,
      "learning_rate": 2.4207882534775888e-05,
      "loss": 1.8058,
      "step": 5340
    },
    {
      "epoch": 1.03,
      "grad_norm": 4.065700054168701,
      "learning_rate": 2.4159582689335395e-05,
      "loss": 1.7548,
      "step": 5350
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.803292989730835,
      "learning_rate": 2.4111282843894902e-05,
      "loss": 1.7937,
      "step": 5360
    },
    {
      "epoch": 1.04,
      "grad_norm": 7.083604335784912,
      "learning_rate": 2.4062982998454405e-05,
      "loss": 1.777,
      "step": 5370
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.5313682556152344,
      "learning_rate": 2.4014683153013913e-05,
      "loss": 1.8956,
      "step": 5380
    },
    {
      "epoch": 1.04,
      "grad_norm": 8.690970420837402,
      "learning_rate": 2.3966383307573416e-05,
      "loss": 1.7025,
      "step": 5390
    },
    {
      "epoch": 1.04,
      "grad_norm": 24.425264358520508,
      "learning_rate": 2.3918083462132923e-05,
      "loss": 2.0192,
      "step": 5400
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.630859375,
      "learning_rate": 2.386978361669243e-05,
      "loss": 2.037,
      "step": 5410
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.8027284145355225,
      "learning_rate": 2.382148377125193e-05,
      "loss": 1.8449,
      "step": 5420
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.489638328552246,
      "learning_rate": 2.3773183925811438e-05,
      "loss": 1.8191,
      "step": 5430
    },
    {
      "epoch": 1.05,
      "grad_norm": 8.98135757446289,
      "learning_rate": 2.3724884080370945e-05,
      "loss": 1.8017,
      "step": 5440
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.661259889602661,
      "learning_rate": 2.367658423493045e-05,
      "loss": 1.7553,
      "step": 5450
    },
    {
      "epoch": 1.05,
      "grad_norm": 4.712551593780518,
      "learning_rate": 2.3628284389489956e-05,
      "loss": 1.8595,
      "step": 5460
    },
    {
      "epoch": 1.06,
      "grad_norm": 7.617225646972656,
      "learning_rate": 2.357998454404946e-05,
      "loss": 1.8508,
      "step": 5470
    },
    {
      "epoch": 1.06,
      "grad_norm": 8.772101402282715,
      "learning_rate": 2.3531684698608966e-05,
      "loss": 1.7315,
      "step": 5480
    },
    {
      "epoch": 1.06,
      "grad_norm": 7.689697265625,
      "learning_rate": 2.3483384853168474e-05,
      "loss": 1.7752,
      "step": 5490
    },
    {
      "epoch": 1.06,
      "grad_norm": 24.919103622436523,
      "learning_rate": 2.3435085007727977e-05,
      "loss": 1.834,
      "step": 5500
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.7391064167022705,
      "learning_rate": 2.338678516228748e-05,
      "loss": 1.893,
      "step": 5510
    },
    {
      "epoch": 1.07,
      "grad_norm": 4.495073318481445,
      "learning_rate": 2.3338485316846988e-05,
      "loss": 1.8284,
      "step": 5520
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.2563154697418213,
      "learning_rate": 2.329018547140649e-05,
      "loss": 1.7465,
      "step": 5530
    },
    {
      "epoch": 1.07,
      "grad_norm": 4.850912570953369,
      "learning_rate": 2.3241885625966e-05,
      "loss": 1.7663,
      "step": 5540
    },
    {
      "epoch": 1.07,
      "grad_norm": 4.364437103271484,
      "learning_rate": 2.3193585780525502e-05,
      "loss": 1.8404,
      "step": 5550
    },
    {
      "epoch": 1.07,
      "grad_norm": 5.966915607452393,
      "learning_rate": 2.314528593508501e-05,
      "loss": 1.718,
      "step": 5560
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.547211170196533,
      "learning_rate": 2.3096986089644517e-05,
      "loss": 1.8671,
      "step": 5570
    },
    {
      "epoch": 1.08,
      "grad_norm": 15.741012573242188,
      "learning_rate": 2.304868624420402e-05,
      "loss": 1.9296,
      "step": 5580
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.085528373718262,
      "learning_rate": 2.3000386398763524e-05,
      "loss": 1.8039,
      "step": 5590
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.6324896812438965,
      "learning_rate": 2.295208655332303e-05,
      "loss": 1.73,
      "step": 5600
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.156549453735352,
      "learning_rate": 2.2903786707882535e-05,
      "loss": 1.8612,
      "step": 5610
    },
    {
      "epoch": 1.09,
      "grad_norm": 14.401927947998047,
      "learning_rate": 2.2855486862442042e-05,
      "loss": 1.9486,
      "step": 5620
    },
    {
      "epoch": 1.09,
      "grad_norm": 4.6332926750183105,
      "learning_rate": 2.2807187017001546e-05,
      "loss": 1.8455,
      "step": 5630
    },
    {
      "epoch": 1.09,
      "grad_norm": 16.640146255493164,
      "learning_rate": 2.2758887171561053e-05,
      "loss": 2.0,
      "step": 5640
    },
    {
      "epoch": 1.09,
      "grad_norm": 4.58611536026001,
      "learning_rate": 2.271058732612056e-05,
      "loss": 1.8091,
      "step": 5650
    },
    {
      "epoch": 1.09,
      "grad_norm": 3.834338665008545,
      "learning_rate": 2.2662287480680063e-05,
      "loss": 1.8709,
      "step": 5660
    },
    {
      "epoch": 1.1,
      "grad_norm": 9.143288612365723,
      "learning_rate": 2.261398763523957e-05,
      "loss": 1.8282,
      "step": 5670
    },
    {
      "epoch": 1.1,
      "grad_norm": 5.624088287353516,
      "learning_rate": 2.2565687789799074e-05,
      "loss": 1.7537,
      "step": 5680
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.967210054397583,
      "learning_rate": 2.2517387944358578e-05,
      "loss": 1.8306,
      "step": 5690
    },
    {
      "epoch": 1.1,
      "grad_norm": 9.41580581665039,
      "learning_rate": 2.2469088098918085e-05,
      "loss": 1.7867,
      "step": 5700
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.6225173473358154,
      "learning_rate": 2.242078825347759e-05,
      "loss": 1.849,
      "step": 5710
    },
    {
      "epoch": 1.11,
      "grad_norm": 7.341036319732666,
      "learning_rate": 2.2372488408037096e-05,
      "loss": 1.7793,
      "step": 5720
    },
    {
      "epoch": 1.11,
      "grad_norm": 4.090700149536133,
      "learning_rate": 2.2324188562596603e-05,
      "loss": 1.923,
      "step": 5730
    },
    {
      "epoch": 1.11,
      "grad_norm": 10.196273803710938,
      "learning_rate": 2.2275888717156107e-05,
      "loss": 1.8925,
      "step": 5740
    },
    {
      "epoch": 1.11,
      "grad_norm": 5.7342071533203125,
      "learning_rate": 2.2227588871715614e-05,
      "loss": 1.909,
      "step": 5750
    },
    {
      "epoch": 1.11,
      "grad_norm": 4.016778945922852,
      "learning_rate": 2.2179289026275117e-05,
      "loss": 1.9815,
      "step": 5760
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.894117832183838,
      "learning_rate": 2.213098918083462e-05,
      "loss": 1.9366,
      "step": 5770
    },
    {
      "epoch": 1.12,
      "grad_norm": 8.74722957611084,
      "learning_rate": 2.2082689335394128e-05,
      "loss": 1.7378,
      "step": 5780
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.833420753479004,
      "learning_rate": 2.2034389489953632e-05,
      "loss": 1.6982,
      "step": 5790
    },
    {
      "epoch": 1.12,
      "grad_norm": 8.887247085571289,
      "learning_rate": 2.198608964451314e-05,
      "loss": 1.8833,
      "step": 5800
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.358395099639893,
      "learning_rate": 2.1937789799072646e-05,
      "loss": 1.8393,
      "step": 5810
    },
    {
      "epoch": 1.12,
      "grad_norm": 28.30077362060547,
      "learning_rate": 2.188948995363215e-05,
      "loss": 1.9132,
      "step": 5820
    },
    {
      "epoch": 1.13,
      "grad_norm": 5.5777058601379395,
      "learning_rate": 2.1841190108191657e-05,
      "loss": 1.9299,
      "step": 5830
    },
    {
      "epoch": 1.13,
      "grad_norm": 5.790768146514893,
      "learning_rate": 2.179289026275116e-05,
      "loss": 1.7343,
      "step": 5840
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.6541404724121094,
      "learning_rate": 2.1744590417310664e-05,
      "loss": 1.9361,
      "step": 5850
    },
    {
      "epoch": 1.13,
      "grad_norm": 4.750905513763428,
      "learning_rate": 2.169629057187017e-05,
      "loss": 1.7638,
      "step": 5860
    },
    {
      "epoch": 1.13,
      "grad_norm": 4.164517879486084,
      "learning_rate": 2.1647990726429675e-05,
      "loss": 1.7984,
      "step": 5870
    },
    {
      "epoch": 1.14,
      "grad_norm": 3.862799644470215,
      "learning_rate": 2.1599690880989182e-05,
      "loss": 1.9927,
      "step": 5880
    },
    {
      "epoch": 1.14,
      "grad_norm": 5.102228164672852,
      "learning_rate": 2.155139103554869e-05,
      "loss": 1.9299,
      "step": 5890
    },
    {
      "epoch": 1.14,
      "grad_norm": 4.3575921058654785,
      "learning_rate": 2.1503091190108193e-05,
      "loss": 1.7149,
      "step": 5900
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.973360300064087,
      "learning_rate": 2.14547913446677e-05,
      "loss": 1.9581,
      "step": 5910
    },
    {
      "epoch": 1.14,
      "grad_norm": 7.894438743591309,
      "learning_rate": 2.1406491499227204e-05,
      "loss": 1.844,
      "step": 5920
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.147648811340332,
      "learning_rate": 2.1358191653786707e-05,
      "loss": 1.8251,
      "step": 5930
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.759703636169434,
      "learning_rate": 2.1309891808346214e-05,
      "loss": 1.7285,
      "step": 5940
    },
    {
      "epoch": 1.15,
      "grad_norm": 6.955203533172607,
      "learning_rate": 2.1261591962905718e-05,
      "loss": 1.8032,
      "step": 5950
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.477252960205078,
      "learning_rate": 2.1213292117465225e-05,
      "loss": 1.874,
      "step": 5960
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.756730556488037,
      "learning_rate": 2.1164992272024732e-05,
      "loss": 1.8245,
      "step": 5970
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.8744781017303467,
      "learning_rate": 2.1116692426584236e-05,
      "loss": 1.9245,
      "step": 5980
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.215759038925171,
      "learning_rate": 2.1068392581143743e-05,
      "loss": 1.8626,
      "step": 5990
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.022429466247559,
      "learning_rate": 2.1020092735703247e-05,
      "loss": 1.89,
      "step": 6000
    },
    {
      "epoch": 1.16,
      "grad_norm": 13.086671829223633,
      "learning_rate": 2.097179289026275e-05,
      "loss": 1.9037,
      "step": 6010
    },
    {
      "epoch": 1.16,
      "grad_norm": 10.18606948852539,
      "learning_rate": 2.0923493044822257e-05,
      "loss": 1.7961,
      "step": 6020
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.6704490184783936,
      "learning_rate": 2.087519319938176e-05,
      "loss": 1.8948,
      "step": 6030
    },
    {
      "epoch": 1.17,
      "grad_norm": 4.917967796325684,
      "learning_rate": 2.0826893353941268e-05,
      "loss": 1.7214,
      "step": 6040
    },
    {
      "epoch": 1.17,
      "grad_norm": 8.450181007385254,
      "learning_rate": 2.0778593508500775e-05,
      "loss": 1.8898,
      "step": 6050
    },
    {
      "epoch": 1.17,
      "grad_norm": 4.202915191650391,
      "learning_rate": 2.073029366306028e-05,
      "loss": 1.7213,
      "step": 6060
    },
    {
      "epoch": 1.17,
      "grad_norm": 6.512363910675049,
      "learning_rate": 2.0681993817619786e-05,
      "loss": 1.8575,
      "step": 6070
    },
    {
      "epoch": 1.17,
      "grad_norm": 6.053705215454102,
      "learning_rate": 2.063369397217929e-05,
      "loss": 1.7477,
      "step": 6080
    },
    {
      "epoch": 1.18,
      "grad_norm": 6.6718316078186035,
      "learning_rate": 2.0585394126738797e-05,
      "loss": 1.7794,
      "step": 6090
    },
    {
      "epoch": 1.18,
      "grad_norm": 17.70193862915039,
      "learning_rate": 2.05370942812983e-05,
      "loss": 1.8561,
      "step": 6100
    },
    {
      "epoch": 1.18,
      "grad_norm": 8.03186321258545,
      "learning_rate": 2.0488794435857804e-05,
      "loss": 1.7521,
      "step": 6110
    },
    {
      "epoch": 1.18,
      "grad_norm": 9.797785758972168,
      "learning_rate": 2.044049459041731e-05,
      "loss": 1.8251,
      "step": 6120
    },
    {
      "epoch": 1.18,
      "grad_norm": 6.719789028167725,
      "learning_rate": 2.039219474497682e-05,
      "loss": 1.7777,
      "step": 6130
    },
    {
      "epoch": 1.19,
      "grad_norm": 9.287593841552734,
      "learning_rate": 2.0343894899536322e-05,
      "loss": 1.8483,
      "step": 6140
    },
    {
      "epoch": 1.19,
      "grad_norm": 5.299696445465088,
      "learning_rate": 2.029559505409583e-05,
      "loss": 1.8278,
      "step": 6150
    },
    {
      "epoch": 1.19,
      "grad_norm": 6.167962074279785,
      "learning_rate": 2.0247295208655333e-05,
      "loss": 1.8596,
      "step": 6160
    },
    {
      "epoch": 1.19,
      "grad_norm": 5.713860988616943,
      "learning_rate": 2.019899536321484e-05,
      "loss": 1.7666,
      "step": 6170
    },
    {
      "epoch": 1.19,
      "grad_norm": 3.308654308319092,
      "learning_rate": 2.0150695517774344e-05,
      "loss": 1.7627,
      "step": 6180
    },
    {
      "epoch": 1.2,
      "grad_norm": 14.497100830078125,
      "learning_rate": 2.0102395672333847e-05,
      "loss": 1.8065,
      "step": 6190
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.534820079803467,
      "learning_rate": 2.0054095826893355e-05,
      "loss": 1.7326,
      "step": 6200
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.3221306800842285,
      "learning_rate": 2.000579598145286e-05,
      "loss": 1.7535,
      "step": 6210
    },
    {
      "epoch": 1.2,
      "grad_norm": 5.48643159866333,
      "learning_rate": 1.9957496136012365e-05,
      "loss": 1.9351,
      "step": 6220
    },
    {
      "epoch": 1.2,
      "grad_norm": 28.110279083251953,
      "learning_rate": 1.9909196290571872e-05,
      "loss": 1.9,
      "step": 6230
    },
    {
      "epoch": 1.21,
      "grad_norm": 11.988542556762695,
      "learning_rate": 1.9860896445131376e-05,
      "loss": 1.8391,
      "step": 6240
    },
    {
      "epoch": 1.21,
      "grad_norm": 14.576866149902344,
      "learning_rate": 1.9812596599690883e-05,
      "loss": 1.8415,
      "step": 6250
    },
    {
      "epoch": 1.21,
      "grad_norm": 23.845069885253906,
      "learning_rate": 1.9764296754250387e-05,
      "loss": 1.856,
      "step": 6260
    },
    {
      "epoch": 1.21,
      "grad_norm": 5.596431732177734,
      "learning_rate": 1.971599690880989e-05,
      "loss": 1.796,
      "step": 6270
    },
    {
      "epoch": 1.21,
      "grad_norm": 5.7637739181518555,
      "learning_rate": 1.9667697063369398e-05,
      "loss": 1.8873,
      "step": 6280
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.32701301574707,
      "learning_rate": 1.9619397217928905e-05,
      "loss": 1.8088,
      "step": 6290
    },
    {
      "epoch": 1.22,
      "grad_norm": 7.677741527557373,
      "learning_rate": 1.957109737248841e-05,
      "loss": 1.7174,
      "step": 6300
    },
    {
      "epoch": 1.22,
      "grad_norm": 10.099072456359863,
      "learning_rate": 1.9522797527047916e-05,
      "loss": 1.6477,
      "step": 6310
    },
    {
      "epoch": 1.22,
      "grad_norm": 6.222919940948486,
      "learning_rate": 1.947449768160742e-05,
      "loss": 1.7048,
      "step": 6320
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.2801544666290283,
      "learning_rate": 1.9426197836166926e-05,
      "loss": 1.8661,
      "step": 6330
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.2781476974487305,
      "learning_rate": 1.9377897990726433e-05,
      "loss": 1.7993,
      "step": 6340
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.6582694053649902,
      "learning_rate": 1.9329598145285934e-05,
      "loss": 1.9135,
      "step": 6350
    },
    {
      "epoch": 1.23,
      "grad_norm": 11.845890998840332,
      "learning_rate": 1.928129829984544e-05,
      "loss": 1.9282,
      "step": 6360
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.423260688781738,
      "learning_rate": 1.9232998454404948e-05,
      "loss": 1.9477,
      "step": 6370
    },
    {
      "epoch": 1.23,
      "grad_norm": 7.463987827301025,
      "learning_rate": 1.918469860896445e-05,
      "loss": 1.7603,
      "step": 6380
    },
    {
      "epoch": 1.23,
      "grad_norm": 16.52410125732422,
      "learning_rate": 1.913639876352396e-05,
      "loss": 1.7792,
      "step": 6390
    },
    {
      "epoch": 1.24,
      "grad_norm": 5.472789764404297,
      "learning_rate": 1.9088098918083462e-05,
      "loss": 1.764,
      "step": 6400
    },
    {
      "epoch": 1.24,
      "grad_norm": 7.126010417938232,
      "learning_rate": 1.903979907264297e-05,
      "loss": 1.774,
      "step": 6410
    },
    {
      "epoch": 1.24,
      "grad_norm": 4.940361976623535,
      "learning_rate": 1.8991499227202476e-05,
      "loss": 1.8367,
      "step": 6420
    },
    {
      "epoch": 1.24,
      "grad_norm": 20.470746994018555,
      "learning_rate": 1.8943199381761977e-05,
      "loss": 1.93,
      "step": 6430
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.8208820819854736,
      "learning_rate": 1.8894899536321484e-05,
      "loss": 1.9458,
      "step": 6440
    },
    {
      "epoch": 1.25,
      "grad_norm": 4.781457901000977,
      "learning_rate": 1.884659969088099e-05,
      "loss": 1.8499,
      "step": 6450
    },
    {
      "epoch": 1.25,
      "grad_norm": 4.999488830566406,
      "learning_rate": 1.8798299845440495e-05,
      "loss": 1.749,
      "step": 6460
    },
    {
      "epoch": 1.25,
      "grad_norm": 4.795538425445557,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 1.7776,
      "step": 6470
    },
    {
      "epoch": 1.25,
      "grad_norm": 8.119667053222656,
      "learning_rate": 1.8701700154559505e-05,
      "loss": 1.9039,
      "step": 6480
    },
    {
      "epoch": 1.25,
      "grad_norm": 4.984917163848877,
      "learning_rate": 1.8653400309119013e-05,
      "loss": 1.8606,
      "step": 6490
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.4857749938964844,
      "learning_rate": 1.860510046367852e-05,
      "loss": 1.744,
      "step": 6500
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.089479446411133,
      "learning_rate": 1.8556800618238023e-05,
      "loss": 1.7844,
      "step": 6510
    },
    {
      "epoch": 1.26,
      "grad_norm": 4.906333923339844,
      "learning_rate": 1.8508500772797527e-05,
      "loss": 1.6568,
      "step": 6520
    },
    {
      "epoch": 1.26,
      "grad_norm": 10.456840515136719,
      "learning_rate": 1.8460200927357034e-05,
      "loss": 1.7964,
      "step": 6530
    },
    {
      "epoch": 1.26,
      "grad_norm": 5.232548236846924,
      "learning_rate": 1.8411901081916538e-05,
      "loss": 1.7179,
      "step": 6540
    },
    {
      "epoch": 1.27,
      "grad_norm": 72.18038940429688,
      "learning_rate": 1.8363601236476045e-05,
      "loss": 1.9393,
      "step": 6550
    },
    {
      "epoch": 1.27,
      "grad_norm": 8.681700706481934,
      "learning_rate": 1.831530139103555e-05,
      "loss": 1.7786,
      "step": 6560
    },
    {
      "epoch": 1.27,
      "grad_norm": 11.570116996765137,
      "learning_rate": 1.8267001545595056e-05,
      "loss": 1.7379,
      "step": 6570
    },
    {
      "epoch": 1.27,
      "grad_norm": 7.796571731567383,
      "learning_rate": 1.8218701700154563e-05,
      "loss": 1.7697,
      "step": 6580
    },
    {
      "epoch": 1.27,
      "grad_norm": 9.103039741516113,
      "learning_rate": 1.8170401854714066e-05,
      "loss": 1.959,
      "step": 6590
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.5235228538513184,
      "learning_rate": 1.812210200927357e-05,
      "loss": 1.766,
      "step": 6600
    },
    {
      "epoch": 1.28,
      "grad_norm": 4.592250823974609,
      "learning_rate": 1.8073802163833077e-05,
      "loss": 1.7646,
      "step": 6610
    },
    {
      "epoch": 1.28,
      "grad_norm": 7.490676403045654,
      "learning_rate": 1.802550231839258e-05,
      "loss": 1.8089,
      "step": 6620
    },
    {
      "epoch": 1.28,
      "grad_norm": 5.276451110839844,
      "learning_rate": 1.7977202472952088e-05,
      "loss": 1.6539,
      "step": 6630
    },
    {
      "epoch": 1.28,
      "grad_norm": 12.320703506469727,
      "learning_rate": 1.792890262751159e-05,
      "loss": 1.8031,
      "step": 6640
    },
    {
      "epoch": 1.28,
      "grad_norm": 10.943641662597656,
      "learning_rate": 1.78806027820711e-05,
      "loss": 1.8251,
      "step": 6650
    },
    {
      "epoch": 1.29,
      "grad_norm": 7.4574174880981445,
      "learning_rate": 1.7832302936630606e-05,
      "loss": 1.7632,
      "step": 6660
    },
    {
      "epoch": 1.29,
      "grad_norm": 11.882811546325684,
      "learning_rate": 1.778400309119011e-05,
      "loss": 1.7919,
      "step": 6670
    },
    {
      "epoch": 1.29,
      "grad_norm": 7.8670878410339355,
      "learning_rate": 1.7735703245749617e-05,
      "loss": 1.8903,
      "step": 6680
    },
    {
      "epoch": 1.29,
      "grad_norm": 12.47612190246582,
      "learning_rate": 1.768740340030912e-05,
      "loss": 1.7189,
      "step": 6690
    },
    {
      "epoch": 1.29,
      "grad_norm": 5.769176006317139,
      "learning_rate": 1.7639103554868624e-05,
      "loss": 1.7534,
      "step": 6700
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.463786602020264,
      "learning_rate": 1.759080370942813e-05,
      "loss": 1.8487,
      "step": 6710
    },
    {
      "epoch": 1.3,
      "grad_norm": 5.6096906661987305,
      "learning_rate": 1.7542503863987635e-05,
      "loss": 1.8513,
      "step": 6720
    },
    {
      "epoch": 1.3,
      "grad_norm": 5.151650905609131,
      "learning_rate": 1.7494204018547142e-05,
      "loss": 1.8905,
      "step": 6730
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.9077982902526855,
      "learning_rate": 1.744590417310665e-05,
      "loss": 1.903,
      "step": 6740
    },
    {
      "epoch": 1.3,
      "grad_norm": 19.972606658935547,
      "learning_rate": 1.7397604327666153e-05,
      "loss": 1.8707,
      "step": 6750
    },
    {
      "epoch": 1.31,
      "grad_norm": 5.265586853027344,
      "learning_rate": 1.734930448222566e-05,
      "loss": 1.9031,
      "step": 6760
    },
    {
      "epoch": 1.31,
      "grad_norm": 27.785446166992188,
      "learning_rate": 1.7301004636785163e-05,
      "loss": 1.727,
      "step": 6770
    },
    {
      "epoch": 1.31,
      "grad_norm": 17.4012451171875,
      "learning_rate": 1.7252704791344667e-05,
      "loss": 1.8182,
      "step": 6780
    },
    {
      "epoch": 1.31,
      "grad_norm": 6.632897853851318,
      "learning_rate": 1.7204404945904174e-05,
      "loss": 1.893,
      "step": 6790
    },
    {
      "epoch": 1.31,
      "grad_norm": 7.068596363067627,
      "learning_rate": 1.7156105100463678e-05,
      "loss": 1.7361,
      "step": 6800
    },
    {
      "epoch": 1.32,
      "grad_norm": 7.150506973266602,
      "learning_rate": 1.7107805255023185e-05,
      "loss": 1.9134,
      "step": 6810
    },
    {
      "epoch": 1.32,
      "grad_norm": 5.004347801208496,
      "learning_rate": 1.7059505409582692e-05,
      "loss": 1.8086,
      "step": 6820
    },
    {
      "epoch": 1.32,
      "grad_norm": 18.9309139251709,
      "learning_rate": 1.7011205564142196e-05,
      "loss": 1.749,
      "step": 6830
    },
    {
      "epoch": 1.32,
      "grad_norm": 14.103450775146484,
      "learning_rate": 1.6962905718701703e-05,
      "loss": 1.8557,
      "step": 6840
    },
    {
      "epoch": 1.32,
      "grad_norm": 5.367413520812988,
      "learning_rate": 1.6914605873261207e-05,
      "loss": 1.7886,
      "step": 6850
    },
    {
      "epoch": 1.33,
      "grad_norm": 8.74439525604248,
      "learning_rate": 1.686630602782071e-05,
      "loss": 1.7549,
      "step": 6860
    },
    {
      "epoch": 1.33,
      "grad_norm": 4.454617500305176,
      "learning_rate": 1.6818006182380217e-05,
      "loss": 1.8882,
      "step": 6870
    },
    {
      "epoch": 1.33,
      "grad_norm": 3.263591766357422,
      "learning_rate": 1.676970633693972e-05,
      "loss": 1.7193,
      "step": 6880
    },
    {
      "epoch": 1.33,
      "grad_norm": 2.6123409271240234,
      "learning_rate": 1.6721406491499228e-05,
      "loss": 1.9041,
      "step": 6890
    },
    {
      "epoch": 1.33,
      "grad_norm": 19.173471450805664,
      "learning_rate": 1.6673106646058735e-05,
      "loss": 1.7449,
      "step": 6900
    },
    {
      "epoch": 1.34,
      "grad_norm": 10.877569198608398,
      "learning_rate": 1.662480680061824e-05,
      "loss": 1.7336,
      "step": 6910
    },
    {
      "epoch": 1.34,
      "grad_norm": 6.705199241638184,
      "learning_rate": 1.6576506955177746e-05,
      "loss": 1.8084,
      "step": 6920
    },
    {
      "epoch": 1.34,
      "grad_norm": 6.20145320892334,
      "learning_rate": 1.652820710973725e-05,
      "loss": 1.7256,
      "step": 6930
    },
    {
      "epoch": 1.34,
      "grad_norm": 6.115902900695801,
      "learning_rate": 1.6479907264296753e-05,
      "loss": 1.785,
      "step": 6940
    },
    {
      "epoch": 1.34,
      "grad_norm": 4.091248512268066,
      "learning_rate": 1.643160741885626e-05,
      "loss": 1.8976,
      "step": 6950
    },
    {
      "epoch": 1.34,
      "grad_norm": 14.327980041503906,
      "learning_rate": 1.6383307573415764e-05,
      "loss": 1.7691,
      "step": 6960
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.107385158538818,
      "learning_rate": 1.633500772797527e-05,
      "loss": 1.8402,
      "step": 6970
    },
    {
      "epoch": 1.35,
      "grad_norm": 10.863578796386719,
      "learning_rate": 1.628670788253478e-05,
      "loss": 1.8406,
      "step": 6980
    },
    {
      "epoch": 1.35,
      "grad_norm": 20.807193756103516,
      "learning_rate": 1.6238408037094282e-05,
      "loss": 1.8994,
      "step": 6990
    },
    {
      "epoch": 1.35,
      "grad_norm": 4.561880111694336,
      "learning_rate": 1.619010819165379e-05,
      "loss": 1.9142,
      "step": 7000
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.763373374938965,
      "learning_rate": 1.6141808346213293e-05,
      "loss": 1.7997,
      "step": 7010
    },
    {
      "epoch": 1.36,
      "grad_norm": 9.341221809387207,
      "learning_rate": 1.6093508500772797e-05,
      "loss": 1.8202,
      "step": 7020
    },
    {
      "epoch": 1.36,
      "grad_norm": 4.994197368621826,
      "learning_rate": 1.6045208655332304e-05,
      "loss": 1.7114,
      "step": 7030
    },
    {
      "epoch": 1.36,
      "grad_norm": 11.558463096618652,
      "learning_rate": 1.5996908809891807e-05,
      "loss": 1.7619,
      "step": 7040
    },
    {
      "epoch": 1.36,
      "grad_norm": 4.491838455200195,
      "learning_rate": 1.5948608964451314e-05,
      "loss": 1.7192,
      "step": 7050
    },
    {
      "epoch": 1.36,
      "grad_norm": 6.5771026611328125,
      "learning_rate": 1.590030911901082e-05,
      "loss": 1.8568,
      "step": 7060
    },
    {
      "epoch": 1.37,
      "grad_norm": 6.40115213394165,
      "learning_rate": 1.5852009273570325e-05,
      "loss": 1.7202,
      "step": 7070
    },
    {
      "epoch": 1.37,
      "grad_norm": 5.686690330505371,
      "learning_rate": 1.5803709428129832e-05,
      "loss": 1.7392,
      "step": 7080
    },
    {
      "epoch": 1.37,
      "grad_norm": 10.664716720581055,
      "learning_rate": 1.5755409582689336e-05,
      "loss": 2.0962,
      "step": 7090
    },
    {
      "epoch": 1.37,
      "grad_norm": 3.9161713123321533,
      "learning_rate": 1.5707109737248843e-05,
      "loss": 1.8026,
      "step": 7100
    },
    {
      "epoch": 1.37,
      "grad_norm": 5.543188571929932,
      "learning_rate": 1.5658809891808347e-05,
      "loss": 1.7958,
      "step": 7110
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.6708593368530273,
      "learning_rate": 1.561051004636785e-05,
      "loss": 1.8286,
      "step": 7120
    },
    {
      "epoch": 1.38,
      "grad_norm": 6.376767635345459,
      "learning_rate": 1.5562210200927358e-05,
      "loss": 1.8086,
      "step": 7130
    },
    {
      "epoch": 1.38,
      "grad_norm": 4.816287517547607,
      "learning_rate": 1.5513910355486865e-05,
      "loss": 1.6877,
      "step": 7140
    },
    {
      "epoch": 1.38,
      "grad_norm": 7.714559078216553,
      "learning_rate": 1.5465610510046368e-05,
      "loss": 1.7946,
      "step": 7150
    },
    {
      "epoch": 1.38,
      "grad_norm": 5.200584888458252,
      "learning_rate": 1.5417310664605875e-05,
      "loss": 1.8436,
      "step": 7160
    },
    {
      "epoch": 1.39,
      "grad_norm": 10.089491844177246,
      "learning_rate": 1.536901081916538e-05,
      "loss": 1.8185,
      "step": 7170
    },
    {
      "epoch": 1.39,
      "grad_norm": 5.719161510467529,
      "learning_rate": 1.5320710973724886e-05,
      "loss": 1.6956,
      "step": 7180
    },
    {
      "epoch": 1.39,
      "grad_norm": 6.7494940757751465,
      "learning_rate": 1.527241112828439e-05,
      "loss": 1.7236,
      "step": 7190
    },
    {
      "epoch": 1.39,
      "grad_norm": 11.63581371307373,
      "learning_rate": 1.5224111282843895e-05,
      "loss": 1.8276,
      "step": 7200
    },
    {
      "epoch": 1.39,
      "grad_norm": 4.721817970275879,
      "learning_rate": 1.51758114374034e-05,
      "loss": 2.0026,
      "step": 7210
    },
    {
      "epoch": 1.39,
      "grad_norm": 6.979727745056152,
      "learning_rate": 1.5127511591962906e-05,
      "loss": 1.7981,
      "step": 7220
    },
    {
      "epoch": 1.4,
      "grad_norm": 47.13263702392578,
      "learning_rate": 1.5079211746522411e-05,
      "loss": 1.8709,
      "step": 7230
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.7526657581329346,
      "learning_rate": 1.5030911901081918e-05,
      "loss": 1.7682,
      "step": 7240
    },
    {
      "epoch": 1.4,
      "grad_norm": 15.372940063476562,
      "learning_rate": 1.4982612055641424e-05,
      "loss": 1.8092,
      "step": 7250
    },
    {
      "epoch": 1.4,
      "grad_norm": 7.3034586906433105,
      "learning_rate": 1.493431221020093e-05,
      "loss": 1.8745,
      "step": 7260
    },
    {
      "epoch": 1.4,
      "grad_norm": 4.744330406188965,
      "learning_rate": 1.4886012364760433e-05,
      "loss": 1.8301,
      "step": 7270
    },
    {
      "epoch": 1.41,
      "grad_norm": 7.147974014282227,
      "learning_rate": 1.4837712519319938e-05,
      "loss": 1.7338,
      "step": 7280
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.661832809448242,
      "learning_rate": 1.4789412673879444e-05,
      "loss": 1.7658,
      "step": 7290
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.685732126235962,
      "learning_rate": 1.4741112828438949e-05,
      "loss": 1.7964,
      "step": 7300
    },
    {
      "epoch": 1.41,
      "grad_norm": 14.697830200195312,
      "learning_rate": 1.4692812982998455e-05,
      "loss": 1.7757,
      "step": 7310
    },
    {
      "epoch": 1.41,
      "grad_norm": 6.180546283721924,
      "learning_rate": 1.4644513137557962e-05,
      "loss": 1.9761,
      "step": 7320
    },
    {
      "epoch": 1.42,
      "grad_norm": 4.269676208496094,
      "learning_rate": 1.4596213292117467e-05,
      "loss": 1.7583,
      "step": 7330
    },
    {
      "epoch": 1.42,
      "grad_norm": 23.462812423706055,
      "learning_rate": 1.4547913446676972e-05,
      "loss": 1.7639,
      "step": 7340
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.012217044830322,
      "learning_rate": 1.4499613601236478e-05,
      "loss": 1.7582,
      "step": 7350
    },
    {
      "epoch": 1.42,
      "grad_norm": 6.1383957862854,
      "learning_rate": 1.4451313755795981e-05,
      "loss": 1.935,
      "step": 7360
    },
    {
      "epoch": 1.42,
      "grad_norm": 11.512539863586426,
      "learning_rate": 1.4403013910355487e-05,
      "loss": 1.892,
      "step": 7370
    },
    {
      "epoch": 1.43,
      "grad_norm": 5.447507858276367,
      "learning_rate": 1.4354714064914992e-05,
      "loss": 1.8763,
      "step": 7380
    },
    {
      "epoch": 1.43,
      "grad_norm": 11.072792053222656,
      "learning_rate": 1.4306414219474498e-05,
      "loss": 1.8063,
      "step": 7390
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.3438873291015625,
      "learning_rate": 1.4258114374034005e-05,
      "loss": 1.8716,
      "step": 7400
    },
    {
      "epoch": 1.43,
      "grad_norm": 6.480071067810059,
      "learning_rate": 1.420981452859351e-05,
      "loss": 1.7944,
      "step": 7410
    },
    {
      "epoch": 1.43,
      "grad_norm": 4.71604585647583,
      "learning_rate": 1.4161514683153016e-05,
      "loss": 1.7321,
      "step": 7420
    },
    {
      "epoch": 1.44,
      "grad_norm": 22.25400733947754,
      "learning_rate": 1.4113214837712521e-05,
      "loss": 1.8635,
      "step": 7430
    },
    {
      "epoch": 1.44,
      "grad_norm": 5.553311347961426,
      "learning_rate": 1.4064914992272025e-05,
      "loss": 1.7583,
      "step": 7440
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.430113315582275,
      "learning_rate": 1.401661514683153e-05,
      "loss": 1.8977,
      "step": 7450
    },
    {
      "epoch": 1.44,
      "grad_norm": 18.361417770385742,
      "learning_rate": 1.3968315301391035e-05,
      "loss": 1.9296,
      "step": 7460
    },
    {
      "epoch": 1.44,
      "grad_norm": 8.770713806152344,
      "learning_rate": 1.392001545595054e-05,
      "loss": 1.7884,
      "step": 7470
    },
    {
      "epoch": 1.45,
      "grad_norm": 5.700755596160889,
      "learning_rate": 1.3871715610510048e-05,
      "loss": 1.7765,
      "step": 7480
    },
    {
      "epoch": 1.45,
      "grad_norm": 14.817022323608398,
      "learning_rate": 1.3823415765069553e-05,
      "loss": 1.8435,
      "step": 7490
    },
    {
      "epoch": 1.45,
      "grad_norm": 4.738095760345459,
      "learning_rate": 1.3775115919629059e-05,
      "loss": 1.8111,
      "step": 7500
    },
    {
      "epoch": 1.45,
      "grad_norm": 6.188582420349121,
      "learning_rate": 1.3726816074188564e-05,
      "loss": 1.9273,
      "step": 7510
    },
    {
      "epoch": 1.45,
      "grad_norm": 10.492987632751465,
      "learning_rate": 1.367851622874807e-05,
      "loss": 1.8729,
      "step": 7520
    },
    {
      "epoch": 1.45,
      "grad_norm": 5.672526836395264,
      "learning_rate": 1.3630216383307573e-05,
      "loss": 1.9044,
      "step": 7530
    },
    {
      "epoch": 1.46,
      "grad_norm": 18.50782012939453,
      "learning_rate": 1.3581916537867079e-05,
      "loss": 1.8075,
      "step": 7540
    },
    {
      "epoch": 1.46,
      "grad_norm": 7.849888324737549,
      "learning_rate": 1.3533616692426584e-05,
      "loss": 1.8977,
      "step": 7550
    },
    {
      "epoch": 1.46,
      "grad_norm": 4.74507999420166,
      "learning_rate": 1.3485316846986091e-05,
      "loss": 1.7953,
      "step": 7560
    },
    {
      "epoch": 1.46,
      "grad_norm": 11.16986083984375,
      "learning_rate": 1.3437017001545596e-05,
      "loss": 1.781,
      "step": 7570
    },
    {
      "epoch": 1.46,
      "grad_norm": 6.962717056274414,
      "learning_rate": 1.3388717156105102e-05,
      "loss": 1.7582,
      "step": 7580
    },
    {
      "epoch": 1.47,
      "grad_norm": 2.945223808288574,
      "learning_rate": 1.3340417310664607e-05,
      "loss": 1.6198,
      "step": 7590
    },
    {
      "epoch": 1.47,
      "grad_norm": 3.1183924674987793,
      "learning_rate": 1.3292117465224113e-05,
      "loss": 1.8635,
      "step": 7600
    },
    {
      "epoch": 1.47,
      "grad_norm": 42.30608367919922,
      "learning_rate": 1.3243817619783616e-05,
      "loss": 1.8282,
      "step": 7610
    },
    {
      "epoch": 1.47,
      "grad_norm": 5.343849182128906,
      "learning_rate": 1.3195517774343122e-05,
      "loss": 1.6957,
      "step": 7620
    },
    {
      "epoch": 1.47,
      "grad_norm": 7.1930718421936035,
      "learning_rate": 1.3147217928902627e-05,
      "loss": 1.8376,
      "step": 7630
    },
    {
      "epoch": 1.48,
      "grad_norm": 6.467588901519775,
      "learning_rate": 1.3098918083462134e-05,
      "loss": 1.8113,
      "step": 7640
    },
    {
      "epoch": 1.48,
      "grad_norm": 5.934568881988525,
      "learning_rate": 1.305061823802164e-05,
      "loss": 1.9196,
      "step": 7650
    },
    {
      "epoch": 1.48,
      "grad_norm": 4.028285026550293,
      "learning_rate": 1.3002318392581145e-05,
      "loss": 1.8135,
      "step": 7660
    },
    {
      "epoch": 1.48,
      "grad_norm": 6.488781929016113,
      "learning_rate": 1.295401854714065e-05,
      "loss": 1.8015,
      "step": 7670
    },
    {
      "epoch": 1.48,
      "grad_norm": 17.291522979736328,
      "learning_rate": 1.2905718701700156e-05,
      "loss": 1.8271,
      "step": 7680
    },
    {
      "epoch": 1.49,
      "grad_norm": 7.585897445678711,
      "learning_rate": 1.285741885625966e-05,
      "loss": 1.8402,
      "step": 7690
    },
    {
      "epoch": 1.49,
      "grad_norm": 10.399519920349121,
      "learning_rate": 1.2809119010819165e-05,
      "loss": 1.9399,
      "step": 7700
    },
    {
      "epoch": 1.49,
      "grad_norm": 7.382762908935547,
      "learning_rate": 1.276081916537867e-05,
      "loss": 1.8687,
      "step": 7710
    },
    {
      "epoch": 1.49,
      "grad_norm": 16.17131996154785,
      "learning_rate": 1.2712519319938177e-05,
      "loss": 1.8368,
      "step": 7720
    },
    {
      "epoch": 1.49,
      "grad_norm": 21.26943016052246,
      "learning_rate": 1.2664219474497683e-05,
      "loss": 1.8156,
      "step": 7730
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.9290335178375244,
      "learning_rate": 1.2615919629057188e-05,
      "loss": 1.8192,
      "step": 7740
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.0316529273986816,
      "learning_rate": 1.2567619783616693e-05,
      "loss": 1.8813,
      "step": 7750
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.8537521362304688,
      "learning_rate": 1.2519319938176199e-05,
      "loss": 1.7911,
      "step": 7760
    },
    {
      "epoch": 1.5,
      "grad_norm": 4.344783306121826,
      "learning_rate": 1.2471020092735704e-05,
      "loss": 1.822,
      "step": 7770
    },
    {
      "epoch": 1.5,
      "grad_norm": 18.074190139770508,
      "learning_rate": 1.242272024729521e-05,
      "loss": 1.8871,
      "step": 7780
    },
    {
      "epoch": 1.51,
      "grad_norm": 9.046500205993652,
      "learning_rate": 1.2374420401854715e-05,
      "loss": 1.7726,
      "step": 7790
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.670020818710327,
      "learning_rate": 1.232612055641422e-05,
      "loss": 1.8188,
      "step": 7800
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.5750997066497803,
      "learning_rate": 1.2277820710973726e-05,
      "loss": 1.8283,
      "step": 7810
    },
    {
      "epoch": 1.51,
      "grad_norm": 4.337550163269043,
      "learning_rate": 1.2229520865533231e-05,
      "loss": 1.8304,
      "step": 7820
    },
    {
      "epoch": 1.51,
      "grad_norm": 6.785642623901367,
      "learning_rate": 1.2181221020092737e-05,
      "loss": 1.7978,
      "step": 7830
    },
    {
      "epoch": 1.51,
      "grad_norm": 16.55763816833496,
      "learning_rate": 1.2132921174652242e-05,
      "loss": 1.9269,
      "step": 7840
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.6435606479644775,
      "learning_rate": 1.2084621329211747e-05,
      "loss": 1.8816,
      "step": 7850
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.542895317077637,
      "learning_rate": 1.2036321483771253e-05,
      "loss": 1.8657,
      "step": 7860
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.136216163635254,
      "learning_rate": 1.1988021638330758e-05,
      "loss": 1.9371,
      "step": 7870
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.567753791809082,
      "learning_rate": 1.1939721792890263e-05,
      "loss": 1.8714,
      "step": 7880
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.9374566078186035,
      "learning_rate": 1.1891421947449769e-05,
      "loss": 1.7918,
      "step": 7890
    },
    {
      "epoch": 1.53,
      "grad_norm": 4.753974437713623,
      "learning_rate": 1.1843122102009274e-05,
      "loss": 1.7962,
      "step": 7900
    },
    {
      "epoch": 1.53,
      "grad_norm": 11.310473442077637,
      "learning_rate": 1.179482225656878e-05,
      "loss": 1.7201,
      "step": 7910
    },
    {
      "epoch": 1.53,
      "grad_norm": 11.668658256530762,
      "learning_rate": 1.1746522411128285e-05,
      "loss": 1.8,
      "step": 7920
    },
    {
      "epoch": 1.53,
      "grad_norm": 6.761082172393799,
      "learning_rate": 1.169822256568779e-05,
      "loss": 1.7432,
      "step": 7930
    },
    {
      "epoch": 1.53,
      "grad_norm": 11.216443061828613,
      "learning_rate": 1.1649922720247296e-05,
      "loss": 1.8207,
      "step": 7940
    },
    {
      "epoch": 1.54,
      "grad_norm": 5.273488998413086,
      "learning_rate": 1.1601622874806801e-05,
      "loss": 1.8796,
      "step": 7950
    },
    {
      "epoch": 1.54,
      "grad_norm": 10.118000984191895,
      "learning_rate": 1.1553323029366307e-05,
      "loss": 1.8386,
      "step": 7960
    },
    {
      "epoch": 1.54,
      "grad_norm": 4.429466724395752,
      "learning_rate": 1.1505023183925812e-05,
      "loss": 1.7541,
      "step": 7970
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.20322585105896,
      "learning_rate": 1.1456723338485317e-05,
      "loss": 1.7651,
      "step": 7980
    },
    {
      "epoch": 1.54,
      "grad_norm": 27.980894088745117,
      "learning_rate": 1.1408423493044823e-05,
      "loss": 1.7201,
      "step": 7990
    },
    {
      "epoch": 1.55,
      "grad_norm": 6.028223514556885,
      "learning_rate": 1.1360123647604328e-05,
      "loss": 1.7774,
      "step": 8000
    },
    {
      "epoch": 1.55,
      "grad_norm": 3.123046875,
      "learning_rate": 1.1311823802163834e-05,
      "loss": 1.7741,
      "step": 8010
    },
    {
      "epoch": 1.55,
      "grad_norm": 10.422560691833496,
      "learning_rate": 1.1263523956723339e-05,
      "loss": 1.7731,
      "step": 8020
    },
    {
      "epoch": 1.55,
      "grad_norm": 3.825244426727295,
      "learning_rate": 1.1215224111282844e-05,
      "loss": 1.8316,
      "step": 8030
    },
    {
      "epoch": 1.55,
      "grad_norm": 4.9312944412231445,
      "learning_rate": 1.116692426584235e-05,
      "loss": 1.8794,
      "step": 8040
    },
    {
      "epoch": 1.56,
      "grad_norm": 12.745820999145508,
      "learning_rate": 1.1118624420401855e-05,
      "loss": 1.8822,
      "step": 8050
    },
    {
      "epoch": 1.56,
      "grad_norm": 9.248758316040039,
      "learning_rate": 1.107032457496136e-05,
      "loss": 1.7627,
      "step": 8060
    },
    {
      "epoch": 1.56,
      "grad_norm": 4.599221229553223,
      "learning_rate": 1.1022024729520866e-05,
      "loss": 1.9136,
      "step": 8070
    },
    {
      "epoch": 1.56,
      "grad_norm": 13.350667953491211,
      "learning_rate": 1.0973724884080371e-05,
      "loss": 1.8094,
      "step": 8080
    },
    {
      "epoch": 1.56,
      "grad_norm": 6.531341075897217,
      "learning_rate": 1.0925425038639877e-05,
      "loss": 1.7215,
      "step": 8090
    },
    {
      "epoch": 1.56,
      "grad_norm": 5.039847373962402,
      "learning_rate": 1.0877125193199382e-05,
      "loss": 1.8294,
      "step": 8100
    },
    {
      "epoch": 1.57,
      "grad_norm": 4.793174743652344,
      "learning_rate": 1.0828825347758887e-05,
      "loss": 1.8419,
      "step": 8110
    },
    {
      "epoch": 1.57,
      "grad_norm": 5.911662578582764,
      "learning_rate": 1.0780525502318393e-05,
      "loss": 1.6771,
      "step": 8120
    },
    {
      "epoch": 1.57,
      "grad_norm": 11.924256324768066,
      "learning_rate": 1.0732225656877898e-05,
      "loss": 1.8864,
      "step": 8130
    },
    {
      "epoch": 1.57,
      "grad_norm": 9.10790729522705,
      "learning_rate": 1.0683925811437404e-05,
      "loss": 1.9349,
      "step": 8140
    },
    {
      "epoch": 1.57,
      "grad_norm": 13.370003700256348,
      "learning_rate": 1.0635625965996909e-05,
      "loss": 1.7806,
      "step": 8150
    },
    {
      "epoch": 1.58,
      "grad_norm": 21.117473602294922,
      "learning_rate": 1.0587326120556414e-05,
      "loss": 1.8131,
      "step": 8160
    },
    {
      "epoch": 1.58,
      "grad_norm": 4.533880233764648,
      "learning_rate": 1.0539026275115921e-05,
      "loss": 1.9576,
      "step": 8170
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.646586894989014,
      "learning_rate": 1.0490726429675425e-05,
      "loss": 1.7666,
      "step": 8180
    },
    {
      "epoch": 1.58,
      "grad_norm": 4.355899810791016,
      "learning_rate": 1.044242658423493e-05,
      "loss": 1.7781,
      "step": 8190
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.829228639602661,
      "learning_rate": 1.0394126738794436e-05,
      "loss": 1.7638,
      "step": 8200
    },
    {
      "epoch": 1.59,
      "grad_norm": 4.299288749694824,
      "learning_rate": 1.0345826893353943e-05,
      "loss": 1.9208,
      "step": 8210
    },
    {
      "epoch": 1.59,
      "grad_norm": 6.8903279304504395,
      "learning_rate": 1.0297527047913447e-05,
      "loss": 1.6698,
      "step": 8220
    },
    {
      "epoch": 1.59,
      "grad_norm": 6.023564338684082,
      "learning_rate": 1.0249227202472952e-05,
      "loss": 1.8666,
      "step": 8230
    },
    {
      "epoch": 1.59,
      "grad_norm": 37.23914337158203,
      "learning_rate": 1.0200927357032458e-05,
      "loss": 1.8335,
      "step": 8240
    },
    {
      "epoch": 1.59,
      "grad_norm": 8.728720664978027,
      "learning_rate": 1.0152627511591965e-05,
      "loss": 1.7787,
      "step": 8250
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.511316299438477,
      "learning_rate": 1.0104327666151468e-05,
      "loss": 1.6954,
      "step": 8260
    },
    {
      "epoch": 1.6,
      "grad_norm": 10.245585441589355,
      "learning_rate": 1.0056027820710974e-05,
      "loss": 1.8937,
      "step": 8270
    },
    {
      "epoch": 1.6,
      "grad_norm": 32.47176742553711,
      "learning_rate": 1.0007727975270479e-05,
      "loss": 1.8423,
      "step": 8280
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.3932785987854004,
      "learning_rate": 9.959428129829986e-06,
      "loss": 1.8137,
      "step": 8290
    },
    {
      "epoch": 1.6,
      "grad_norm": 7.465877056121826,
      "learning_rate": 9.91112828438949e-06,
      "loss": 1.8437,
      "step": 8300
    },
    {
      "epoch": 1.61,
      "grad_norm": 9.449926376342773,
      "learning_rate": 9.862828438948995e-06,
      "loss": 1.7442,
      "step": 8310
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.828223705291748,
      "learning_rate": 9.8145285935085e-06,
      "loss": 1.8591,
      "step": 8320
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.73524808883667,
      "learning_rate": 9.766228748068008e-06,
      "loss": 1.7795,
      "step": 8330
    },
    {
      "epoch": 1.61,
      "grad_norm": 4.191903114318848,
      "learning_rate": 9.717928902627511e-06,
      "loss": 1.7889,
      "step": 8340
    },
    {
      "epoch": 1.61,
      "grad_norm": 4.623872756958008,
      "learning_rate": 9.669629057187017e-06,
      "loss": 1.7971,
      "step": 8350
    },
    {
      "epoch": 1.62,
      "grad_norm": 4.289031982421875,
      "learning_rate": 9.621329211746522e-06,
      "loss": 1.7975,
      "step": 8360
    },
    {
      "epoch": 1.62,
      "grad_norm": 5.644751071929932,
      "learning_rate": 9.57302936630603e-06,
      "loss": 1.7629,
      "step": 8370
    },
    {
      "epoch": 1.62,
      "grad_norm": 10.40076732635498,
      "learning_rate": 9.524729520865535e-06,
      "loss": 1.9444,
      "step": 8380
    },
    {
      "epoch": 1.62,
      "grad_norm": 5.371562957763672,
      "learning_rate": 9.476429675425038e-06,
      "loss": 1.8261,
      "step": 8390
    },
    {
      "epoch": 1.62,
      "grad_norm": 11.46846866607666,
      "learning_rate": 9.428129829984544e-06,
      "loss": 1.7917,
      "step": 8400
    },
    {
      "epoch": 1.62,
      "grad_norm": 13.173624992370605,
      "learning_rate": 9.37982998454405e-06,
      "loss": 1.6734,
      "step": 8410
    },
    {
      "epoch": 1.63,
      "grad_norm": 5.986289978027344,
      "learning_rate": 9.331530139103556e-06,
      "loss": 1.7614,
      "step": 8420
    },
    {
      "epoch": 1.63,
      "grad_norm": 10.905080795288086,
      "learning_rate": 9.28323029366306e-06,
      "loss": 1.8674,
      "step": 8430
    },
    {
      "epoch": 1.63,
      "grad_norm": 8.893590927124023,
      "learning_rate": 9.234930448222565e-06,
      "loss": 1.8467,
      "step": 8440
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.304110288619995,
      "learning_rate": 9.186630602782072e-06,
      "loss": 1.7793,
      "step": 8450
    },
    {
      "epoch": 1.63,
      "grad_norm": 38.84960174560547,
      "learning_rate": 9.138330757341578e-06,
      "loss": 1.7854,
      "step": 8460
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.593104839324951,
      "learning_rate": 9.090030911901081e-06,
      "loss": 1.9389,
      "step": 8470
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.494390964508057,
      "learning_rate": 9.041731066460587e-06,
      "loss": 1.7158,
      "step": 8480
    },
    {
      "epoch": 1.64,
      "grad_norm": 6.604211807250977,
      "learning_rate": 8.993431221020094e-06,
      "loss": 1.817,
      "step": 8490
    },
    {
      "epoch": 1.64,
      "grad_norm": 8.409168243408203,
      "learning_rate": 8.9451313755796e-06,
      "loss": 1.8648,
      "step": 8500
    },
    {
      "epoch": 1.64,
      "grad_norm": 7.18859338760376,
      "learning_rate": 8.896831530139103e-06,
      "loss": 1.637,
      "step": 8510
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.5243330001831055,
      "learning_rate": 8.848531684698608e-06,
      "loss": 1.9837,
      "step": 8520
    },
    {
      "epoch": 1.65,
      "grad_norm": 10.911335945129395,
      "learning_rate": 8.800231839258116e-06,
      "loss": 1.8146,
      "step": 8530
    },
    {
      "epoch": 1.65,
      "grad_norm": 6.830844879150391,
      "learning_rate": 8.751931993817621e-06,
      "loss": 1.8502,
      "step": 8540
    },
    {
      "epoch": 1.65,
      "grad_norm": 6.45206356048584,
      "learning_rate": 8.703632148377125e-06,
      "loss": 1.9311,
      "step": 8550
    },
    {
      "epoch": 1.65,
      "grad_norm": 9.012900352478027,
      "learning_rate": 8.65533230293663e-06,
      "loss": 1.7426,
      "step": 8560
    },
    {
      "epoch": 1.66,
      "grad_norm": 10.127899169921875,
      "learning_rate": 8.607032457496137e-06,
      "loss": 1.7713,
      "step": 8570
    },
    {
      "epoch": 1.66,
      "grad_norm": 6.835199356079102,
      "learning_rate": 8.558732612055642e-06,
      "loss": 1.8542,
      "step": 8580
    },
    {
      "epoch": 1.66,
      "grad_norm": 5.368827819824219,
      "learning_rate": 8.510432766615148e-06,
      "loss": 1.8417,
      "step": 8590
    },
    {
      "epoch": 1.66,
      "grad_norm": 15.510774612426758,
      "learning_rate": 8.462132921174652e-06,
      "loss": 1.7773,
      "step": 8600
    },
    {
      "epoch": 1.66,
      "grad_norm": 4.085052490234375,
      "learning_rate": 8.413833075734159e-06,
      "loss": 1.8391,
      "step": 8610
    },
    {
      "epoch": 1.67,
      "grad_norm": 6.754365921020508,
      "learning_rate": 8.365533230293664e-06,
      "loss": 1.9335,
      "step": 8620
    },
    {
      "epoch": 1.67,
      "grad_norm": 3.1791460514068604,
      "learning_rate": 8.31723338485317e-06,
      "loss": 1.8552,
      "step": 8630
    },
    {
      "epoch": 1.67,
      "grad_norm": 9.676457405090332,
      "learning_rate": 8.268933539412673e-06,
      "loss": 1.7804,
      "step": 8640
    },
    {
      "epoch": 1.67,
      "grad_norm": 8.654069900512695,
      "learning_rate": 8.22063369397218e-06,
      "loss": 1.889,
      "step": 8650
    },
    {
      "epoch": 1.67,
      "grad_norm": 6.334933280944824,
      "learning_rate": 8.172333848531686e-06,
      "loss": 1.9047,
      "step": 8660
    },
    {
      "epoch": 1.68,
      "grad_norm": 6.374536037445068,
      "learning_rate": 8.124034003091191e-06,
      "loss": 1.791,
      "step": 8670
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.955280303955078,
      "learning_rate": 8.075734157650695e-06,
      "loss": 1.821,
      "step": 8680
    },
    {
      "epoch": 1.68,
      "grad_norm": 6.057497024536133,
      "learning_rate": 8.027434312210202e-06,
      "loss": 1.7303,
      "step": 8690
    },
    {
      "epoch": 1.68,
      "grad_norm": 6.282639503479004,
      "learning_rate": 7.979134466769707e-06,
      "loss": 1.7255,
      "step": 8700
    },
    {
      "epoch": 1.68,
      "grad_norm": 4.926921844482422,
      "learning_rate": 7.930834621329213e-06,
      "loss": 1.8272,
      "step": 8710
    },
    {
      "epoch": 1.68,
      "grad_norm": 5.016631603240967,
      "learning_rate": 7.882534775888716e-06,
      "loss": 1.8768,
      "step": 8720
    },
    {
      "epoch": 1.69,
      "grad_norm": 6.675820827484131,
      "learning_rate": 7.834234930448223e-06,
      "loss": 1.787,
      "step": 8730
    },
    {
      "epoch": 1.69,
      "grad_norm": 3.992258071899414,
      "learning_rate": 7.785935085007729e-06,
      "loss": 1.8484,
      "step": 8740
    },
    {
      "epoch": 1.69,
      "grad_norm": 10.635244369506836,
      "learning_rate": 7.737635239567234e-06,
      "loss": 1.7779,
      "step": 8750
    },
    {
      "epoch": 1.69,
      "grad_norm": 4.1422929763793945,
      "learning_rate": 7.689335394126738e-06,
      "loss": 1.8042,
      "step": 8760
    },
    {
      "epoch": 1.69,
      "grad_norm": 10.0559663772583,
      "learning_rate": 7.641035548686245e-06,
      "loss": 1.7467,
      "step": 8770
    },
    {
      "epoch": 1.7,
      "grad_norm": 9.66066837310791,
      "learning_rate": 7.59273570324575e-06,
      "loss": 1.6183,
      "step": 8780
    },
    {
      "epoch": 1.7,
      "grad_norm": 17.22589111328125,
      "learning_rate": 7.544435857805256e-06,
      "loss": 1.996,
      "step": 8790
    },
    {
      "epoch": 1.7,
      "grad_norm": 5.269350051879883,
      "learning_rate": 7.496136012364761e-06,
      "loss": 1.7416,
      "step": 8800
    },
    {
      "epoch": 1.7,
      "grad_norm": 10.497654914855957,
      "learning_rate": 7.447836166924266e-06,
      "loss": 1.9378,
      "step": 8810
    },
    {
      "epoch": 1.7,
      "grad_norm": 17.379802703857422,
      "learning_rate": 7.399536321483772e-06,
      "loss": 1.7339,
      "step": 8820
    },
    {
      "epoch": 1.71,
      "grad_norm": 6.384565830230713,
      "learning_rate": 7.351236476043277e-06,
      "loss": 1.7658,
      "step": 8830
    },
    {
      "epoch": 1.71,
      "grad_norm": 7.668420314788818,
      "learning_rate": 7.302936630602783e-06,
      "loss": 1.797,
      "step": 8840
    },
    {
      "epoch": 1.71,
      "grad_norm": 6.866000175476074,
      "learning_rate": 7.254636785162287e-06,
      "loss": 1.9356,
      "step": 8850
    },
    {
      "epoch": 1.71,
      "grad_norm": 4.1004958152771,
      "learning_rate": 7.206336939721793e-06,
      "loss": 1.6705,
      "step": 8860
    },
    {
      "epoch": 1.71,
      "grad_norm": 4.670814514160156,
      "learning_rate": 7.158037094281299e-06,
      "loss": 1.7483,
      "step": 8870
    },
    {
      "epoch": 1.72,
      "grad_norm": 9.61104965209961,
      "learning_rate": 7.109737248840804e-06,
      "loss": 1.7978,
      "step": 8880
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.5408124923706055,
      "learning_rate": 7.061437403400309e-06,
      "loss": 1.8909,
      "step": 8890
    },
    {
      "epoch": 1.72,
      "grad_norm": 16.53595733642578,
      "learning_rate": 7.013137557959815e-06,
      "loss": 2.0854,
      "step": 8900
    },
    {
      "epoch": 1.72,
      "grad_norm": 7.478730201721191,
      "learning_rate": 6.96483771251932e-06,
      "loss": 1.7812,
      "step": 8910
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.158832550048828,
      "learning_rate": 6.916537867078826e-06,
      "loss": 1.8029,
      "step": 8920
    },
    {
      "epoch": 1.73,
      "grad_norm": 5.235408306121826,
      "learning_rate": 6.86823802163833e-06,
      "loss": 1.8061,
      "step": 8930
    },
    {
      "epoch": 1.73,
      "grad_norm": 4.070465564727783,
      "learning_rate": 6.8199381761978365e-06,
      "loss": 1.8349,
      "step": 8940
    },
    {
      "epoch": 1.73,
      "grad_norm": 5.820075035095215,
      "learning_rate": 6.771638330757342e-06,
      "loss": 1.848,
      "step": 8950
    },
    {
      "epoch": 1.73,
      "grad_norm": 4.120875835418701,
      "learning_rate": 6.723338485316847e-06,
      "loss": 1.8255,
      "step": 8960
    },
    {
      "epoch": 1.73,
      "grad_norm": 6.673956394195557,
      "learning_rate": 6.675038639876352e-06,
      "loss": 1.8632,
      "step": 8970
    },
    {
      "epoch": 1.73,
      "grad_norm": 20.771787643432617,
      "learning_rate": 6.626738794435858e-06,
      "loss": 1.9209,
      "step": 8980
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.863679885864258,
      "learning_rate": 6.5784389489953635e-06,
      "loss": 1.9486,
      "step": 8990
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.429171562194824,
      "learning_rate": 6.530139103554869e-06,
      "loss": 1.8171,
      "step": 9000
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.670764684677124,
      "learning_rate": 6.481839258114375e-06,
      "loss": 1.6799,
      "step": 9010
    },
    {
      "epoch": 1.74,
      "grad_norm": 6.439200401306152,
      "learning_rate": 6.43353941267388e-06,
      "loss": 1.6565,
      "step": 9020
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.1883134841918945,
      "learning_rate": 6.385239567233385e-06,
      "loss": 1.9187,
      "step": 9030
    },
    {
      "epoch": 1.75,
      "grad_norm": 5.2202935218811035,
      "learning_rate": 6.3369397217928904e-06,
      "loss": 1.9419,
      "step": 9040
    },
    {
      "epoch": 1.75,
      "grad_norm": 5.2287397384643555,
      "learning_rate": 6.288639876352397e-06,
      "loss": 1.8065,
      "step": 9050
    },
    {
      "epoch": 1.75,
      "grad_norm": 5.664492607116699,
      "learning_rate": 6.240340030911901e-06,
      "loss": 1.7409,
      "step": 9060
    },
    {
      "epoch": 1.75,
      "grad_norm": 12.998749732971191,
      "learning_rate": 6.192040185471407e-06,
      "loss": 1.8531,
      "step": 9070
    },
    {
      "epoch": 1.75,
      "grad_norm": 18.89012908935547,
      "learning_rate": 6.143740340030912e-06,
      "loss": 1.9622,
      "step": 9080
    },
    {
      "epoch": 1.76,
      "grad_norm": 7.808173656463623,
      "learning_rate": 6.095440494590417e-06,
      "loss": 1.7757,
      "step": 9090
    },
    {
      "epoch": 1.76,
      "grad_norm": 7.750152587890625,
      "learning_rate": 6.047140649149923e-06,
      "loss": 1.7889,
      "step": 9100
    },
    {
      "epoch": 1.76,
      "grad_norm": 8.328801155090332,
      "learning_rate": 5.998840803709428e-06,
      "loss": 1.7965,
      "step": 9110
    },
    {
      "epoch": 1.76,
      "grad_norm": 10.974767684936523,
      "learning_rate": 5.9505409582689335e-06,
      "loss": 1.8124,
      "step": 9120
    },
    {
      "epoch": 1.76,
      "grad_norm": 6.10870885848999,
      "learning_rate": 5.902241112828439e-06,
      "loss": 1.8456,
      "step": 9130
    },
    {
      "epoch": 1.77,
      "grad_norm": 9.53679084777832,
      "learning_rate": 5.853941267387944e-06,
      "loss": 1.7841,
      "step": 9140
    },
    {
      "epoch": 1.77,
      "grad_norm": 7.83945369720459,
      "learning_rate": 5.80564142194745e-06,
      "loss": 1.8391,
      "step": 9150
    },
    {
      "epoch": 1.77,
      "grad_norm": 12.390243530273438,
      "learning_rate": 5.757341576506955e-06,
      "loss": 1.8022,
      "step": 9160
    },
    {
      "epoch": 1.77,
      "grad_norm": 6.357089519500732,
      "learning_rate": 5.7090417310664605e-06,
      "loss": 1.7831,
      "step": 9170
    },
    {
      "epoch": 1.77,
      "grad_norm": 6.769309997558594,
      "learning_rate": 5.660741885625966e-06,
      "loss": 1.905,
      "step": 9180
    },
    {
      "epoch": 1.78,
      "grad_norm": 13.751240730285645,
      "learning_rate": 5.612442040185472e-06,
      "loss": 1.7401,
      "step": 9190
    },
    {
      "epoch": 1.78,
      "grad_norm": 6.759350776672363,
      "learning_rate": 5.564142194744977e-06,
      "loss": 1.7749,
      "step": 9200
    },
    {
      "epoch": 1.78,
      "grad_norm": 7.959718227386475,
      "learning_rate": 5.515842349304483e-06,
      "loss": 1.8113,
      "step": 9210
    },
    {
      "epoch": 1.78,
      "grad_norm": 7.755118370056152,
      "learning_rate": 5.4675425038639875e-06,
      "loss": 1.7323,
      "step": 9220
    },
    {
      "epoch": 1.78,
      "grad_norm": 3.84541916847229,
      "learning_rate": 5.419242658423494e-06,
      "loss": 1.8705,
      "step": 9230
    },
    {
      "epoch": 1.79,
      "grad_norm": 5.789711952209473,
      "learning_rate": 5.370942812982998e-06,
      "loss": 1.7963,
      "step": 9240
    },
    {
      "epoch": 1.79,
      "grad_norm": 7.061842441558838,
      "learning_rate": 5.3226429675425045e-06,
      "loss": 1.7535,
      "step": 9250
    },
    {
      "epoch": 1.79,
      "grad_norm": 6.444509506225586,
      "learning_rate": 5.274343122102009e-06,
      "loss": 1.7223,
      "step": 9260
    },
    {
      "epoch": 1.79,
      "grad_norm": 5.35390043258667,
      "learning_rate": 5.226043276661515e-06,
      "loss": 1.776,
      "step": 9270
    },
    {
      "epoch": 1.79,
      "grad_norm": 6.859521389007568,
      "learning_rate": 5.17774343122102e-06,
      "loss": 1.8807,
      "step": 9280
    },
    {
      "epoch": 1.79,
      "grad_norm": 6.300440311431885,
      "learning_rate": 5.129443585780526e-06,
      "loss": 1.7751,
      "step": 9290
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.0736918449401855,
      "learning_rate": 5.0811437403400306e-06,
      "loss": 1.9846,
      "step": 9300
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.040762424468994,
      "learning_rate": 5.032843894899537e-06,
      "loss": 1.842,
      "step": 9310
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.012515068054199,
      "learning_rate": 4.984544049459041e-06,
      "loss": 1.6567,
      "step": 9320
    },
    {
      "epoch": 1.8,
      "grad_norm": 9.19300651550293,
      "learning_rate": 4.936244204018548e-06,
      "loss": 1.7104,
      "step": 9330
    },
    {
      "epoch": 1.8,
      "grad_norm": 22.621660232543945,
      "learning_rate": 4.887944358578052e-06,
      "loss": 1.8674,
      "step": 9340
    },
    {
      "epoch": 1.81,
      "grad_norm": 7.064842224121094,
      "learning_rate": 4.839644513137558e-06,
      "loss": 1.9232,
      "step": 9350
    },
    {
      "epoch": 1.81,
      "grad_norm": 7.960102081298828,
      "learning_rate": 4.791344667697063e-06,
      "loss": 1.817,
      "step": 9360
    },
    {
      "epoch": 1.81,
      "grad_norm": 6.70323371887207,
      "learning_rate": 4.743044822256569e-06,
      "loss": 1.6583,
      "step": 9370
    },
    {
      "epoch": 1.81,
      "grad_norm": 8.228599548339844,
      "learning_rate": 4.694744976816074e-06,
      "loss": 1.876,
      "step": 9380
    },
    {
      "epoch": 1.81,
      "grad_norm": 5.506947040557861,
      "learning_rate": 4.64644513137558e-06,
      "loss": 1.7621,
      "step": 9390
    },
    {
      "epoch": 1.82,
      "grad_norm": 29.345258712768555,
      "learning_rate": 4.598145285935085e-06,
      "loss": 2.0563,
      "step": 9400
    },
    {
      "epoch": 1.82,
      "grad_norm": 7.9318318367004395,
      "learning_rate": 4.549845440494591e-06,
      "loss": 1.8222,
      "step": 9410
    },
    {
      "epoch": 1.82,
      "grad_norm": 12.8427734375,
      "learning_rate": 4.501545595054096e-06,
      "loss": 1.9677,
      "step": 9420
    },
    {
      "epoch": 1.82,
      "grad_norm": 6.196568489074707,
      "learning_rate": 4.4532457496136015e-06,
      "loss": 1.8279,
      "step": 9430
    },
    {
      "epoch": 1.82,
      "grad_norm": 3.641064167022705,
      "learning_rate": 4.404945904173107e-06,
      "loss": 1.7603,
      "step": 9440
    },
    {
      "epoch": 1.83,
      "grad_norm": 5.4687652587890625,
      "learning_rate": 4.356646058732612e-06,
      "loss": 1.7901,
      "step": 9450
    },
    {
      "epoch": 1.83,
      "grad_norm": 6.594400882720947,
      "learning_rate": 4.308346213292118e-06,
      "loss": 1.7293,
      "step": 9460
    },
    {
      "epoch": 1.83,
      "grad_norm": 18.089031219482422,
      "learning_rate": 4.260046367851623e-06,
      "loss": 1.7761,
      "step": 9470
    },
    {
      "epoch": 1.83,
      "grad_norm": 5.6120829582214355,
      "learning_rate": 4.2117465224111284e-06,
      "loss": 1.7543,
      "step": 9480
    },
    {
      "epoch": 1.83,
      "grad_norm": 5.340545654296875,
      "learning_rate": 4.163446676970634e-06,
      "loss": 1.7595,
      "step": 9490
    },
    {
      "epoch": 1.84,
      "grad_norm": 5.62434196472168,
      "learning_rate": 4.115146831530139e-06,
      "loss": 1.8461,
      "step": 9500
    },
    {
      "epoch": 1.84,
      "grad_norm": 11.517315864562988,
      "learning_rate": 4.066846986089645e-06,
      "loss": 1.7961,
      "step": 9510
    },
    {
      "epoch": 1.84,
      "grad_norm": 17.157957077026367,
      "learning_rate": 4.01854714064915e-06,
      "loss": 1.8586,
      "step": 9520
    },
    {
      "epoch": 1.84,
      "grad_norm": 6.821659088134766,
      "learning_rate": 3.970247295208655e-06,
      "loss": 1.7262,
      "step": 9530
    },
    {
      "epoch": 1.84,
      "grad_norm": 25.774076461791992,
      "learning_rate": 3.921947449768161e-06,
      "loss": 1.838,
      "step": 9540
    },
    {
      "epoch": 1.85,
      "grad_norm": 3.5554146766662598,
      "learning_rate": 3.873647604327666e-06,
      "loss": 1.6501,
      "step": 9550
    },
    {
      "epoch": 1.85,
      "grad_norm": 13.610532760620117,
      "learning_rate": 3.8253477588871716e-06,
      "loss": 1.8162,
      "step": 9560
    },
    {
      "epoch": 1.85,
      "grad_norm": 8.68835163116455,
      "learning_rate": 3.777047913446677e-06,
      "loss": 1.6655,
      "step": 9570
    },
    {
      "epoch": 1.85,
      "grad_norm": 4.925208568572998,
      "learning_rate": 3.7287480680061828e-06,
      "loss": 1.7863,
      "step": 9580
    },
    {
      "epoch": 1.85,
      "grad_norm": 13.199919700622559,
      "learning_rate": 3.6804482225656877e-06,
      "loss": 1.803,
      "step": 9590
    },
    {
      "epoch": 1.85,
      "grad_norm": 13.555641174316406,
      "learning_rate": 3.6321483771251936e-06,
      "loss": 1.8275,
      "step": 9600
    },
    {
      "epoch": 1.86,
      "grad_norm": 4.751107692718506,
      "learning_rate": 3.583848531684699e-06,
      "loss": 1.6117,
      "step": 9610
    },
    {
      "epoch": 1.86,
      "grad_norm": 16.31805992126465,
      "learning_rate": 3.5355486862442043e-06,
      "loss": 1.7993,
      "step": 9620
    },
    {
      "epoch": 1.86,
      "grad_norm": 40.33696746826172,
      "learning_rate": 3.4872488408037097e-06,
      "loss": 1.7543,
      "step": 9630
    },
    {
      "epoch": 1.86,
      "grad_norm": 28.66231918334961,
      "learning_rate": 3.438948995363215e-06,
      "loss": 1.8107,
      "step": 9640
    },
    {
      "epoch": 1.86,
      "grad_norm": 14.511078834533691,
      "learning_rate": 3.3906491499227205e-06,
      "loss": 1.9882,
      "step": 9650
    },
    {
      "epoch": 1.87,
      "grad_norm": 42.45106887817383,
      "learning_rate": 3.342349304482226e-06,
      "loss": 2.012,
      "step": 9660
    },
    {
      "epoch": 1.87,
      "grad_norm": 7.417457580566406,
      "learning_rate": 3.2940494590417313e-06,
      "loss": 1.6946,
      "step": 9670
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.099104881286621,
      "learning_rate": 3.2457496136012367e-06,
      "loss": 1.7563,
      "step": 9680
    },
    {
      "epoch": 1.87,
      "grad_norm": 3.3565726280212402,
      "learning_rate": 3.197449768160742e-06,
      "loss": 1.9257,
      "step": 9690
    },
    {
      "epoch": 1.87,
      "grad_norm": 8.40714168548584,
      "learning_rate": 3.1491499227202475e-06,
      "loss": 1.593,
      "step": 9700
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.441448926925659,
      "learning_rate": 3.100850077279753e-06,
      "loss": 1.8049,
      "step": 9710
    },
    {
      "epoch": 1.88,
      "grad_norm": 8.762283325195312,
      "learning_rate": 3.0525502318392582e-06,
      "loss": 1.7747,
      "step": 9720
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.837574005126953,
      "learning_rate": 3.0042503863987636e-06,
      "loss": 1.7966,
      "step": 9730
    },
    {
      "epoch": 1.88,
      "grad_norm": 10.64705753326416,
      "learning_rate": 2.955950540958269e-06,
      "loss": 1.9526,
      "step": 9740
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.698513031005859,
      "learning_rate": 2.9076506955177744e-06,
      "loss": 1.7896,
      "step": 9750
    },
    {
      "epoch": 1.89,
      "grad_norm": 14.910139083862305,
      "learning_rate": 2.85935085007728e-06,
      "loss": 1.6331,
      "step": 9760
    },
    {
      "epoch": 1.89,
      "grad_norm": 12.789458274841309,
      "learning_rate": 2.811051004636785e-06,
      "loss": 1.8555,
      "step": 9770
    },
    {
      "epoch": 1.89,
      "grad_norm": 3.4340078830718994,
      "learning_rate": 2.7627511591962906e-06,
      "loss": 1.8456,
      "step": 9780
    },
    {
      "epoch": 1.89,
      "grad_norm": 5.640080451965332,
      "learning_rate": 2.714451313755796e-06,
      "loss": 1.9683,
      "step": 9790
    },
    {
      "epoch": 1.89,
      "grad_norm": 3.969930648803711,
      "learning_rate": 2.6661514683153014e-06,
      "loss": 1.8692,
      "step": 9800
    },
    {
      "epoch": 1.9,
      "grad_norm": 11.59457778930664,
      "learning_rate": 2.6178516228748067e-06,
      "loss": 1.6593,
      "step": 9810
    },
    {
      "epoch": 1.9,
      "grad_norm": 8.699268341064453,
      "learning_rate": 2.569551777434312e-06,
      "loss": 1.7521,
      "step": 9820
    },
    {
      "epoch": 1.9,
      "grad_norm": 19.803014755249023,
      "learning_rate": 2.5212519319938175e-06,
      "loss": 1.782,
      "step": 9830
    },
    {
      "epoch": 1.9,
      "grad_norm": 4.692877292633057,
      "learning_rate": 2.472952086553323e-06,
      "loss": 1.9298,
      "step": 9840
    },
    {
      "epoch": 1.9,
      "grad_norm": 34.046329498291016,
      "learning_rate": 2.4246522411128283e-06,
      "loss": 1.7833,
      "step": 9850
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.3483805656433105,
      "learning_rate": 2.3763523956723337e-06,
      "loss": 1.7902,
      "step": 9860
    },
    {
      "epoch": 1.91,
      "grad_norm": 21.15275001525879,
      "learning_rate": 2.328052550231839e-06,
      "loss": 1.7497,
      "step": 9870
    },
    {
      "epoch": 1.91,
      "grad_norm": 24.925451278686523,
      "learning_rate": 2.2797527047913445e-06,
      "loss": 1.7398,
      "step": 9880
    },
    {
      "epoch": 1.91,
      "grad_norm": 10.217535018920898,
      "learning_rate": 2.23145285935085e-06,
      "loss": 1.7197,
      "step": 9890
    },
    {
      "epoch": 1.91,
      "grad_norm": 4.893764495849609,
      "learning_rate": 2.1831530139103553e-06,
      "loss": 1.9067,
      "step": 9900
    },
    {
      "epoch": 1.91,
      "grad_norm": 11.811156272888184,
      "learning_rate": 2.1348531684698606e-06,
      "loss": 1.778,
      "step": 9910
    },
    {
      "epoch": 1.92,
      "grad_norm": 11.123636245727539,
      "learning_rate": 2.0865533230293665e-06,
      "loss": 1.6988,
      "step": 9920
    },
    {
      "epoch": 1.92,
      "grad_norm": 6.068378448486328,
      "learning_rate": 2.038253477588872e-06,
      "loss": 1.9415,
      "step": 9930
    },
    {
      "epoch": 1.92,
      "grad_norm": 6.346973419189453,
      "learning_rate": 1.9899536321483772e-06,
      "loss": 1.7555,
      "step": 9940
    },
    {
      "epoch": 1.92,
      "grad_norm": 40.91312789916992,
      "learning_rate": 1.9416537867078826e-06,
      "loss": 1.8368,
      "step": 9950
    },
    {
      "epoch": 1.92,
      "grad_norm": 6.679590225219727,
      "learning_rate": 1.8933539412673882e-06,
      "loss": 1.7721,
      "step": 9960
    },
    {
      "epoch": 1.93,
      "grad_norm": 11.292010307312012,
      "learning_rate": 1.8450540958268936e-06,
      "loss": 1.7305,
      "step": 9970
    },
    {
      "epoch": 1.93,
      "grad_norm": 4.593034744262695,
      "learning_rate": 1.796754250386399e-06,
      "loss": 1.7889,
      "step": 9980
    },
    {
      "epoch": 1.93,
      "grad_norm": 10.655942916870117,
      "learning_rate": 1.7484544049459044e-06,
      "loss": 1.7216,
      "step": 9990
    },
    {
      "epoch": 1.93,
      "grad_norm": 10.517552375793457,
      "learning_rate": 1.7001545595054098e-06,
      "loss": 1.837,
      "step": 10000
    }
  ],
  "logging_steps": 10,
  "max_steps": 10352,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 4.628019272299315e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
