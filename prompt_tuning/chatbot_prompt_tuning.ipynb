{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloom 1b1 finetuning with PEFT prompt tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23686\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, TrainerCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset.  \n",
    "The dataset used is alpaca cleaned version. The first 8000 rows from training set is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"yahma/alpaca-cleaned\", split=\"train[:8000]\")\n",
    "ds # inspect dataset structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect first 3 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': ['1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       "  'The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).',\n",
       "  \"An atom is the basic building block of all matter and is made up of three types of particles: protons, neutrons, and electrons. The structure of an atom can be described as a nucleus at the center surrounded by a cloud of electrons.\\n\\nThe nucleus of an atom is made up of protons and neutrons. Protons are positively charged particles and neutrons are neutral particles with no charge. Both of these particles are located in the nucleus of the atom, which is at the center of the atom and contains most of the atom's mass.\\n\\nSurrounding the nucleus of the atom is a cloud of electrons. Electrons are negatively charged particles that are in constant motion around the nucleus. The electron cloud is divided into shells or orbitals, and each shell can hold a certain number of electrons. The number of electrons in the outermost shell, called the valence shell, determines the chemical properties of the atom. \\n\\nIn a neutral atom, the number of protons in the nucleus is equal to the number of electrons in the electron cloud, so the positive and negative charges balance out and the atom has no overall charge. The number of protons, also called the atomic number, determines what element the atom is.\"],\n",
       " 'instruction': ['Give three tips for staying healthy.',\n",
       "  'What are the three primary colors?',\n",
       "  'Describe the structure of an atom.'],\n",
       " 'input': ['', '', '']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process dataset using the tokenizer from the pretrained model  \n",
    "Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BloomTokenizerFast(name_or_path='bigscience/bloom-1b1', vocab_size=250680, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b1\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for data processing and map the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 256\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\"\\n\".join([\"Human: \" + example[\"instruction\"], example[\"input\"]]).strip() + \"\\n\\nAssistant: \")\n",
    "    response = tokenizer(example[\"output\"] + tokenizer.eos_token)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"]\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "tokenized_ds = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What are the three primary colors?\\n\\nAssistant: The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).</s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).</s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(filter(lambda x: x != -100, tokenized_ds[1][\"labels\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trianed model Bloom-1b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BloomForCausalLM(\n",
       "  (transformer): BloomModel(\n",
       "    (word_embeddings): Embedding(250880, 1536)\n",
       "    (word_embeddings_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x BloomBlock(\n",
       "        (input_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): BloomAttention(\n",
       "          (query_key_value): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "          (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (post_attention_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): BloomMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "          (gelu_impl): BloomGelu()\n",
       "          (dense_4h_to_h): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=250880, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b1\", low_cpu_mem_usage=True)\n",
    "model # inspect model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the configuration for prompt tuning using the Huggingface PEFT library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PromptTuningConfig, get_peft_model, TaskType, PromptTuningInit\n",
    "\n",
    "config = PromptTuningConfig(task_type=TaskType.CAUSAL_LM,\n",
    "                            prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "                            prompt_tuning_init_text=\"Below is a conversation between a person and a chatbot.\",\n",
    "                            num_virtual_tokens=len(tokenizer(\"Below is a conversation between a person and a chatbot.\")[\"input_ids\"]),\n",
    "                            tokenizer_name_or_path=\"bigscience/bloom-1b1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model for peft training from the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): BloomForCausalLM(\n",
       "    (transformer): BloomModel(\n",
       "      (word_embeddings): Embedding(250880, 1536)\n",
       "      (word_embeddings_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (h): ModuleList(\n",
       "        (0-23): 24 x BloomBlock(\n",
       "          (input_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attention): BloomAttention(\n",
       "            (query_key_value): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (post_attention_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BloomMLP(\n",
       "            (dense_h_to_4h): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (gelu_impl): BloomGelu()\n",
       "            (dense_4h_to_h): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1536, out_features=250880, bias=False)\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PromptEmbedding(\n",
       "      (embedding): Embedding(12, 1536)\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(250880, 1536)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(model, config)\n",
    "model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check size of parameters to be trained in finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,432 || all params: 1,065,332,736 || trainable%: 0.0017301636734835116\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set arguments for trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./chatbot\", # Save checkpoints to a folder\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=20,\n",
    "    disable_tqdm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create trainer for training the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),    \n",
    ")\n",
    "\n",
    "# define a callback function for logging the losses to a text file\n",
    "class LossLoggingCallback(TrainerCallback):\n",
    "    def __init__(self, output_dir):\n",
    "        self.output_dir = output_dir\n",
    "        self.losses = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if 'loss' in logs:\n",
    "            self.losses.append(logs['loss'])\n",
    "            with open(f\"{self.output_dir}/losses.txt\", \"a\") as f:\n",
    "                f.write(f\"{state.global_step}: {logs['loss']}\\n\")\n",
    "\n",
    "trainer.add_callback(LossLoggingCallback(output_dir=\"./\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4391, 'grad_norm': 0.6870361566543579, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 2.4893, 'grad_norm': 0.6608906388282776, 'learning_rate': 4.9e-05, 'epoch': 0.02}\n",
      "{'loss': 2.4627, 'grad_norm': 1.5243343114852905, 'learning_rate': 4.85e-05, 'epoch': 0.03}\n",
      "{'loss': 2.5278, 'grad_norm': 1.57200026512146, 'learning_rate': 4.8e-05, 'epoch': 0.04}\n",
      "{'loss': 2.6109, 'grad_norm': 1.3944616317749023, 'learning_rate': 4.75e-05, 'epoch': 0.05}\n",
      "{'loss': 2.3909, 'grad_norm': 1.9582581520080566, 'learning_rate': 4.7e-05, 'epoch': 0.06}\n",
      "{'loss': 2.4162, 'grad_norm': 1.15701425075531, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.07}\n",
      "{'loss': 2.5592, 'grad_norm': 4.310897350311279, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 2.4701, 'grad_norm': 1.0848174095153809, 'learning_rate': 4.55e-05, 'epoch': 0.09}\n",
      "{'loss': 2.2615, 'grad_norm': 1.9100693464279175, 'learning_rate': 4.5e-05, 'epoch': 0.1}\n",
      "{'loss': 2.1659, 'grad_norm': 1.8064520359039307, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.11}\n",
      "{'loss': 2.3789, 'grad_norm': 7.942606449127197, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0539, 'grad_norm': 6.327280521392822, 'learning_rate': 4.35e-05, 'epoch': 0.13}\n",
      "{'loss': 2.1171, 'grad_norm': 3.644955635070801, 'learning_rate': 4.3e-05, 'epoch': 0.14}\n",
      "{'loss': 2.0674, 'grad_norm': 11.997719764709473, 'learning_rate': 4.25e-05, 'epoch': 0.15}\n",
      "{'loss': 2.1475, 'grad_norm': 2.1074724197387695, 'learning_rate': 4.2e-05, 'epoch': 0.16}\n",
      "{'loss': 2.0617, 'grad_norm': 4.1811017990112305, 'learning_rate': 4.15e-05, 'epoch': 0.17}\n",
      "{'loss': 2.0819, 'grad_norm': 2.8143200874328613, 'learning_rate': 4.1e-05, 'epoch': 0.18}\n",
      "{'loss': 2.1633, 'grad_norm': 3.8766496181488037, 'learning_rate': 4.05e-05, 'epoch': 0.19}\n",
      "{'loss': 2.2017, 'grad_norm': 3.9494924545288086, 'learning_rate': 4e-05, 'epoch': 0.2}\n",
      "{'loss': 2.0355, 'grad_norm': 5.083515167236328, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9358, 'grad_norm': 2.5962917804718018, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.22}\n",
      "{'loss': 2.0159, 'grad_norm': 5.452695369720459, 'learning_rate': 3.85e-05, 'epoch': 0.23}\n",
      "{'loss': 2.0023, 'grad_norm': 2.257032871246338, 'learning_rate': 3.8e-05, 'epoch': 0.24}\n",
      "{'loss': 2.0006, 'grad_norm': 6.83630895614624, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9894, 'grad_norm': 3.093113899230957, 'learning_rate': 3.7e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9553, 'grad_norm': 2.7863786220550537, 'learning_rate': 3.65e-05, 'epoch': 0.27}\n",
      "{'loss': 2.0399, 'grad_norm': 4.943046569824219, 'learning_rate': 3.6e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9494, 'grad_norm': 5.547587871551514, 'learning_rate': 3.55e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9444, 'grad_norm': 7.323053359985352, 'learning_rate': 3.5e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9372, 'grad_norm': 4.130950927734375, 'learning_rate': 3.45e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9383, 'grad_norm': 14.688751220703125, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.32}\n",
      "{'loss': 2.0647, 'grad_norm': 2.5410637855529785, 'learning_rate': 3.35e-05, 'epoch': 0.33}\n",
      "{'loss': 2.1042, 'grad_norm': 1.5745023488998413, 'learning_rate': 3.3e-05, 'epoch': 0.34}\n",
      "{'loss': 2.0128, 'grad_norm': 5.503964900970459, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9848, 'grad_norm': 3.6022908687591553, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9197, 'grad_norm': 3.4175314903259277, 'learning_rate': 3.15e-05, 'epoch': 0.37}\n",
      "{'loss': 2.032, 'grad_norm': 6.717776775360107, 'learning_rate': 3.1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9469, 'grad_norm': 5.920449733734131, 'learning_rate': 3.05e-05, 'epoch': 0.39}\n",
      "{'loss': 2.2138, 'grad_norm': 5.391157150268555, 'learning_rate': 3e-05, 'epoch': 0.4}\n",
      "{'loss': 2.0539, 'grad_norm': 5.19682502746582, 'learning_rate': 2.95e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8327, 'grad_norm': 5.230288028717041, 'learning_rate': 2.9e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9347, 'grad_norm': 5.397407531738281, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8698, 'grad_norm': 7.066709518432617, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.44}\n",
      "{'loss': 2.017, 'grad_norm': 28.584409713745117, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0546, 'grad_norm': 4.052536487579346, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.46}\n",
      "{'loss': 1.894, 'grad_norm': 4.416062831878662, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7557, 'grad_norm': 1.6943247318267822, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9787, 'grad_norm': 5.79905366897583, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9457, 'grad_norm': 15.31166934967041, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8485, 'grad_norm': 7.347099304199219, 'learning_rate': 2.45e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9258, 'grad_norm': 3.7078397274017334, 'learning_rate': 2.4e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9353, 'grad_norm': 4.162527561187744, 'learning_rate': 2.35e-05, 'epoch': 0.53}\n",
      "{'loss': 2.012, 'grad_norm': 3.3117501735687256, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9245, 'grad_norm': 6.376501083374023, 'learning_rate': 2.25e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9975, 'grad_norm': 4.120516300201416, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8968, 'grad_norm': 3.7491207122802734, 'learning_rate': 2.15e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8347, 'grad_norm': 3.35284423828125, 'learning_rate': 2.1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9507, 'grad_norm': 4.495387077331543, 'learning_rate': 2.05e-05, 'epoch': 0.59}\n",
      "{'loss': 2.0982, 'grad_norm': 7.028389930725098, 'learning_rate': 2e-05, 'epoch': 0.6}\n",
      "{'loss': 1.804, 'grad_norm': 4.104323387145996, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8554, 'grad_norm': 2.529031753540039, 'learning_rate': 1.9e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9133, 'grad_norm': 3.05096697807312, 'learning_rate': 1.85e-05, 'epoch': 0.63}\n",
      "{'loss': 2.1438, 'grad_norm': 2.4347541332244873, 'learning_rate': 1.8e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8425, 'grad_norm': 1.6905996799468994, 'learning_rate': 1.75e-05, 'epoch': 0.65}\n",
      "{'loss': 2.1236, 'grad_norm': 4.824453353881836, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8309, 'grad_norm': 1.7918866872787476, 'learning_rate': 1.65e-05, 'epoch': 0.67}\n",
      "{'loss': 1.799, 'grad_norm': 5.8652143478393555, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.68}\n",
      "{'loss': 2.0229, 'grad_norm': 4.375917434692383, 'learning_rate': 1.55e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8294, 'grad_norm': 5.961401462554932, 'learning_rate': 1.5e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9226, 'grad_norm': 3.6290934085845947, 'learning_rate': 1.45e-05, 'epoch': 0.71}\n",
      "{'loss': 1.8617, 'grad_norm': 3.0041160583496094, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.72}\n",
      "{'loss': 1.8995, 'grad_norm': 3.7108278274536133, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.73}\n",
      "{'loss': 1.8949, 'grad_norm': 6.270410537719727, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.74}\n",
      "{'loss': 2.293, 'grad_norm': 6.541668891906738, 'learning_rate': 1.25e-05, 'epoch': 0.75}\n",
      "{'loss': 1.9989, 'grad_norm': 3.434535503387451, 'learning_rate': 1.2e-05, 'epoch': 0.76}\n",
      "{'loss': 1.889, 'grad_norm': 3.8126251697540283, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.77}\n",
      "{'loss': 1.8385, 'grad_norm': 25.650218963623047, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.78}\n",
      "{'loss': 1.8791, 'grad_norm': 8.194701194763184, 'learning_rate': 1.05e-05, 'epoch': 0.79}\n",
      "{'loss': 1.8026, 'grad_norm': 2.3855128288269043, 'learning_rate': 1e-05, 'epoch': 0.8}\n",
      "{'loss': 1.8554, 'grad_norm': 3.797210454940796, 'learning_rate': 9.5e-06, 'epoch': 0.81}\n",
      "{'loss': 1.9393, 'grad_norm': 3.0857903957366943, 'learning_rate': 9e-06, 'epoch': 0.82}\n",
      "{'loss': 2.0455, 'grad_norm': 2.5917108058929443, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.83}\n",
      "{'loss': 1.9918, 'grad_norm': 10.804362297058105, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.84}\n",
      "{'loss': 1.8254, 'grad_norm': 4.138972759246826, 'learning_rate': 7.5e-06, 'epoch': 0.85}\n",
      "{'loss': 1.8447, 'grad_norm': 7.142788887023926, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 1.926, 'grad_norm': 2.801628828048706, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.87}\n",
      "{'loss': 1.922, 'grad_norm': 1.8333594799041748, 'learning_rate': 6e-06, 'epoch': 0.88}\n",
      "{'loss': 1.7936, 'grad_norm': 1.9754905700683594, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 2.1224, 'grad_norm': 22.787025451660156, 'learning_rate': 5e-06, 'epoch': 0.9}\n",
      "{'loss': 1.9315, 'grad_norm': 2.36653995513916, 'learning_rate': 4.5e-06, 'epoch': 0.91}\n",
      "{'loss': 1.9374, 'grad_norm': 3.6348397731781006, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 1.8217, 'grad_norm': 3.1446750164031982, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.93}\n",
      "{'loss': 1.9334, 'grad_norm': 4.165468692779541, 'learning_rate': 3e-06, 'epoch': 0.94}\n",
      "{'loss': 1.9942, 'grad_norm': 3.5285894870758057, 'learning_rate': 2.5e-06, 'epoch': 0.95}\n",
      "{'loss': 1.8839, 'grad_norm': 3.6729063987731934, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.96}\n",
      "{'loss': 1.8374, 'grad_norm': 7.00624418258667, 'learning_rate': 1.5e-06, 'epoch': 0.97}\n",
      "{'loss': 1.9164, 'grad_norm': 3.742387294769287, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.98}\n",
      "{'loss': 1.8832, 'grad_norm': 2.6665797233581543, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.99}\n",
      "{'loss': 1.7852, 'grad_norm': 7.610786437988281, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 995.5488, 'train_samples_per_second': 8.036, 'train_steps_per_second': 1.004, 'train_loss': 2.0148623447418212, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=2.0148623447418212, metrics={'train_runtime': 995.5488, 'train_samples_per_second': 8.036, 'train_steps_per_second': 1.004, 'train_loss': 2.0148623447418212, 'epoch': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test finetuned model with a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: How to prepare for an exam?\n",
      "\n",
      "Assistant: Use prepared material for the exam to reinforce the material being taught, and think through any questions that may come up or are coming up. For example, you might find yourself thinking about the question \"What is a free event?\" and want to give a specific answer to it, or perhaps you can look up other relevant topics for your area.\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "ipt = tokenizer(\"Human: {}\\n{}\".format(\"How to prepare for an exam?\", \"\").strip() + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
    "print(tokenizer.decode(model.generate(**ipt, max_length=128, do_sample=True)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Give me some tips for an exam.\n",
      "\n",
      "Assistant: An important thing to take into consideration is the stress of reading. The question is not a simple academic one but a life-help question with significant consequences in the real world. Here are recommendations to try to avoid:\n",
      "1. Keep a daily plan and work on your mindlist. This will help you to stay consistent.\n",
      "2. Create an environment that encourages you to focus on the test, as this will reduce stress.\n",
      "3. Remember to set realistic goals for your exam;\n",
      "4. It is also advisable to keep a record of where exactly you failed while\n"
     ]
    }
   ],
   "source": [
    "ipt2 = tokenizer(\"Human: {}\\n{}\".format(\"Give me some tips for an exam.\", \"\").strip() + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
    "print(tokenizer.decode(model.generate(**ipt2, max_length=128, do_sample=True)[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
