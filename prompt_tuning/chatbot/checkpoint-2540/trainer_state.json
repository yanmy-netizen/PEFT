{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7565715987787623,
  "eval_steps": 500,
  "global_step": 2540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.6640512943267822,
      "learning_rate": 4.985105749180816e-05,
      "loss": 2.9732,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5674738883972168,
      "learning_rate": 4.9702114983616324e-05,
      "loss": 3.1365,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9389584064483643,
      "learning_rate": 4.9553172475424484e-05,
      "loss": 2.9594,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.771834373474121,
      "learning_rate": 4.940422996723265e-05,
      "loss": 2.938,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.7694634199142456,
      "learning_rate": 4.925528745904081e-05,
      "loss": 2.9647,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2461851835250854,
      "learning_rate": 4.910634495084897e-05,
      "loss": 3.0108,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4141992330551147,
      "learning_rate": 4.895740244265713e-05,
      "loss": 2.8142,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0646880865097046,
      "learning_rate": 4.88084599344653e-05,
      "loss": 2.7301,
      "step": 80
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.720672369003296,
      "learning_rate": 4.865951742627346e-05,
      "loss": 2.741,
      "step": 90
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.2627732753753662,
      "learning_rate": 4.851057491808162e-05,
      "loss": 2.6354,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.708901047706604,
      "learning_rate": 4.836163240988978e-05,
      "loss": 2.7931,
      "step": 110
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9769964218139648,
      "learning_rate": 4.821268990169795e-05,
      "loss": 2.7269,
      "step": 120
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.5995397567749023,
      "learning_rate": 4.806374739350611e-05,
      "loss": 2.7338,
      "step": 130
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4605712890625,
      "learning_rate": 4.791480488531427e-05,
      "loss": 2.7993,
      "step": 140
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.390085220336914,
      "learning_rate": 4.776586237712243e-05,
      "loss": 2.837,
      "step": 150
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.967026710510254,
      "learning_rate": 4.761691986893059e-05,
      "loss": 2.6731,
      "step": 160
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.5421735048294067,
      "learning_rate": 4.746797736073876e-05,
      "loss": 2.661,
      "step": 170
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.110607624053955,
      "learning_rate": 4.731903485254692e-05,
      "loss": 2.7678,
      "step": 180
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4836845397949219,
      "learning_rate": 4.717009234435508e-05,
      "loss": 2.6846,
      "step": 190
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.1743075847625732,
      "learning_rate": 4.702114983616324e-05,
      "loss": 2.5644,
      "step": 200
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.4209296703338623,
      "learning_rate": 4.687220732797141e-05,
      "loss": 2.5251,
      "step": 210
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3691807985305786,
      "learning_rate": 4.672326481977957e-05,
      "loss": 2.5618,
      "step": 220
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.567174196243286,
      "learning_rate": 4.657432231158773e-05,
      "loss": 2.8222,
      "step": 230
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.113948106765747,
      "learning_rate": 4.642537980339589e-05,
      "loss": 2.5593,
      "step": 240
    },
    {
      "epoch": 0.07,
      "grad_norm": 4.265616416931152,
      "learning_rate": 4.627643729520406e-05,
      "loss": 2.7192,
      "step": 250
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.395743370056152,
      "learning_rate": 4.612749478701222e-05,
      "loss": 2.7387,
      "step": 260
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.650744438171387,
      "learning_rate": 4.597855227882037e-05,
      "loss": 2.7835,
      "step": 270
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.385898590087891,
      "learning_rate": 4.582960977062854e-05,
      "loss": 2.6282,
      "step": 280
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.6007463932037354,
      "learning_rate": 4.56806672624367e-05,
      "loss": 2.6706,
      "step": 290
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.3050522804260254,
      "learning_rate": 4.553172475424487e-05,
      "loss": 2.6454,
      "step": 300
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.460850477218628,
      "learning_rate": 4.538278224605302e-05,
      "loss": 2.6688,
      "step": 310
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.260340213775635,
      "learning_rate": 4.523383973786119e-05,
      "loss": 2.5949,
      "step": 320
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.293784141540527,
      "learning_rate": 4.508489722966935e-05,
      "loss": 2.4647,
      "step": 330
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.081178903579712,
      "learning_rate": 4.493595472147752e-05,
      "loss": 2.6479,
      "step": 340
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.2746496200561523,
      "learning_rate": 4.478701221328567e-05,
      "loss": 2.7424,
      "step": 350
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1669716835021973,
      "learning_rate": 4.463806970509384e-05,
      "loss": 2.6555,
      "step": 360
    },
    {
      "epoch": 0.11,
      "grad_norm": 5.271701335906982,
      "learning_rate": 4.4489127196902e-05,
      "loss": 2.7655,
      "step": 370
    },
    {
      "epoch": 0.11,
      "grad_norm": 7.1665472984313965,
      "learning_rate": 4.4340184688710166e-05,
      "loss": 2.6401,
      "step": 380
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.199481010437012,
      "learning_rate": 4.419124218051832e-05,
      "loss": 2.5463,
      "step": 390
    },
    {
      "epoch": 0.12,
      "grad_norm": 16.883129119873047,
      "learning_rate": 4.404229967232648e-05,
      "loss": 2.6576,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.7557315826416016,
      "learning_rate": 4.389335716413465e-05,
      "loss": 2.5311,
      "step": 410
    },
    {
      "epoch": 0.13,
      "grad_norm": 4.293335437774658,
      "learning_rate": 4.374441465594281e-05,
      "loss": 2.6362,
      "step": 420
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.166297912597656,
      "learning_rate": 4.359547214775097e-05,
      "loss": 2.6509,
      "step": 430
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.013270854949951,
      "learning_rate": 4.344652963955913e-05,
      "loss": 2.6385,
      "step": 440
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.082080841064453,
      "learning_rate": 4.32975871313673e-05,
      "loss": 2.4558,
      "step": 450
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.7459754943847656,
      "learning_rate": 4.314864462317546e-05,
      "loss": 2.5902,
      "step": 460
    },
    {
      "epoch": 0.14,
      "grad_norm": 6.335379600524902,
      "learning_rate": 4.299970211498362e-05,
      "loss": 2.6386,
      "step": 470
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.998929738998413,
      "learning_rate": 4.285075960679178e-05,
      "loss": 2.554,
      "step": 480
    },
    {
      "epoch": 0.15,
      "grad_norm": 9.008585929870605,
      "learning_rate": 4.2701817098599946e-05,
      "loss": 2.7297,
      "step": 490
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6380919218063354,
      "learning_rate": 4.2552874590408106e-05,
      "loss": 2.6174,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.626524925231934,
      "learning_rate": 4.240393208221627e-05,
      "loss": 2.5053,
      "step": 510
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2602434158325195,
      "learning_rate": 4.225498957402443e-05,
      "loss": 2.7195,
      "step": 520
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.724397659301758,
      "learning_rate": 4.2106047065832595e-05,
      "loss": 2.5611,
      "step": 530
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.05440092086792,
      "learning_rate": 4.1957104557640756e-05,
      "loss": 2.5602,
      "step": 540
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.585549831390381,
      "learning_rate": 4.180816204944891e-05,
      "loss": 2.5515,
      "step": 550
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.1186652183532715,
      "learning_rate": 4.165921954125708e-05,
      "loss": 2.5188,
      "step": 560
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.150039196014404,
      "learning_rate": 4.151027703306524e-05,
      "loss": 2.6237,
      "step": 570
    },
    {
      "epoch": 0.17,
      "grad_norm": 11.370450019836426,
      "learning_rate": 4.1361334524873405e-05,
      "loss": 2.6718,
      "step": 580
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.4191861152648926,
      "learning_rate": 4.121239201668156e-05,
      "loss": 2.5038,
      "step": 590
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.722511291503906,
      "learning_rate": 4.1063449508489726e-05,
      "loss": 2.4675,
      "step": 600
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.334100723266602,
      "learning_rate": 4.0914507000297886e-05,
      "loss": 2.5879,
      "step": 610
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.448482513427734,
      "learning_rate": 4.0765564492106054e-05,
      "loss": 2.6219,
      "step": 620
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.115993976593018,
      "learning_rate": 4.061662198391421e-05,
      "loss": 2.6354,
      "step": 630
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.577558994293213,
      "learning_rate": 4.0467679475722375e-05,
      "loss": 2.4487,
      "step": 640
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.4666993618011475,
      "learning_rate": 4.0318736967530536e-05,
      "loss": 2.6493,
      "step": 650
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5179038047790527,
      "learning_rate": 4.01697944593387e-05,
      "loss": 2.4994,
      "step": 660
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.0535993576049805,
      "learning_rate": 4.002085195114686e-05,
      "loss": 2.5073,
      "step": 670
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.2633843421936035,
      "learning_rate": 3.987190944295502e-05,
      "loss": 2.651,
      "step": 680
    },
    {
      "epoch": 0.21,
      "grad_norm": 6.602355003356934,
      "learning_rate": 3.9722966934763185e-05,
      "loss": 2.5239,
      "step": 690
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.5304481983184814,
      "learning_rate": 3.9574024426571345e-05,
      "loss": 2.4859,
      "step": 700
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.151241779327393,
      "learning_rate": 3.9425081918379506e-05,
      "loss": 2.5664,
      "step": 710
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.269733190536499,
      "learning_rate": 3.9276139410187666e-05,
      "loss": 2.588,
      "step": 720
    },
    {
      "epoch": 0.22,
      "grad_norm": 6.373344421386719,
      "learning_rate": 3.9127196901995834e-05,
      "loss": 2.6497,
      "step": 730
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.808483362197876,
      "learning_rate": 3.8978254393803994e-05,
      "loss": 2.609,
      "step": 740
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.838164806365967,
      "learning_rate": 3.8829311885612155e-05,
      "loss": 2.5466,
      "step": 750
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.031064987182617,
      "learning_rate": 3.8680369377420316e-05,
      "loss": 2.5367,
      "step": 760
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.986056327819824,
      "learning_rate": 3.853142686922848e-05,
      "loss": 2.4146,
      "step": 770
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.374699115753174,
      "learning_rate": 3.8382484361036644e-05,
      "loss": 2.6205,
      "step": 780
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.3757548332214355,
      "learning_rate": 3.8233541852844804e-05,
      "loss": 2.6715,
      "step": 790
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.7615268230438232,
      "learning_rate": 3.8084599344652965e-05,
      "loss": 2.7065,
      "step": 800
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.6722476482391357,
      "learning_rate": 3.7935656836461125e-05,
      "loss": 2.6956,
      "step": 810
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.8443149328231812,
      "learning_rate": 3.778671432826929e-05,
      "loss": 2.34,
      "step": 820
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.439411640167236,
      "learning_rate": 3.7637771820077446e-05,
      "loss": 2.6098,
      "step": 830
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.79564905166626,
      "learning_rate": 3.7488829311885614e-05,
      "loss": 2.511,
      "step": 840
    },
    {
      "epoch": 0.25,
      "grad_norm": 13.305561065673828,
      "learning_rate": 3.7339886803693774e-05,
      "loss": 2.5137,
      "step": 850
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.712789297103882,
      "learning_rate": 3.719094429550194e-05,
      "loss": 2.6743,
      "step": 860
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.8766279220581055,
      "learning_rate": 3.7042001787310096e-05,
      "loss": 2.7768,
      "step": 870
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.388460636138916,
      "learning_rate": 3.689305927911826e-05,
      "loss": 2.564,
      "step": 880
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.02405309677124,
      "learning_rate": 3.6744116770926424e-05,
      "loss": 2.5616,
      "step": 890
    },
    {
      "epoch": 0.27,
      "grad_norm": 6.679425239562988,
      "learning_rate": 3.659517426273459e-05,
      "loss": 2.4665,
      "step": 900
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.144030570983887,
      "learning_rate": 3.6446231754542745e-05,
      "loss": 2.4999,
      "step": 910
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.753212928771973,
      "learning_rate": 3.629728924635091e-05,
      "loss": 2.4121,
      "step": 920
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.905243396759033,
      "learning_rate": 3.614834673815907e-05,
      "loss": 2.5129,
      "step": 930
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.7753641605377197,
      "learning_rate": 3.599940422996723e-05,
      "loss": 2.563,
      "step": 940
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.2317845821380615,
      "learning_rate": 3.5850461721775394e-05,
      "loss": 2.5546,
      "step": 950
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.858487129211426,
      "learning_rate": 3.5701519213583554e-05,
      "loss": 2.5022,
      "step": 960
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.674869060516357,
      "learning_rate": 3.555257670539172e-05,
      "loss": 2.4974,
      "step": 970
    },
    {
      "epoch": 0.29,
      "grad_norm": 9.669310569763184,
      "learning_rate": 3.540363419719988e-05,
      "loss": 2.5263,
      "step": 980
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.3525550365448,
      "learning_rate": 3.525469168900804e-05,
      "loss": 2.4572,
      "step": 990
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.532605171203613,
      "learning_rate": 3.5105749180816204e-05,
      "loss": 2.4162,
      "step": 1000
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.257659912109375,
      "learning_rate": 3.495680667262437e-05,
      "loss": 2.4632,
      "step": 1010
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.836860179901123,
      "learning_rate": 3.480786416443253e-05,
      "loss": 2.4784,
      "step": 1020
    },
    {
      "epoch": 0.31,
      "grad_norm": 6.1240553855896,
      "learning_rate": 3.465892165624069e-05,
      "loss": 2.521,
      "step": 1030
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.079700469970703,
      "learning_rate": 3.450997914804885e-05,
      "loss": 2.5418,
      "step": 1040
    },
    {
      "epoch": 0.31,
      "grad_norm": 9.026725769042969,
      "learning_rate": 3.436103663985702e-05,
      "loss": 2.4229,
      "step": 1050
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.327347755432129,
      "learning_rate": 3.421209413166518e-05,
      "loss": 2.5218,
      "step": 1060
    },
    {
      "epoch": 0.32,
      "grad_norm": 11.48438549041748,
      "learning_rate": 3.406315162347334e-05,
      "loss": 2.5012,
      "step": 1070
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.848445892333984,
      "learning_rate": 3.39142091152815e-05,
      "loss": 2.6207,
      "step": 1080
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.583990573883057,
      "learning_rate": 3.376526660708966e-05,
      "loss": 2.4135,
      "step": 1090
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.018393039703369,
      "learning_rate": 3.361632409889783e-05,
      "loss": 2.4053,
      "step": 1100
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.6958682537078857,
      "learning_rate": 3.346738159070599e-05,
      "loss": 2.4063,
      "step": 1110
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.51276969909668,
      "learning_rate": 3.331843908251415e-05,
      "loss": 2.2712,
      "step": 1120
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.084146976470947,
      "learning_rate": 3.316949657432231e-05,
      "loss": 2.568,
      "step": 1130
    },
    {
      "epoch": 0.34,
      "grad_norm": 10.099345207214355,
      "learning_rate": 3.302055406613048e-05,
      "loss": 2.557,
      "step": 1140
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7658698558807373,
      "learning_rate": 3.287161155793864e-05,
      "loss": 2.3588,
      "step": 1150
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.725391387939453,
      "learning_rate": 3.27226690497468e-05,
      "loss": 2.3931,
      "step": 1160
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.2348222732543945,
      "learning_rate": 3.257372654155496e-05,
      "loss": 2.5888,
      "step": 1170
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.625451564788818,
      "learning_rate": 3.242478403336313e-05,
      "loss": 2.5853,
      "step": 1180
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.3676438331604,
      "learning_rate": 3.227584152517129e-05,
      "loss": 2.4183,
      "step": 1190
    },
    {
      "epoch": 0.36,
      "grad_norm": 11.59292984008789,
      "learning_rate": 3.212689901697944e-05,
      "loss": 2.5501,
      "step": 1200
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.651050090789795,
      "learning_rate": 3.197795650878761e-05,
      "loss": 2.3599,
      "step": 1210
    },
    {
      "epoch": 0.36,
      "grad_norm": 8.130476951599121,
      "learning_rate": 3.182901400059577e-05,
      "loss": 2.5557,
      "step": 1220
    },
    {
      "epoch": 0.37,
      "grad_norm": 5.056962013244629,
      "learning_rate": 3.168007149240393e-05,
      "loss": 2.4357,
      "step": 1230
    },
    {
      "epoch": 0.37,
      "grad_norm": 12.720372200012207,
      "learning_rate": 3.153112898421209e-05,
      "loss": 2.4853,
      "step": 1240
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.987758636474609,
      "learning_rate": 3.138218647602026e-05,
      "loss": 2.5447,
      "step": 1250
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.198827266693115,
      "learning_rate": 3.123324396782842e-05,
      "loss": 2.3108,
      "step": 1260
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.0477631092071533,
      "learning_rate": 3.108430145963658e-05,
      "loss": 2.4167,
      "step": 1270
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.223721742630005,
      "learning_rate": 3.093535895144474e-05,
      "loss": 2.4815,
      "step": 1280
    },
    {
      "epoch": 0.38,
      "grad_norm": 5.984067440032959,
      "learning_rate": 3.078641644325291e-05,
      "loss": 2.3477,
      "step": 1290
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.387757301330566,
      "learning_rate": 3.063747393506107e-05,
      "loss": 2.4723,
      "step": 1300
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.0877366065979004,
      "learning_rate": 3.0488531426869233e-05,
      "loss": 2.5092,
      "step": 1310
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.0674643516540527,
      "learning_rate": 3.0339588918677393e-05,
      "loss": 2.439,
      "step": 1320
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.972179889678955,
      "learning_rate": 3.019064641048555e-05,
      "loss": 2.5077,
      "step": 1330
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.256378650665283,
      "learning_rate": 3.0041703902293718e-05,
      "loss": 2.459,
      "step": 1340
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.328571319580078,
      "learning_rate": 2.9892761394101875e-05,
      "loss": 2.4517,
      "step": 1350
    },
    {
      "epoch": 0.41,
      "grad_norm": 7.409837245941162,
      "learning_rate": 2.9743818885910042e-05,
      "loss": 2.4979,
      "step": 1360
    },
    {
      "epoch": 0.41,
      "grad_norm": 19.866670608520508,
      "learning_rate": 2.95948763777182e-05,
      "loss": 2.6325,
      "step": 1370
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.915303707122803,
      "learning_rate": 2.9445933869526367e-05,
      "loss": 2.5872,
      "step": 1380
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.640496730804443,
      "learning_rate": 2.9296991361334524e-05,
      "loss": 2.5507,
      "step": 1390
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.523892402648926,
      "learning_rate": 2.914804885314269e-05,
      "loss": 2.566,
      "step": 1400
    },
    {
      "epoch": 0.42,
      "grad_norm": 9.919709205627441,
      "learning_rate": 2.899910634495085e-05,
      "loss": 2.6933,
      "step": 1410
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.179708003997803,
      "learning_rate": 2.8850163836759013e-05,
      "loss": 2.388,
      "step": 1420
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.7094550132751465,
      "learning_rate": 2.8701221328567173e-05,
      "loss": 2.5967,
      "step": 1430
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.5600104331970215,
      "learning_rate": 2.8552278820375337e-05,
      "loss": 2.5514,
      "step": 1440
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.205080986022949,
      "learning_rate": 2.8403336312183498e-05,
      "loss": 2.4222,
      "step": 1450
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.312573432922363,
      "learning_rate": 2.825439380399166e-05,
      "loss": 2.5229,
      "step": 1460
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.192376613616943,
      "learning_rate": 2.8105451295799822e-05,
      "loss": 2.455,
      "step": 1470
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.5007781982421875,
      "learning_rate": 2.7956508787607983e-05,
      "loss": 2.4761,
      "step": 1480
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.082608222961426,
      "learning_rate": 2.7807566279416147e-05,
      "loss": 2.559,
      "step": 1490
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.086747169494629,
      "learning_rate": 2.7658623771224308e-05,
      "loss": 2.4614,
      "step": 1500
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.6845805644989014,
      "learning_rate": 2.750968126303247e-05,
      "loss": 2.5293,
      "step": 1510
    },
    {
      "epoch": 0.45,
      "grad_norm": 6.0733489990234375,
      "learning_rate": 2.7360738754840632e-05,
      "loss": 2.4345,
      "step": 1520
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.7011494636535645,
      "learning_rate": 2.7211796246648796e-05,
      "loss": 2.6125,
      "step": 1530
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.1474404335021973,
      "learning_rate": 2.7062853738456957e-05,
      "loss": 2.516,
      "step": 1540
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.860625743865967,
      "learning_rate": 2.691391123026512e-05,
      "loss": 2.6154,
      "step": 1550
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.642435312271118,
      "learning_rate": 2.676496872207328e-05,
      "loss": 2.4463,
      "step": 1560
    },
    {
      "epoch": 0.47,
      "grad_norm": 5.674299240112305,
      "learning_rate": 2.6616026213881445e-05,
      "loss": 2.3893,
      "step": 1570
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.304816961288452,
      "learning_rate": 2.6467083705689606e-05,
      "loss": 2.2076,
      "step": 1580
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.084446907043457,
      "learning_rate": 2.631814119749777e-05,
      "loss": 2.4138,
      "step": 1590
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.293008804321289,
      "learning_rate": 2.616919868930593e-05,
      "loss": 2.5577,
      "step": 1600
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.7386474609375,
      "learning_rate": 2.6020256181114088e-05,
      "loss": 2.4907,
      "step": 1610
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.287510395050049,
      "learning_rate": 2.5871313672922255e-05,
      "loss": 2.3675,
      "step": 1620
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.221519947052002,
      "learning_rate": 2.5722371164730412e-05,
      "loss": 2.5045,
      "step": 1630
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.7449867725372314,
      "learning_rate": 2.557342865653858e-05,
      "loss": 2.3172,
      "step": 1640
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.174471378326416,
      "learning_rate": 2.5424486148346737e-05,
      "loss": 2.6323,
      "step": 1650
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.707222938537598,
      "learning_rate": 2.5275543640154904e-05,
      "loss": 2.5817,
      "step": 1660
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.385011196136475,
      "learning_rate": 2.512660113196306e-05,
      "loss": 2.4281,
      "step": 1670
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.6597909927368164,
      "learning_rate": 2.4977658623771225e-05,
      "loss": 2.5401,
      "step": 1680
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5708281993865967,
      "learning_rate": 2.4828716115579386e-05,
      "loss": 2.5575,
      "step": 1690
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.408431053161621,
      "learning_rate": 2.467977360738755e-05,
      "loss": 2.2995,
      "step": 1700
    },
    {
      "epoch": 0.51,
      "grad_norm": 10.887014389038086,
      "learning_rate": 2.453083109919571e-05,
      "loss": 2.4367,
      "step": 1710
    },
    {
      "epoch": 0.51,
      "grad_norm": 6.729780197143555,
      "learning_rate": 2.4381888591003874e-05,
      "loss": 2.2668,
      "step": 1720
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.05083703994751,
      "learning_rate": 2.4232946082812035e-05,
      "loss": 2.4844,
      "step": 1730
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.795023441314697,
      "learning_rate": 2.40840035746202e-05,
      "loss": 2.3344,
      "step": 1740
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.489793300628662,
      "learning_rate": 2.393506106642836e-05,
      "loss": 2.4973,
      "step": 1750
    },
    {
      "epoch": 0.52,
      "grad_norm": 13.507704734802246,
      "learning_rate": 2.3786118558236524e-05,
      "loss": 2.4307,
      "step": 1760
    },
    {
      "epoch": 0.53,
      "grad_norm": 6.698305130004883,
      "learning_rate": 2.3637176050044684e-05,
      "loss": 2.4706,
      "step": 1770
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.327826976776123,
      "learning_rate": 2.3488233541852848e-05,
      "loss": 2.3809,
      "step": 1780
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.7719123363494873,
      "learning_rate": 2.333929103366101e-05,
      "loss": 2.4411,
      "step": 1790
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.3730649948120117,
      "learning_rate": 2.319034852546917e-05,
      "loss": 2.3407,
      "step": 1800
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.08209753036499,
      "learning_rate": 2.304140601727733e-05,
      "loss": 2.4849,
      "step": 1810
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.210109233856201,
      "learning_rate": 2.2892463509085494e-05,
      "loss": 2.5815,
      "step": 1820
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.942209005355835,
      "learning_rate": 2.2743521000893654e-05,
      "loss": 2.5145,
      "step": 1830
    },
    {
      "epoch": 0.55,
      "grad_norm": 4.675853252410889,
      "learning_rate": 2.259457849270182e-05,
      "loss": 2.4455,
      "step": 1840
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.634085655212402,
      "learning_rate": 2.244563598450998e-05,
      "loss": 2.5217,
      "step": 1850
    },
    {
      "epoch": 0.55,
      "grad_norm": 9.450822830200195,
      "learning_rate": 2.2296693476318143e-05,
      "loss": 2.6441,
      "step": 1860
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.660185813903809,
      "learning_rate": 2.2147750968126304e-05,
      "loss": 2.4992,
      "step": 1870
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.5667386054992676,
      "learning_rate": 2.1998808459934468e-05,
      "loss": 2.5692,
      "step": 1880
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.826855659484863,
      "learning_rate": 2.1849865951742628e-05,
      "loss": 2.4879,
      "step": 1890
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.886360168457031,
      "learning_rate": 2.1700923443550792e-05,
      "loss": 2.5625,
      "step": 1900
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.4284119606018066,
      "learning_rate": 2.1551980935358953e-05,
      "loss": 2.4382,
      "step": 1910
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.285093307495117,
      "learning_rate": 2.1403038427167117e-05,
      "loss": 2.4349,
      "step": 1920
    },
    {
      "epoch": 0.57,
      "grad_norm": 14.183887481689453,
      "learning_rate": 2.1254095918975274e-05,
      "loss": 2.5241,
      "step": 1930
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.9191536903381348,
      "learning_rate": 2.1105153410783438e-05,
      "loss": 2.4344,
      "step": 1940
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.049967288970947,
      "learning_rate": 2.09562109025916e-05,
      "loss": 2.4573,
      "step": 1950
    },
    {
      "epoch": 0.58,
      "grad_norm": 6.443820476531982,
      "learning_rate": 2.0807268394399762e-05,
      "loss": 2.4567,
      "step": 1960
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.742692708969116,
      "learning_rate": 2.0658325886207923e-05,
      "loss": 2.4126,
      "step": 1970
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.267324924468994,
      "learning_rate": 2.0509383378016087e-05,
      "loss": 2.5633,
      "step": 1980
    },
    {
      "epoch": 0.59,
      "grad_norm": 9.911867141723633,
      "learning_rate": 2.0360440869824248e-05,
      "loss": 2.4617,
      "step": 1990
    },
    {
      "epoch": 0.6,
      "grad_norm": 12.760661125183105,
      "learning_rate": 2.021149836163241e-05,
      "loss": 2.5683,
      "step": 2000
    },
    {
      "epoch": 0.6,
      "grad_norm": 10.091838836669922,
      "learning_rate": 2.0062555853440572e-05,
      "loss": 2.4141,
      "step": 2010
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.779691696166992,
      "learning_rate": 1.9913613345248736e-05,
      "loss": 2.402,
      "step": 2020
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.6460280418396,
      "learning_rate": 1.9764670837056897e-05,
      "loss": 2.5,
      "step": 2030
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.7172529697418213,
      "learning_rate": 1.961572832886506e-05,
      "loss": 2.3517,
      "step": 2040
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.086886405944824,
      "learning_rate": 1.946678582067322e-05,
      "loss": 2.547,
      "step": 2050
    },
    {
      "epoch": 0.61,
      "grad_norm": 6.861302375793457,
      "learning_rate": 1.9317843312481382e-05,
      "loss": 2.4227,
      "step": 2060
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.317337989807129,
      "learning_rate": 1.9168900804289542e-05,
      "loss": 2.3555,
      "step": 2070
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.807221412658691,
      "learning_rate": 1.9019958296097706e-05,
      "loss": 2.4401,
      "step": 2080
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.965820789337158,
      "learning_rate": 1.8871015787905867e-05,
      "loss": 2.3695,
      "step": 2090
    },
    {
      "epoch": 0.63,
      "grad_norm": 5.640227317810059,
      "learning_rate": 1.872207327971403e-05,
      "loss": 2.4374,
      "step": 2100
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.932208061218262,
      "learning_rate": 1.857313077152219e-05,
      "loss": 2.5639,
      "step": 2110
    },
    {
      "epoch": 0.63,
      "grad_norm": 7.255680084228516,
      "learning_rate": 1.8424188263330356e-05,
      "loss": 2.4731,
      "step": 2120
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.5263214111328125,
      "learning_rate": 1.8275245755138516e-05,
      "loss": 2.5154,
      "step": 2130
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.495967388153076,
      "learning_rate": 1.812630324694668e-05,
      "loss": 2.2935,
      "step": 2140
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.9195587635040283,
      "learning_rate": 1.797736073875484e-05,
      "loss": 2.2907,
      "step": 2150
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.372274160385132,
      "learning_rate": 1.7828418230563005e-05,
      "loss": 2.5856,
      "step": 2160
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.224673271179199,
      "learning_rate": 1.7679475722371165e-05,
      "loss": 2.3488,
      "step": 2170
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.828741550445557,
      "learning_rate": 1.753053321417933e-05,
      "loss": 2.2603,
      "step": 2180
    },
    {
      "epoch": 0.65,
      "grad_norm": 12.606054306030273,
      "learning_rate": 1.738159070598749e-05,
      "loss": 2.5885,
      "step": 2190
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.171082973480225,
      "learning_rate": 1.723264819779565e-05,
      "loss": 2.3504,
      "step": 2200
    },
    {
      "epoch": 0.66,
      "grad_norm": 8.35417652130127,
      "learning_rate": 1.7083705689603814e-05,
      "loss": 2.4533,
      "step": 2210
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.578888893127441,
      "learning_rate": 1.6934763181411975e-05,
      "loss": 2.3813,
      "step": 2220
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.748009443283081,
      "learning_rate": 1.6785820673220136e-05,
      "loss": 2.3349,
      "step": 2230
    },
    {
      "epoch": 0.67,
      "grad_norm": 5.294661998748779,
      "learning_rate": 1.66368781650283e-05,
      "loss": 2.3947,
      "step": 2240
    },
    {
      "epoch": 0.67,
      "grad_norm": 7.814409255981445,
      "learning_rate": 1.648793565683646e-05,
      "loss": 2.4496,
      "step": 2250
    },
    {
      "epoch": 0.67,
      "grad_norm": 9.948721885681152,
      "learning_rate": 1.6338993148644624e-05,
      "loss": 2.3867,
      "step": 2260
    },
    {
      "epoch": 0.68,
      "grad_norm": 13.314842224121094,
      "learning_rate": 1.6190050640452785e-05,
      "loss": 2.4573,
      "step": 2270
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.5780839920043945,
      "learning_rate": 1.604110813226095e-05,
      "loss": 2.602,
      "step": 2280
    },
    {
      "epoch": 0.68,
      "grad_norm": 8.943178176879883,
      "learning_rate": 1.589216562406911e-05,
      "loss": 2.4743,
      "step": 2290
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.617758274078369,
      "learning_rate": 1.5743223115877273e-05,
      "loss": 2.4127,
      "step": 2300
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.001884937286377,
      "learning_rate": 1.5594280607685434e-05,
      "loss": 2.448,
      "step": 2310
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.636711597442627,
      "learning_rate": 1.5445338099493598e-05,
      "loss": 2.397,
      "step": 2320
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.0492513179779053,
      "learning_rate": 1.529639559130176e-05,
      "loss": 2.5336,
      "step": 2330
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.5069580078125,
      "learning_rate": 1.5147453083109919e-05,
      "loss": 2.5141,
      "step": 2340
    },
    {
      "epoch": 0.7,
      "grad_norm": 4.840648651123047,
      "learning_rate": 1.4998510574918081e-05,
      "loss": 2.5561,
      "step": 2350
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.862248420715332,
      "learning_rate": 1.4849568066726244e-05,
      "loss": 2.5149,
      "step": 2360
    },
    {
      "epoch": 0.71,
      "grad_norm": 4.9727373123168945,
      "learning_rate": 1.4700625558534406e-05,
      "loss": 2.3152,
      "step": 2370
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.075726270675659,
      "learning_rate": 1.4551683050342568e-05,
      "loss": 2.2488,
      "step": 2380
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.589580535888672,
      "learning_rate": 1.440274054215073e-05,
      "loss": 2.4896,
      "step": 2390
    },
    {
      "epoch": 0.71,
      "grad_norm": 6.588881015777588,
      "learning_rate": 1.4253798033958893e-05,
      "loss": 2.447,
      "step": 2400
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.365574359893799,
      "learning_rate": 1.4104855525767055e-05,
      "loss": 2.5062,
      "step": 2410
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.447772026062012,
      "learning_rate": 1.3955913017575217e-05,
      "loss": 2.5615,
      "step": 2420
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.3008430004119873,
      "learning_rate": 1.380697050938338e-05,
      "loss": 2.484,
      "step": 2430
    },
    {
      "epoch": 0.73,
      "grad_norm": 8.062328338623047,
      "learning_rate": 1.3658028001191542e-05,
      "loss": 2.4362,
      "step": 2440
    },
    {
      "epoch": 0.73,
      "grad_norm": 13.137541770935059,
      "learning_rate": 1.3509085492999704e-05,
      "loss": 2.3567,
      "step": 2450
    },
    {
      "epoch": 0.73,
      "grad_norm": 4.894090175628662,
      "learning_rate": 1.3360142984807863e-05,
      "loss": 2.423,
      "step": 2460
    },
    {
      "epoch": 0.74,
      "grad_norm": 11.762821197509766,
      "learning_rate": 1.3211200476616025e-05,
      "loss": 2.6539,
      "step": 2470
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.9901115894317627,
      "learning_rate": 1.3062257968424188e-05,
      "loss": 2.6058,
      "step": 2480
    },
    {
      "epoch": 0.74,
      "grad_norm": 5.094537258148193,
      "learning_rate": 1.291331546023235e-05,
      "loss": 2.3607,
      "step": 2490
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.8613810539245605,
      "learning_rate": 1.2764372952040512e-05,
      "loss": 2.5274,
      "step": 2500
    },
    {
      "epoch": 0.75,
      "grad_norm": 14.420809745788574,
      "learning_rate": 1.2615430443848674e-05,
      "loss": 2.3843,
      "step": 2510
    },
    {
      "epoch": 0.75,
      "grad_norm": 13.548538208007812,
      "learning_rate": 1.2466487935656837e-05,
      "loss": 2.4122,
      "step": 2520
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.6142497062683105,
      "learning_rate": 1.2317545427464999e-05,
      "loss": 2.4951,
      "step": 2530
    },
    {
      "epoch": 0.76,
      "grad_norm": 6.484640121459961,
      "learning_rate": 1.2168602919273161e-05,
      "loss": 2.4702,
      "step": 2540
    }
  ],
  "logging_steps": 10,
  "max_steps": 3357,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 20,
  "total_flos": 1.118007868219392e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
