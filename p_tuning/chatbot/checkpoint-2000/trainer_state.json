{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5957256683297342,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 2.5412025451660156,
      "learning_rate": 4.985105749180816e-05,
      "loss": 2.9718,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.9718728065490723,
      "learning_rate": 4.9702114983616324e-05,
      "loss": 2.9877,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.827620029449463,
      "learning_rate": 4.9553172475424484e-05,
      "loss": 2.7543,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.714890718460083,
      "learning_rate": 4.940422996723265e-05,
      "loss": 2.6658,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.9357666969299316,
      "learning_rate": 4.925528745904081e-05,
      "loss": 2.6665,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.93037486076355,
      "learning_rate": 4.910634495084897e-05,
      "loss": 2.6528,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.529818534851074,
      "learning_rate": 4.895740244265713e-05,
      "loss": 2.4472,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1248974800109863,
      "learning_rate": 4.88084599344653e-05,
      "loss": 2.5335,
      "step": 80
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.600733995437622,
      "learning_rate": 4.865951742627346e-05,
      "loss": 2.4137,
      "step": 90
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4148048162460327,
      "learning_rate": 4.851057491808162e-05,
      "loss": 2.3515,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.2408928871154785,
      "learning_rate": 4.836163240988978e-05,
      "loss": 2.562,
      "step": 110
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.621337652206421,
      "learning_rate": 4.821268990169795e-05,
      "loss": 2.4354,
      "step": 120
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.2161731719970703,
      "learning_rate": 4.806374739350611e-05,
      "loss": 2.4431,
      "step": 130
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0022850036621094,
      "learning_rate": 4.791480488531427e-05,
      "loss": 2.5353,
      "step": 140
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.048275470733643,
      "learning_rate": 4.776586237712243e-05,
      "loss": 2.6746,
      "step": 150
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.479307770729065,
      "learning_rate": 4.761691986893059e-05,
      "loss": 2.4257,
      "step": 160
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3765112161636353,
      "learning_rate": 4.746797736073876e-05,
      "loss": 2.4517,
      "step": 170
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.518884301185608,
      "learning_rate": 4.731903485254692e-05,
      "loss": 2.5293,
      "step": 180
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.7423560619354248,
      "learning_rate": 4.717009234435508e-05,
      "loss": 2.4852,
      "step": 190
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.665286660194397,
      "learning_rate": 4.702114983616324e-05,
      "loss": 2.3293,
      "step": 200
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.6365302801132202,
      "learning_rate": 4.687220732797141e-05,
      "loss": 2.2768,
      "step": 210
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1444506645202637,
      "learning_rate": 4.672326481977957e-05,
      "loss": 2.3442,
      "step": 220
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8973579406738281,
      "learning_rate": 4.657432231158773e-05,
      "loss": 2.6234,
      "step": 230
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.3842601776123047,
      "learning_rate": 4.642537980339589e-05,
      "loss": 2.3882,
      "step": 240
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.1765472888946533,
      "learning_rate": 4.627643729520406e-05,
      "loss": 2.5362,
      "step": 250
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9949631690979004,
      "learning_rate": 4.612749478701222e-05,
      "loss": 2.4956,
      "step": 260
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.2062859535217285,
      "learning_rate": 4.597855227882037e-05,
      "loss": 2.57,
      "step": 270
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.4620728492736816,
      "learning_rate": 4.582960977062854e-05,
      "loss": 2.4172,
      "step": 280
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.3221184015274048,
      "learning_rate": 4.56806672624367e-05,
      "loss": 2.4464,
      "step": 290
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1975675821304321,
      "learning_rate": 4.553172475424487e-05,
      "loss": 2.4328,
      "step": 300
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.665703296661377,
      "learning_rate": 4.538278224605302e-05,
      "loss": 2.5326,
      "step": 310
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3206632137298584,
      "learning_rate": 4.523383973786119e-05,
      "loss": 2.406,
      "step": 320
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.063138484954834,
      "learning_rate": 4.508489722966935e-05,
      "loss": 2.2493,
      "step": 330
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0926787853240967,
      "learning_rate": 4.493595472147752e-05,
      "loss": 2.4499,
      "step": 340
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2967725992202759,
      "learning_rate": 4.478701221328567e-05,
      "loss": 2.5359,
      "step": 350
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0578148365020752,
      "learning_rate": 4.463806970509384e-05,
      "loss": 2.4812,
      "step": 360
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.4678367376327515,
      "learning_rate": 4.4489127196902e-05,
      "loss": 2.5583,
      "step": 370
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.969104290008545,
      "learning_rate": 4.4340184688710166e-05,
      "loss": 2.4183,
      "step": 380
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.175560235977173,
      "learning_rate": 4.419124218051832e-05,
      "loss": 2.3768,
      "step": 390
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.635801792144775,
      "learning_rate": 4.404229967232648e-05,
      "loss": 2.4549,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.7684178352355957,
      "learning_rate": 4.389335716413465e-05,
      "loss": 2.3435,
      "step": 410
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0676400661468506,
      "learning_rate": 4.374441465594281e-05,
      "loss": 2.4441,
      "step": 420
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9474908113479614,
      "learning_rate": 4.359547214775097e-05,
      "loss": 2.4262,
      "step": 430
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.256826639175415,
      "learning_rate": 4.344652963955913e-05,
      "loss": 2.4316,
      "step": 440
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.34540855884552,
      "learning_rate": 4.32975871313673e-05,
      "loss": 2.3043,
      "step": 450
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.3394343852996826,
      "learning_rate": 4.314864462317546e-05,
      "loss": 2.4155,
      "step": 460
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.8755760192871094,
      "learning_rate": 4.299970211498362e-05,
      "loss": 2.4543,
      "step": 470
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3404693603515625,
      "learning_rate": 4.285075960679178e-05,
      "loss": 2.3526,
      "step": 480
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.3190433979034424,
      "learning_rate": 4.2701817098599946e-05,
      "loss": 2.5371,
      "step": 490
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9011284112930298,
      "learning_rate": 4.2552874590408106e-05,
      "loss": 2.4714,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1198716163635254,
      "learning_rate": 4.240393208221627e-05,
      "loss": 2.3277,
      "step": 510
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.3955211639404297,
      "learning_rate": 4.225498957402443e-05,
      "loss": 2.5407,
      "step": 520
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.3576197624206543,
      "learning_rate": 4.2106047065832595e-05,
      "loss": 2.3589,
      "step": 530
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.5544769763946533,
      "learning_rate": 4.1957104557640756e-05,
      "loss": 2.3901,
      "step": 540
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7879952192306519,
      "learning_rate": 4.180816204944891e-05,
      "loss": 2.379,
      "step": 550
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.322885513305664,
      "learning_rate": 4.165921954125708e-05,
      "loss": 2.3308,
      "step": 560
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.3200099468231201,
      "learning_rate": 4.151027703306524e-05,
      "loss": 2.4145,
      "step": 570
    },
    {
      "epoch": 0.17,
      "grad_norm": 5.0171074867248535,
      "learning_rate": 4.1361334524873405e-05,
      "loss": 2.4786,
      "step": 580
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.178719162940979,
      "learning_rate": 4.121239201668156e-05,
      "loss": 2.3413,
      "step": 590
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.243594169616699,
      "learning_rate": 4.1063449508489726e-05,
      "loss": 2.3188,
      "step": 600
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.3749932050704956,
      "learning_rate": 4.0914507000297886e-05,
      "loss": 2.4183,
      "step": 610
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9538421630859375,
      "learning_rate": 4.0765564492106054e-05,
      "loss": 2.4262,
      "step": 620
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9443756341934204,
      "learning_rate": 4.061662198391421e-05,
      "loss": 2.4708,
      "step": 630
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2517273426055908,
      "learning_rate": 4.0467679475722375e-05,
      "loss": 2.2698,
      "step": 640
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.248164415359497,
      "learning_rate": 4.0318736967530536e-05,
      "loss": 2.4322,
      "step": 650
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3402389287948608,
      "learning_rate": 4.01697944593387e-05,
      "loss": 2.3195,
      "step": 660
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0490994453430176,
      "learning_rate": 4.002085195114686e-05,
      "loss": 2.3327,
      "step": 670
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.2454988956451416,
      "learning_rate": 3.987190944295502e-05,
      "loss": 2.4429,
      "step": 680
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9031587839126587,
      "learning_rate": 3.9722966934763185e-05,
      "loss": 2.3243,
      "step": 690
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.3307340145111084,
      "learning_rate": 3.9574024426571345e-05,
      "loss": 2.324,
      "step": 700
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.129737138748169,
      "learning_rate": 3.9425081918379506e-05,
      "loss": 2.4082,
      "step": 710
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.403415322303772,
      "learning_rate": 3.9276139410187666e-05,
      "loss": 2.4049,
      "step": 720
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.6072660684585571,
      "learning_rate": 3.9127196901995834e-05,
      "loss": 2.4843,
      "step": 730
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2327724695205688,
      "learning_rate": 3.8978254393803994e-05,
      "loss": 2.4511,
      "step": 740
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9346785545349121,
      "learning_rate": 3.8829311885612155e-05,
      "loss": 2.3721,
      "step": 750
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.2247717380523682,
      "learning_rate": 3.8680369377420316e-05,
      "loss": 2.3574,
      "step": 760
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3696833848953247,
      "learning_rate": 3.853142686922848e-05,
      "loss": 2.2477,
      "step": 770
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.6656346321105957,
      "learning_rate": 3.8382484361036644e-05,
      "loss": 2.4578,
      "step": 780
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.6102129220962524,
      "learning_rate": 3.8233541852844804e-05,
      "loss": 2.4782,
      "step": 790
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.4715545177459717,
      "learning_rate": 3.8084599344652965e-05,
      "loss": 2.5185,
      "step": 800
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.44815194606781,
      "learning_rate": 3.7935656836461125e-05,
      "loss": 2.5082,
      "step": 810
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8084781765937805,
      "learning_rate": 3.778671432826929e-05,
      "loss": 2.1552,
      "step": 820
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3884315490722656,
      "learning_rate": 3.7637771820077446e-05,
      "loss": 2.3886,
      "step": 830
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.718609571456909,
      "learning_rate": 3.7488829311885614e-05,
      "loss": 2.3207,
      "step": 840
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.321659564971924,
      "learning_rate": 3.7339886803693774e-05,
      "loss": 2.3277,
      "step": 850
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.3190550804138184,
      "learning_rate": 3.719094429550194e-05,
      "loss": 2.4514,
      "step": 860
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.8564532995224,
      "learning_rate": 3.7042001787310096e-05,
      "loss": 2.612,
      "step": 870
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.6268150806427002,
      "learning_rate": 3.689305927911826e-05,
      "loss": 2.3794,
      "step": 880
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8869099617004395,
      "learning_rate": 3.6744116770926424e-05,
      "loss": 2.3822,
      "step": 890
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.0695321559906006,
      "learning_rate": 3.659517426273459e-05,
      "loss": 2.3086,
      "step": 900
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.6626091003417969,
      "learning_rate": 3.6446231754542745e-05,
      "loss": 2.3308,
      "step": 910
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.5677565336227417,
      "learning_rate": 3.629728924635091e-05,
      "loss": 2.2299,
      "step": 920
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.074778437614441,
      "learning_rate": 3.614834673815907e-05,
      "loss": 2.3622,
      "step": 930
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0527149438858032,
      "learning_rate": 3.599940422996723e-05,
      "loss": 2.4062,
      "step": 940
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1910169124603271,
      "learning_rate": 3.5850461721775394e-05,
      "loss": 2.3822,
      "step": 950
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0833468437194824,
      "learning_rate": 3.5701519213583554e-05,
      "loss": 2.2875,
      "step": 960
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.154773473739624,
      "learning_rate": 3.555257670539172e-05,
      "loss": 2.3732,
      "step": 970
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.572722434997559,
      "learning_rate": 3.540363419719988e-05,
      "loss": 2.3752,
      "step": 980
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.4175266027450562,
      "learning_rate": 3.525469168900804e-05,
      "loss": 2.3034,
      "step": 990
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.9894425868988037,
      "learning_rate": 3.5105749180816204e-05,
      "loss": 2.2358,
      "step": 1000
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7075095176696777,
      "learning_rate": 3.495680667262437e-05,
      "loss": 2.2828,
      "step": 1010
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.3618321418762207,
      "learning_rate": 3.480786416443253e-05,
      "loss": 2.3201,
      "step": 1020
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.699994683265686,
      "learning_rate": 3.465892165624069e-05,
      "loss": 2.3541,
      "step": 1030
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3020401000976562,
      "learning_rate": 3.450997914804885e-05,
      "loss": 2.3386,
      "step": 1040
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9238812923431396,
      "learning_rate": 3.436103663985702e-05,
      "loss": 2.2188,
      "step": 1050
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.024731397628784,
      "learning_rate": 3.421209413166518e-05,
      "loss": 2.379,
      "step": 1060
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.900002956390381,
      "learning_rate": 3.406315162347334e-05,
      "loss": 2.3326,
      "step": 1070
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.504303216934204,
      "learning_rate": 3.39142091152815e-05,
      "loss": 2.4385,
      "step": 1080
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.511397361755371,
      "learning_rate": 3.376526660708966e-05,
      "loss": 2.2639,
      "step": 1090
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.5134040117263794,
      "learning_rate": 3.361632409889783e-05,
      "loss": 2.234,
      "step": 1100
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.441681146621704,
      "learning_rate": 3.346738159070599e-05,
      "loss": 2.2775,
      "step": 1110
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0357176065444946,
      "learning_rate": 3.331843908251415e-05,
      "loss": 2.1396,
      "step": 1120
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.7186458110809326,
      "learning_rate": 3.316949657432231e-05,
      "loss": 2.4172,
      "step": 1130
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.6414945125579834,
      "learning_rate": 3.302055406613048e-05,
      "loss": 2.4028,
      "step": 1140
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3295425176620483,
      "learning_rate": 3.287161155793864e-05,
      "loss": 2.2074,
      "step": 1150
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.25019371509552,
      "learning_rate": 3.27226690497468e-05,
      "loss": 2.2334,
      "step": 1160
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0349246263504028,
      "learning_rate": 3.257372654155496e-05,
      "loss": 2.4415,
      "step": 1170
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.388025999069214,
      "learning_rate": 3.242478403336313e-05,
      "loss": 2.409,
      "step": 1180
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.6426537036895752,
      "learning_rate": 3.227584152517129e-05,
      "loss": 2.2619,
      "step": 1190
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.075775146484375,
      "learning_rate": 3.212689901697944e-05,
      "loss": 2.387,
      "step": 1200
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.4990999698638916,
      "learning_rate": 3.197795650878761e-05,
      "loss": 2.2394,
      "step": 1210
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8569700717926025,
      "learning_rate": 3.182901400059577e-05,
      "loss": 2.3747,
      "step": 1220
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.7363755702972412,
      "learning_rate": 3.168007149240393e-05,
      "loss": 2.2826,
      "step": 1230
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.2535219192504883,
      "learning_rate": 3.153112898421209e-05,
      "loss": 2.2952,
      "step": 1240
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.6185462474822998,
      "learning_rate": 3.138218647602026e-05,
      "loss": 2.3749,
      "step": 1250
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.2879998683929443,
      "learning_rate": 3.123324396782842e-05,
      "loss": 2.1639,
      "step": 1260
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.5372858047485352,
      "learning_rate": 3.108430145963658e-05,
      "loss": 2.2588,
      "step": 1270
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.383244276046753,
      "learning_rate": 3.093535895144474e-05,
      "loss": 2.3389,
      "step": 1280
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.074323892593384,
      "learning_rate": 3.078641644325291e-05,
      "loss": 2.2225,
      "step": 1290
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9874260425567627,
      "learning_rate": 3.063747393506107e-05,
      "loss": 2.3103,
      "step": 1300
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9828352928161621,
      "learning_rate": 3.0488531426869233e-05,
      "loss": 2.3408,
      "step": 1310
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3723702430725098,
      "learning_rate": 3.0339588918677393e-05,
      "loss": 2.2602,
      "step": 1320
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.5326964855194092,
      "learning_rate": 3.019064641048555e-05,
      "loss": 2.3804,
      "step": 1330
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8515849113464355,
      "learning_rate": 3.0041703902293718e-05,
      "loss": 2.3187,
      "step": 1340
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1231873035430908,
      "learning_rate": 2.9892761394101875e-05,
      "loss": 2.3192,
      "step": 1350
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.719979763031006,
      "learning_rate": 2.9743818885910042e-05,
      "loss": 2.3032,
      "step": 1360
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.088465690612793,
      "learning_rate": 2.95948763777182e-05,
      "loss": 2.4682,
      "step": 1370
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5291465520858765,
      "learning_rate": 2.9445933869526367e-05,
      "loss": 2.4199,
      "step": 1380
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6721866130828857,
      "learning_rate": 2.9296991361334524e-05,
      "loss": 2.3881,
      "step": 1390
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7768380641937256,
      "learning_rate": 2.914804885314269e-05,
      "loss": 2.4009,
      "step": 1400
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.2076752185821533,
      "learning_rate": 2.899910634495085e-05,
      "loss": 2.5238,
      "step": 1410
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.9509162902832031,
      "learning_rate": 2.8850163836759013e-05,
      "loss": 2.203,
      "step": 1420
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7999640703201294,
      "learning_rate": 2.8701221328567173e-05,
      "loss": 2.4493,
      "step": 1430
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5464633703231812,
      "learning_rate": 2.8552278820375337e-05,
      "loss": 2.3973,
      "step": 1440
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.700016975402832,
      "learning_rate": 2.8403336312183498e-05,
      "loss": 2.261,
      "step": 1450
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5465526580810547,
      "learning_rate": 2.825439380399166e-05,
      "loss": 2.3867,
      "step": 1460
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.625169515609741,
      "learning_rate": 2.8105451295799822e-05,
      "loss": 2.2592,
      "step": 1470
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3149778842926025,
      "learning_rate": 2.7956508787607983e-05,
      "loss": 2.2877,
      "step": 1480
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2473676204681396,
      "learning_rate": 2.7807566279416147e-05,
      "loss": 2.3719,
      "step": 1490
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.1293063163757324,
      "learning_rate": 2.7658623771224308e-05,
      "loss": 2.3272,
      "step": 1500
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8090343475341797,
      "learning_rate": 2.750968126303247e-05,
      "loss": 2.3663,
      "step": 1510
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6866825819015503,
      "learning_rate": 2.7360738754840632e-05,
      "loss": 2.3224,
      "step": 1520
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1315535306930542,
      "learning_rate": 2.7211796246648796e-05,
      "loss": 2.4471,
      "step": 1530
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1265441179275513,
      "learning_rate": 2.7062853738456957e-05,
      "loss": 2.3433,
      "step": 1540
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0578296184539795,
      "learning_rate": 2.691391123026512e-05,
      "loss": 2.4303,
      "step": 1550
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.959364116191864,
      "learning_rate": 2.676496872207328e-05,
      "loss": 2.3156,
      "step": 1560
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.5815012454986572,
      "learning_rate": 2.6616026213881445e-05,
      "loss": 2.2396,
      "step": 1570
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.5383870601654053,
      "learning_rate": 2.6467083705689606e-05,
      "loss": 2.0935,
      "step": 1580
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1428238153457642,
      "learning_rate": 2.631814119749777e-05,
      "loss": 2.2572,
      "step": 1590
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.1951887607574463,
      "learning_rate": 2.616919868930593e-05,
      "loss": 2.3994,
      "step": 1600
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.501322269439697,
      "learning_rate": 2.6020256181114088e-05,
      "loss": 2.3799,
      "step": 1610
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3662240505218506,
      "learning_rate": 2.5871313672922255e-05,
      "loss": 2.2234,
      "step": 1620
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0280570983886719,
      "learning_rate": 2.5722371164730412e-05,
      "loss": 2.344,
      "step": 1630
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.244477391242981,
      "learning_rate": 2.557342865653858e-05,
      "loss": 2.1938,
      "step": 1640
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4121493101119995,
      "learning_rate": 2.5424486148346737e-05,
      "loss": 2.4331,
      "step": 1650
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8491958379745483,
      "learning_rate": 2.5275543640154904e-05,
      "loss": 2.4134,
      "step": 1660
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.6028181314468384,
      "learning_rate": 2.512660113196306e-05,
      "loss": 2.2961,
      "step": 1670
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.095230221748352,
      "learning_rate": 2.4977658623771225e-05,
      "loss": 2.4162,
      "step": 1680
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2030268907546997,
      "learning_rate": 2.4828716115579386e-05,
      "loss": 2.4101,
      "step": 1690
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.2799980640411377,
      "learning_rate": 2.467977360738755e-05,
      "loss": 2.1641,
      "step": 1700
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.344389915466309,
      "learning_rate": 2.453083109919571e-05,
      "loss": 2.2745,
      "step": 1710
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6561062335968018,
      "learning_rate": 2.4381888591003874e-05,
      "loss": 2.1212,
      "step": 1720
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7460823059082031,
      "learning_rate": 2.4232946082812035e-05,
      "loss": 2.3266,
      "step": 1730
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5174989700317383,
      "learning_rate": 2.40840035746202e-05,
      "loss": 2.1999,
      "step": 1740
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1861250400543213,
      "learning_rate": 2.393506106642836e-05,
      "loss": 2.3586,
      "step": 1750
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.818646192550659,
      "learning_rate": 2.3786118558236524e-05,
      "loss": 2.273,
      "step": 1760
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.4107613563537598,
      "learning_rate": 2.3637176050044684e-05,
      "loss": 2.3123,
      "step": 1770
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.486831545829773,
      "learning_rate": 2.3488233541852848e-05,
      "loss": 2.2219,
      "step": 1780
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6125266551971436,
      "learning_rate": 2.333929103366101e-05,
      "loss": 2.3245,
      "step": 1790
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.2164791822433472,
      "learning_rate": 2.319034852546917e-05,
      "loss": 2.1749,
      "step": 1800
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9362674951553345,
      "learning_rate": 2.304140601727733e-05,
      "loss": 2.3205,
      "step": 1810
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5688738822937012,
      "learning_rate": 2.2892463509085494e-05,
      "loss": 2.4271,
      "step": 1820
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.1577765941619873,
      "learning_rate": 2.2743521000893654e-05,
      "loss": 2.3898,
      "step": 1830
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3255587816238403,
      "learning_rate": 2.259457849270182e-05,
      "loss": 2.2796,
      "step": 1840
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9621644020080566,
      "learning_rate": 2.244563598450998e-05,
      "loss": 2.3294,
      "step": 1850
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8714631795883179,
      "learning_rate": 2.2296693476318143e-05,
      "loss": 2.4645,
      "step": 1860
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8709815740585327,
      "learning_rate": 2.2147750968126304e-05,
      "loss": 2.3138,
      "step": 1870
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.940036416053772,
      "learning_rate": 2.1998808459934468e-05,
      "loss": 2.4199,
      "step": 1880
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.2080769538879395,
      "learning_rate": 2.1849865951742628e-05,
      "loss": 2.3545,
      "step": 1890
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.492598056793213,
      "learning_rate": 2.1700923443550792e-05,
      "loss": 2.3841,
      "step": 1900
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.1686089038848877,
      "learning_rate": 2.1551980935358953e-05,
      "loss": 2.3022,
      "step": 1910
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5391292572021484,
      "learning_rate": 2.1403038427167117e-05,
      "loss": 2.2899,
      "step": 1920
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.3855695724487305,
      "learning_rate": 2.1254095918975274e-05,
      "loss": 2.3597,
      "step": 1930
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6493502855300903,
      "learning_rate": 2.1105153410783438e-05,
      "loss": 2.2753,
      "step": 1940
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.5132759809494019,
      "learning_rate": 2.09562109025916e-05,
      "loss": 2.2883,
      "step": 1950
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.113267183303833,
      "learning_rate": 2.0807268394399762e-05,
      "loss": 2.3207,
      "step": 1960
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5602355003356934,
      "learning_rate": 2.0658325886207923e-05,
      "loss": 2.2594,
      "step": 1970
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.661512553691864,
      "learning_rate": 2.0509383378016087e-05,
      "loss": 2.3949,
      "step": 1980
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.4049577713012695,
      "learning_rate": 2.0360440869824248e-05,
      "loss": 2.3204,
      "step": 1990
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.742214679718018,
      "learning_rate": 2.021149836163241e-05,
      "loss": 2.3845,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 3357,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 8808567496704000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
